* tool
** VIM
*** 配置
+ 文章1
@vim

配置文件路径：/etc/vim/vimrc

  syn on                    ;语法高亮

  set tabstop=4             ;tab宽度

  set shiftwidth=4          ;换行缩进宽度

  set backspace=2           ;设置退格可用

  set incsearch             ;搜索自动补全

  set ai!                   ;设置自动缩进

  set nu!                   ;显示行号

  set autoindent       ;自动换行

使vi兼容windows的中文

  set fencs=utf-8,ucs-bom,euc-jp,gb18030,gbk,gb2312,cp936

Ctrl＋N 自动搜索补全函数或变量等。如果习惯shell的tab补全功能只需要在vimrc里面加入如下代码：

function! CleverTab()
  if strpart( getline('.'), 0, col('.')-1 ) =~ '^\s*$'
      return "\<Tab>"
  else
      return "\<C-N>"
endfunction
inoremap <Tab> <C-R>=CleverTab()<CR>
+ 文章2
@vim

set fenc=utf-8
set fencs=utf-8,usc-bom,euc-jp,gb18030,gbk,gb2312,cp936

" 不要使用vi的键盘模式，而是vim自己的
set nocompatible

" history文件中需要记录的行数
set history=100

" 在处理未保存或只读文件的时候，弹出确认
set confirm

" 与windows共享剪贴板
set clipboard+=unnamed

" 侦测文件类型
filetype on

" 载入文件类型插件
filetype plugin on

" 为特定文件类型载入相关缩进文件
filetype indent on

" 保存全局变量
set viminfo+=!

" 带有如下符号的单词不要被换行分割
set iskeyword+=_,$,@,%,#,-

" 语法高亮
syntax on

" 高亮字符，让其不受100列限制
:highlight OverLength ctermbg=red ctermfg=white guibg=red guifg=white
:match OverLength '%101v.*'

" 状态行颜色
highlight StatusLine guifg=SlateBlue guibg=Yellow
highlight StatusLineNC guifg=Gray guibg=White

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 文件设置
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 不要备份文件（根据自己需要取舍）
set nobackup

" 不要生成swap文件，当buffer被丢弃的时候隐藏它
setlocal noswapfile
set bufhidden=hide

" 字符间插入的像素行数目
set linespace=0

" 增强模式中的命令行自动完成操作
set wildmenu

" 在状态行上显示光标所在位置的行号和列号
set ruler
set rulerformat=%20(%2*%<%f%= %m%r %3l %c %p%%%)

" 命令行（在状态行下）的高度，默认为1，这里是2
set cmdheight=2

" 使回格键（backspace）正常处理indent, eol, start等
set backspace=2

" 允许backspace和光标键跨越行边界
set whichwrap+=<,>,h,l

" 可以在buffer的任何地方使用鼠标（类似office中在工作区双击鼠标定位）
set mouse=a
set selection=exclusive
set selectmode=mouse,key

" 启动的时候不显示那个援助索马里儿童的提示
set shortmess=atI

" 通过使用: commands命令，告诉我们文件的哪一行被改变过
set report=0

" 不让vim发出讨厌的滴滴声
set noerrorbells

" 在被分割的窗口间显示空白，便于阅读
set fillchars=vert: ,stl: ,stlnc:

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 搜索和匹配
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 高亮显示匹配的括号
set showmatch

" 匹配括号高亮的时间（单位是十分之一秒）
set matchtime=5

" 在搜索的时候忽略大小写
set ignorecase

" 不要高亮被搜索的句子（phrases）
set nohlsearch

" 在搜索时，输入的词句的逐字符高亮（类似firefox的搜索）
set incsearch

" 输入:set list命令是应该显示些啥？
set listchars=tab:| ,trail:.,extends:>,precedes:<,eol

" 光标移动到buffer的顶部和底部时保持3行距离
set scrolloff=3

" 不要闪烁
set novisualbell

" 我的状态行显示的内容（包括文件类型和解码）
set statusline=%F%m%r%h%w [FORMAT=%{&ff}] [TYPE=%Y] [POS=%l,%v][%p%%] %{strftime("%d/%m/%y - %H:%M")}

" 总是显示状态行
set laststatus=2

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 文本格式和排版
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 自动格式化
set formatoptions=tcrqn

" 继承前一行的缩进方式，特别适用于多行注释
set autoindent

" 为C程序提供自动缩进
set smartindent

" 使用C样式的缩进
set cindent

" 制表符为4
set tabstop=4

" 统一缩进为4
set softtabstop=4
set shiftwidth=4

" 不要用空格代替制表符
set noexpandtab

" 不要换行
set nowrap

" 在行和段开始处使用制表符
set smarttab

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" CTags的设定
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 按照名称排序
let Tlist_Sort_Type = "name"

" 在右侧显示窗口
let Tlist_Use_Right_Window = 1

" 压缩方式
let Tlist_Compart_Format = 1

" 如果只有一个buffer，kill窗口也kill掉buffer
let Tlist_Exist_OnlyWindow = 1

" 不要关闭其他文件的tags
let Tlist_File_Fold_Auto_Close = 0

" 不要显示折叠树
let Tlist_Enable_Fold_Column = 0

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" Autocommands
"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
" 只在下列文件类型被侦测到的时候显示行号，普通文本文件不显示

if has("autocmd")
autocmd FileType xml,html,c,cs,java,perl,shell,bash,cpp,python,vim,php,ruby set number
autocmd FileType xml,html vmap <C-o> <ESC>'<i<!--<ESC>o<ESC>'>o-->
autocmd FileType java,c,cpp,cs vmap <C-o> <ESC>'<o/*<ESC>'>o*/
autocmd FileType html,text,php,vim,c,java,xml,bash,shell,perl,python setlocal textwidth=100
autocmd Filetype html,xml,xsl source $VIMRUNTIME/plugin/closetag.vim
autocmd BufReadPost *
   if line("'"") > 0 && line("'"") <= line("$") |
      exe "normal g`"" |
   endif
endif " has("autocmd")

" F5编译和运行C程序，F6编译和运行C++程序
" 请注意，下述代码在windows下使用会报错
" 需要去掉./这两个字符

" C的编译和运行
map <F5> :call CompileRunGcc()<CR>
func! CompileRunGcc()
exec "w"
exec "!gcc % -o %<"
exec "! ./%<"
endfunc

" C++的编译和运行
map <F6> :call CompileRunGpp()<CR>
func! CompileRunGpp()
exec "w"
exec "!g++ % -o %<"
exec "! ./%<"
endfunc

" 能够漂亮地显示.NFO文件
set encoding=utf-8
function! SetFileEncodings(encodings)
let b:myfileencodingsbak=&fileencodings
let &fileencodings=a:encodings
endfunction
function! RestoreFileEncodings()
let &fileencodings=b:myfileencodingsbak
unlet b:myfileencodingsbak
endfunction

au BufReadPre *.nfo call SetFileEncodings('cp437')|set ambiwidth=single
au BufReadPost *.nfo call RestoreFileEncodings()

" 高亮显示普通txt文件（需要txt.vim脚本）
au BufRead,BufNewFile *   setfiletype txt

" 用空格键来开关折叠
set foldenable
set foldmethod=manual
nnoremap <space> @=((foldclosed(line('.')) < 0) ? 'zc' : 'zo')<CR>

" minibufexpl插件的一般设置
let g:miniBufExplMapWindowNavVim = 1
let g:miniBufExplMapWindowNavArrows = 1
let g:miniBufExplMapCTabSwitchBufs = 1
let g:miniBufExplModSelTarget = 1
** emacs  
*** emacs下配置python开发环境
+ 相关网站
官方网站：http://pymacs.progiciels-bpi.ca/
python开发环境 [[http://hi.baidu.com/tiger_tnt/blog/item/6c6d9497af4e656455fb969f.html][python开发环境安装介绍]]

+ pymacs安装方法
运行make check
检查没问题

安装pymacs.py：
运行sudo python setup.py install
在命令行运行python，输入from Pymacs import lisp，然后回车，没有出错信息就表示pymacs.py安装成功了。

安装pymacs.el：
sudo cp pymacs.el /usr/local/share/emacs/site-lisp
（我的emacs是自己编译安装的，所以在/usr/local下）

编辑自己的.emacs文件，加入下面几行：
(autoload 'pymacs-apply "pymacs")
(autoload 'pymacs-call "pymacs")
(autoload 'pymacs-eval "pymacs" nil t)
(autoload 'pymacs-exec "pymacs" nil t)
(autoload 'pymacs-load "pymacs" nil t)
;;(eval-after-load "pymacs"
;;  '(add-to-list 'pymacs-load-path YOUR-PYMACS-DIRECTORY))
最后被注释掉的这两行，是为pymacs-load加载python模块设置搜索路径的。
eval-after-load表示pymacs.el被emacs加载后才设置这个路径。


*** 网址
@emacs

介绍如何建立emacs的IDE
http://www.360doc.com/content/10/0221/00/155970_16296841.shtml

http://www.cbi.pku.edu.cn/chinese/documents/csdoc/emacs/chap3.html

http://emacser.com/
*** elisp
**** 常用函数
***** lambda 
函数编程相关lambda  funcall 

function这个函数返回一个用户自己定义好的函数
fset这个函数可以定义一个新的函数
     (defun make-add (n)
         (function (lambda (m) (+ n m))))  ; Return a function.
          => make-add
     (fset 'add2 (make-add 2))  ; Define function `add2'
                                ;   with `(make-add 2)'.
          => (lambda (m) (+ n m))
     (add2 4)                   ; Try to add 2 to 4.
     error--> Symbol's value as variable is void: n

***** hash
hash-table相关#s(hash-table)  puthash gethash


***** string相关
— Function: concat &rest sequences

This function returns a new string consisting of the characters in the arguments passed to it (along with their text properties, if any). The arguments may be strings, lists of numbers, or vectors of numbers; they are not themselves changed. If concat receives no arguments, it returns an empty string. 

          (concat "abc" "-def")
               ⇒ "abc-def"
          (concat "abc" (list 120 121) [122])
               ⇒ "abcxyz"
          ;; nil is an empty sequence.
          (concat "abc" nil "-def")
               ⇒ "abc-def"
          (concat "The " "quick brown " "fox.")
               ⇒ "The quick brown fox."
          (concat)
               ⇒ ""

 拆分字符串split-string 
 (split-string "  two words ")
               ⇒ ("two" "words")


字符串常用：
用于转换字符串至数字
(string-to-number "256")
               ⇒ 256

(substring "abcdefg" 0 3)
               => "abc"

          (string= "abc" "abc")
               => t
          (string= "abc" "ABC")
               => nil
          (string= "ab" "ABC")
               => nil

          (string< "abc" "abd")
               => t
          (string< "abd" "abc")
               => nil
          (string< "123" "abc")
               => t
     (format "The value of fill-column is %d." fill-column)
          => "The value of fill-column is 72."




***** List相关的函数
判断b是否是list的成员
          (memq 'b '(a b c b a))
               => (b c b a)

          (elt [1 2 3 4] 2)
               => 3
          (elt '(1 2 3 4) 2)
               => 3



合并list
ncoco不copy 且会合并两个list中相同的东西， append会copy
          (setq x '(1 2 3))
               ⇒ (1 2 3)
          (nconc x '(4 5))
               ⇒ (1 2 3 4 5)
          x
               ⇒ (1 2 3 4 5)

     (setq trees '(pine oak))
          ⇒ (pine oak)
     (setq more-trees (append '(maple birch) trees))
          ⇒ (maple birch pine oak)

很有用的链表操作函数 setcdr setcar   last



***** buffer相关
用于切换buffer中的位置
goto-char  
          (setq x '(1 2 3 4))
               ⇒ (1 2 3 4)
          (reverse x)
               ⇒ (4 3 2 1)
          x
               ⇒ (1 2 3 4)

获取当前位置
(postion)

取buffer中的内容
(thing-at-point 'line)  (thing-at-point 'word)
((buffer-substring-no-properties  begin-pos  end-pos)


创建buffer
get-buffer-create 
generate-new-buffer 


返回当前buffer的名字
current-buffer
切换至某一个buffer
 set-buffer 
显示某个buffer
switch-to-buffer 




     
*** pymacs
**** 安装
如下文章都不是很好，建议直接看pymacs的官方网站：[[http://pymacs.progiciels-bpi.ca]]
1. 文章一
安装pymacs.py：
运行sudo python setup.py install
在命令行运行python，输入from Pymacs import lisp，然后回车，没有出错信息就表示pymacs.py安装成功了。

安装pymacs.el：
sudo cp pymacs.el /usr/local/share/emacs/site-lisp
（我的emacs是自己编译安装的，所以在/usr/local下）

编辑自己的.emacs文件，加入下面几行：
(autoload 'pymacs-apply "pymacs")
(autoload 'pymacs-call "pymacs")
(autoload 'pymacs-eval "pymacs" nil t)
(autoload 'pymacs-exec "pymacs" nil t)
(autoload 'pymacs-load "pymacs" nil t)
;;(eval-after-load "pymacs"
;;  '(add-to-list 'pymacs-load-path YOUR-PYMACS-DIRECTORY))
最后被注释掉的这两行，是为pymacs-load加载python模块设置搜索路径的。
eval-after-load表示pymacs.el被emacs加载后才设置这个路径。

2. 文章二
Emacs中安装pymacs和pycomplete的方法
2010-01-07 13:03
下载pymacs，解压到任意一个目录中，ubuntu和windows均在命令提示符里:
python setup.py install
这里涉及查看PYTHONPATH环境变量的问题:
打开python命令行解释器，依次输入：
>>>import sys
>>>sys.path
pymacs:
windows下安装在C:\\Python26\\lib\\site-packages(记住)中
ubuntu下需要注意：
python环境变量：
['', '/usr/lib/python2.6', '/usr/lib/python2.6/plat-linux2', '/usr/lib/python2.6/lib-tk', '/usr/lib/python2.6/lib-old', '/usr/lib/python2.6/lib-dynload', '/usr/lib/python2.6/dist-packages', '/usr/lib/python2.6/dist-packages/PIL', '/usr/lib/python2.6/dist-packages/gst-0.10', '/usr/lib/pymodules/python2.6', '/usr/lib/python2.6/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.6/gtk-2.0', '/usr/local/lib/python2.6/dist-packages']
我的pymacs默认安装在/usr/local/lib/python2.6/dist-packages中（记住),其他自行查找！！！
emacs中：
(autoload 'pymacs-apply "pymacs")
(autoload 'pymacs-call "pymacs")
(autoload 'pymacs-eval "pymacs" nil t)
(autoload 'pymacs-exec "pymacs" nil t)
(autoload 'pymacs-load "pymacs" nil t)
最后把pymacs.el放到emacs的插件目录里，安装完毕！
然后安装
pycomplete
安装方法：
1.拷贝 python-mode.el and pycomplete.el 到Emacs的load_path中。
2.拷贝 pycomplete.py 到PYTHONPATH
这里需要注意的就是上边的路径，其他系统自行查找：
windows:
C:\\Python26\\lib\\site-packages
ubuntu：
/usr/local/lib/python2.6/dist-packages
3..emacs中添加：
(require 'pymacs)
(require 'pycomplete)
一定要记住把pycomplete.py放在和pymacs安装目录相同的目录中。



*** org
**** 安装
从官网上面下载org的zip包，
在某个目录下解压，如  c:/software_green/org-7.5
然后在.emacs中增加如下配置：
;;org-mode
(add-to-list 'load-path "C:/software_green/org-7.5")
(require 'org)
(add-to-list 'auto-mode-alist '("\\.org$" . org-mode))
(define-key global-map "\C-cl" 'org-store-link)
(define-key global-map "\C-ca" 'org-agenda)
(setq org-log-done t)
**** 设置
***** 换行
 (add-hook 'org-mode-hook (lambda () (setq truncate-lines nil)))

**** 如何导出成网页形式
c-c c-e  h

*** emacs code-browser
可以参考 http://ecb.sourceforge.net/ 里面有非常详细的说明

**** 安装
emerge  app-emacs/ecb

然后再.emacs 中增加如下代码
;;CEDET
(load-file "/usr/share/emacs/site-lisp/cedet/common/cedet.el")
(global-ede-mode 1)                      ; Enable the Project management system
(semantic-load-enable-code-helpers)      ; Enable prototype help and smart completion
(global-srecode-minor-mode 1)            ; Enable template insertion menu

;;emacs code-browser
(add-to-list 'load-path "/usr/share/emacs/site-lisp/ecb")
(require 'ecb-autoloads)



*** 如何配置、常用命令
**** .emacs文件的位置
**** 修改默认路径
解决方案1：添加(cd "C:/Users/Name/Desktop")到。emacs文件
解决方案2：添加(setq default-directory "C:/Documents and Settings/USER NAME/Desktop/" )到。emacs文件
解决方案3：右键单击emacs的捷径，打属性和更改字段开始到所需的目录
**** 如何用命令打开文件
(find-file "...")
**** 如何加载elisp脚本
(load "...")

**** 自定义键的两种方法
;;(global-set-key (read-kbd-macro "C-;") 'search-any)
;;(global-set-key (read-kbd-macro "C-'") 'res-ret)
(global-set-key [M-f11] 'search-any)
(global-set-key [M-f12] 'ret-res)

**** 目前我的emacs的配置
目前emacs我的配置

;;(setq c-basic-offset 4)
;;缩进
(setq tab-width 4)
(setq indent-tabs-mod nil)

;;搜索
(add-to-list 'load-path "~/.emacs.d/")
(load "search_extend.el")
;;(global-set-key (read-kbd-macro "C-;") 'search-any)
;;(global-set-key (read-kbd-macro "C-'") 'search-extend-any-ret)
(global-set-key [M-f11] 'search-extend-any)
(global-set-key [M-f12] 'search-extend-any-ret)


;;org-mode
(add-to-list 'load-path "D:\software\org-7.4")
(require 'org)
(add-to-list 'auto-mode-alist '("\\.org$" . org-mode))
(define-key global-map "\C-cl" 'org-store-link)
(define-key global-map "\C-ca" 'org-agenda)
(setq org-log-done t)

**** color-theme
在网上下载color-theme-6.6.0.zip ， 下载网址http://download.csdn.net/source/691147#acomment
将该包解压在~/.emacs.d/site/color-theme目录下面
在.emacs中增加如下代码
(add-to-list 'load-path "~/.emacs.d/site/color-theme")  ;;在加载目录中增加color-theme所在的目录
(require 'color-theme)  ;;加载color-theme.el
(color-theme-initialize)  ;;初始化color-theme模块
(color-theme-jonadabian)  ;;将配色设置为我喜欢的jonadabian
重启emacs就会发现配色方案已经切换到jonadabian


**** 如何影藏menu-bar 和 tool-bar
(menu-bar-mode)
(tool-bar-mode)
这两个命令执行一次就会隐藏menu和tool，在执行又会使他们出来

**** 网络上的好用配置
哈哈，昨天才搞好一份自己用的
;;author:Logic0
;;time:2009-7-27


;;启动窗口最大化
;;(setq default-frame-alist
;;'(
;;(top . 0)
;;(left . 0)
;;(height . 67)
;;(width . 138)
;;))

(fset 'yes-or-no-p 'y-or-n-p)
(display-time)
(transient-mark-mode t)
(show-paren-mode t)

;;隐藏工具条
(tool-bar-mode -1)
;;显示在右边
(set-scroll-bar-mode 'right)
;;不要临时文件
(setq-default make-backup-files nil)



(setq inhibit-startup-message t)
(setq default-major-mode 'text-mode)
(mouse-avoidance-mode 'animate)
(setq frame-title-format "emacs@%b")
(auto-image-file-mode)
(global-font-lock-mode t)
(put 'set-goal-column 'disabled nil)
(put 'narrow-to-region 'disabled nil)
(put 'upcase-region 'disabled nil)
(put 'downcase-region 'disabled nil)
(put 'LaTeX-hide-environment 'disabled nil)

(show-paren-mode t)
(setq show-paren-style 'parentheses)
(require 'ido)
(ido-mode t)
(setq ido-save-directory-list-file nil)
(require 'recentf)
(recentf-mode t)

;;括号匹配
(global-set-key "%" 'match-paren)
(defun match-paren (arg)
"Go to the matching paren if on a paren; otherwise insert %."
(interactive "p")
(cond ((looking-at "\\s\(") (forward-list 1) (backward-char 1))
((looking-at "\\s\)") (forward-char 1) (backward-list 1))
(t (self-insert-command (or arg 1)))))
;;vim中fx的替代品
(defun wy-go-to-char (n char)
"Move forward to Nth occurence of CHAR.
Typing `wy-go-to-char-key' again will move forwad to the next Nth
occurence of CHAR."
(interactive "p\ncGo to char: ")
(search-forward (string char) nil nil n)
(while (char-equal (read-char)
char)
(search-forward (string char) nil nil n))
(setq unread-command-events (list last-input-event)))
(define-key global-map (kbd "C-c a") 'wy-go-to-char)

;;主题选择
(require 'color-theme)

;;(color-theme-dark-blue)
(color-theme-blue-mood)
;;(color-theme-sitaramv-solaris)

;;设置编码格式
(prefer-coding-system 'utf-8)
;;设置字体
(create-fontset-from-fontset-spec
"-adobe-courier-medium-r-*-*-14-*-*-*-*-*-fontset-ifree,
chinese-gb2312:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1,\
chinese-gbk:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1,\
chinese-gb18030:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1,\
chinese-cns11643-5:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1,\
chinese-cns11643-6:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1,\
chinese-cns11643-7:-wenquanyi-wenquanyi bitmap song-medium-r-*-*-15-*-*-*-*-*-iso10646-1")
(set-default-font "fontset-ifree")
(add-to-list 'after-make-frame-functions
(lambda (new-frame) (select-frame new-frame)
(set-default-font "fontset-ifree")))

;;使用cedet工具
;;(add-to-list 'load-path
;;"/usr/local/share/emacs/site-lisp/cedet-1.0pre3")
;;(load-file "/usr/local/share/emacs/site-lisp/cedet-1.0pre3/common/cedet.el")
;;(semantic-load-enable-code-helpers)

;;using ecb
(add-to-list 'load-path
"/usr/local/share/emacs/site-lisp/ecb-snap")
(require 'ecb)

(setq track-eol t)
;; 当光标在行尾上下移动的时候，始终保持在行尾。

(setq Man-notify-method 'pushy)
;; 当浏览 man page 时，直接跳转到 man buffer。

(setq-default kill-whole-line t)
;; 在行首 C-k 时，同时删除该行。



(custom-set-variables
  ;; custom-set-variables was added by Custom.
  ;; If you edit it by hand, you could mess it up, so be careful.
  ;; Your init file should contain only one such instance.
  ;; If there is more than one, they won't work right.
 '(display-time-mode t)
 '(ecb-options-version "2.33beta1")
 '(ecb-tip-of-the-day nil)
 '(ecb-tree-indent 1)
 '(ecb-tree-truncate-lines nil)
 '(ecb-truncate-long-names t)
 '(show-paren-mode t))

(custom-set-faces
  ;; custom-set-faces was added by Custom.
  ;; If you edit it by hand, you could mess it up, so be careful.
  ;; Your init file should contain only one such instance.
  ;; If there is more than one, they won't work right.
 '(default ((t (:inherit nil :stipple nil :background "DodgerBlue4" :foreground "white smoke" :inverse-video nil :box nil :strike-through nil :overline nil :underline nil :slant normal :weight normal :height 109 :width normal :foundry "apple" :family "Monaco")))))

(setq truncate-partial-width-windows nil)

(require 'xcscope)


;;有关c语言编程方面的设置
;;;; CC-mode配置 http://cc-mode.sourceforge.net/
(require 'cc-mode)
(c-set-offset 'inline-open 0)
(c-set-offset 'friend '-)
(c-set-offset 'substatement-open 0)

;;;我的C/C++语言编辑策略
(defun my-c-indent-setup()
  (setq c-basic-offset 4)
  (setq indent-tabs-mode nil))
(add-hook 'c-mode-hook 'my-c-indent-setup)
(defun my-c-mode-common-hook()
(setq tab-width 4 indent-tabs-mode t)
;;; hungry-delete and auto-newline
(c-toggle-auto-hungry-state 1)
;;按键定义
(define-key c-mode-base-map [(control \`)] 'hs-toggle-hiding)
(define-key c-mode-base-map [(return)] 'newline-and-indent)
(define-key c-mode-base-map [(f7)] 'compile)
(define-key c-mode-base-map [(meta \`)] 'c-indent-command)
;; (define-key c-mode-base-map [(tab)] 'hippie-expand)
;;(define-key c-mode-base-map [(tab)] 'my-indent-or-complete)
(define-key c-mode-base-map [(meta ?/)] 'semantic-ia-complete-symbol-menu)

;;预处理设置
(setq c-macro-shrink-window-flag t)
(setq c-macro-preprocessor "cpp")
(setq c-macro-cppflags " ")
(setq c-macro-prompt-flag t)
(setq hs-minor-mode t)
(setq abbrev-mode t)
)
(add-hook 'c-mode-common-hook 'my-c-mode-common-hook)

;;;;我的C++语言编辑策略
(defun my-c++-mode-hook()
(setq tab-width 4 indent-tabs-mode t)
(c-set-style "stroustrup")
;; (define-key c++-mode-map [f3] 'replace-regexp)
)

;;配置semantic检索的范围
(setq semanticdb-project-roots
(list
(expand-file-name "/")))

(defun my-indent-or-complete ()
(interactive)
(if (looking-at "\\>")
(hippie-expand nil)
(indent-for-tab-command))
)

(global-set-key [(control tab)] 'my-indent-or-complete)

(autoload 'senator-try-expand-semantic "senator")

(setq hippie-expand-try-functions-list
'(
senator-try-expand-semantic
try-expand-dabbrev
try-expand-dabbrev-visible
try-expand-dabbrev-all-buffers
try-expand-dabbrev-from-kill
try-expand-list
try-expand-list-all-buffers
try-expand-line
try-expand-line-all-buffers
try-complete-file-name-partially
try-complete-file-name
try-expand-whole-kill
)
)
(defun eshell/clear ()
"04Dec2001 - sailor, to clear the eshell buffer."
(interactive)
(let ((inhibit-read-only t))
(erase-buffer)))

;;加入对auctex以方便对latex文件的编辑
(load "auctex.el" nil t t)
(setq TeX-auto-save t)
(setq TeX-parse-self t)
(setq-default TeX-master nil)

有几个插件，ecb,autex,color-theme,cedet等,直接apt-get就可以了


**** 如何设置行号
从网站上下载 http://homepage1.nifty.com/blankspace/emacs/elisp.html  wb-line-number.el
将该文件放在 ~/.emacs.d/site目录中
在.emacs中增加如下代码：
(add-to-list 'load-path "~/.emacs.d/site/")
(set-scroll-bar-mode nil)   ; no scroll bar, even in x-window system (recommended)
(require 'wb-line-number)
(wb-line-number-toggle)

**** 如何设置临时文件生成的位置
;;设置semantic cache临时文件的路径，避免到处都是临时文件
(setq semanticdb-default-save-directory "~/.emacs.d/")


**** 如何禁用vc-git
(remove-hook 'find-file-hooks 'vc-find-file-hook)
you might need a (require 'vc) before the above line to get the timing right. Or perhaps wrap it like so:

(eval-after-load "vc" '(remove-hook 'find-file-hooks 'vc-find-file-hook))
to get the timing right.


** virsual svn
**** 备份和恢复
virsual svn的备份需要使用svnadmin.exe，这个exe文件通常在c:\Program Files\VisualSVN Server\bin目录下面
virsual svn的项目库目录通常在c:\repositories下面，
如果电脑上有一个叫做linuxdemo的项目，
则备份的方法是 svnadmin.exe dump c:\repositories\linuxdemo -r 6 > c:\wangyao\backup\linuxdemo_2012_09_30_oneversion.svn
其中c:\repositories\linuxdemo是项目的目录
-r 6是要备份的版本号   , 注意这个参数一定要要，没有这个参数就会将每一个版本都备份一遍，后续用svnadmin load的时候会出错，目前还不知道出错的原因
c:\wangyao\backup\linuxdemo_2012_09_30_oneversion.svn 是备份出来的文件

例如要拿这个备份文件恢复成一个叫做test的新项目，方法是：
svnadmin.exe load c:\repositories\test < c:\wangyao\backup\linuxdemo_2012_09_30_oneversion.svn

** VMWare
*** 安装6.5版本
1. 在win7下面下载了vmware6.5版本 vmware_652
2. 安装的时候一通next就可以了。
3. 安装后，会要求输入cdkey，从csdn上下载一个cdkey生成工具，轻松搞定。
4. 重启就安装完毕了。

*** 网络设置
使用NAT上网，要点：
1. 防火墙需关闭
2. 在主机中，wmware的NAT网络适配器需要被增加到internat网络适配器的share关系中，NAT网络适配器的ip会被配置成192.168.137.1
3. wmware需要将NAT网络平面的网关设置成192.168.137.1
4. 虚拟机的网络ip需要配置成192.168.137.X

其中第3条非常重要，不知道为什么，如果用默认的192.168.137.2虚拟机就连不上internat
但是这样设置带来的问题是一旦虚拟机充当了一次服务器后，就不能再向NAT的外边建立TCP链接了。

*** vmware tool
**** 如何在ubuntu server上面安装vmware tool
本人的ubuntu server版本是10.04.4，安装在免费的vmware player 4.0中。 安装vmware-tools需要gcc和对应的linux-headers进行编译，需先执行下面两个命令进行安装：

sudo apt-get gcc

sudo apt-get install build-essential linux-headers-$(uname -r)
安装后，点击vmware player菜单“Virtual Machine->Install VMware Tools”，画面下方会出现黄色的VMware Tools安装提示框。 1、把安装光盘绑定到一个文件夹：

mkdir /mnt/cdrom

sudo mount /dev/cdrom /mnt/cdrom
2、解压安装文件到临时目录/tmp：

cd /tmp

tar zxpf /mnt/cdrom/VMwareTools-8.0.0-.tar.gz
3、执行安装：

cd vmware-tools-distrib

sudo ./vmware-install.pl
4、之后按照安装提示，一直按Enter键确认就可以了。 5、安装后执行reboot重启：

sudo reboot

** git
*** 从svn过渡到git
**** 基本概念
服务器:
  1. 分支a
  2. 分支b

本地git目录:
  1. 本地分支     # 对应svn中.svn中的代码数据，存储在.git中，不能进行代码阅读，本地分支可以有多个
  2. 远端关联     # 对应服务器url，存储在.git中
       远端分支a  # 存储在.git中， 不能进行代码阅读
       远端分支b  # 存储在.git中   不能进行代码阅读
  3. 临时区       # 这个区svn没有，git新增出来，在代码提交至本地分支前先做一次缓冲， 不能进行代码阅读
  4. 工作区       # 实际读代码，写代码的地方

区别，git在本地可以管理很多歌分支，而svn只能是一个分支。
提交代码时：  工作区  --->  add至临时区  --->  commit至本地分支 (此时产生版本号) ---> push至远端服务器上的某个分支
更新代码时：  远端服务器 ---> fetch至远端关联  ----> merge远端关联中的一个分支至本地分支和工作区 

master分支是一个默认的主分支，建库时自然有

**** 基本操作
1. 创建一个git目录
git init    #创建一个空的git目录，建立好.git
git clone <url> + <分支信息>   #创建本地git目录，并从服务器上下载一个现成分支代码
2. 修改本地代码
修改本代码之前一定要先至少指定一个分支
git checkout master   #将本地工作区和本地默认的master分支进行关联
或者：
第一步 git branch  <分支名称>   #创建一个本地分支
第二步 git checkout <分支名称>  #将本地工作区切换至该分支管理上
3. 提交本地修改至本地分支
第一步  git add <修改的文件的名称，或者.也可以> #将工作区的修改提交至临时区
第二步  git commit   #将临时区的内容提交至本地分区
4. 和服务器建立关联关系
git remote add <远端关联名称> <url>   #在git目录上增加一个远端关联，名字可以随便起，通常大家用origin，并将这个分支和服务器url上的git目录关联
5. 将远端分支的修改更新至工作区
git fetch <远端关联>  #从服务器下载远端git目录的更新数据，仅仅下载至远端分支中，并没有merge到工作区
git merge <远端关联>/<远端分支>  #将远端关联中的一个指定分支的内容merge到工作区
6. 想服务器push本地分支的修改内容
git push <远端关联名称> <分支名称>  #将本地分支中的内容提交给远端关联中对应的分支上面，后面一节对push中分支的对应关系进行详细描述
7. 回退工作区中的修改
git checkout -- <文件名>
8. 回退临时区中的内容
git reset HEAD <文件名>  #该命令执行完之后工作区中的内容没有修改
9. 回退本地方分支中的修改
git reset --hard HEADAD^ # 回退至上一个版本
git reset --hard <版本号>   #回头至指定的版本
10. 查看当前工作区和临时区的状态，有没有没有提交的文件
git status
11. 差异比较
git diff #比较本地工作区和本地分支之间的差异
git diff <分支1>  <分支2>  #比较两个分支之间的差异
git diff <版本号> <版本号>  #比较两个版本号之间的差异
git diff -- <文件名>  #比较该文件工作区和本地分支之间的差异

**** 如何关联本地分支和远端分支
git push <远端关联> <分支名称> 这个命令可以将本地分支的内容提交到远端关联的对应分支上，那究竟将本地哪一个分支是提交到了远端哪一个分支上面去了呢？
1. 远端关联的默认分支
远端关联默认的提交分支是master，由于本地默认也是master分支，所以如果没有做什么设置，默认是提交到了远端关联的master分支上，master分支也是一个必然存在的分支，他在建库的时候就存在了。
比如 git push origin master  
就会将本地master分支的内容提交到远端master分支上。
2. 创建本地分支时关联远端分支
git checkout -b <本地分支> <远端关联>/<远端分支> 
以这种形式建立的本地分支会自动关联到指定的远端服务器的指定分支上，
如果本地分支名称和远端分支名称相同的情况下，本地分支的内容会提交到对应的远端分支上面
比如 git checkout  -b dev origin/dev
push origin dev  
就会将本地dev分支提交到远端dev分支上面
3. 如果本地分支名称和远端分支名称不一致怎么办
比如 git checkout -b dev origin/test
需要看一下.git/config 目录

*** github
**** github上面是怎么多人协作的
github怎么做到多个账号维护一个git仓呢？
首先作为一个参与者，要从主人那里fork他的一个git仓，
这样自己的主页下面也会有这个git仓了，然后在自己的git仓中进行任意修改，修改完了，点击pull request，就会把修改的内容上交到主人那里


*** git的一些错误
**** The certificate of the remote verify failed by the local system
The certificate of the remote verify failed by the local system, the git will display as below. 
There is a easy way, just export GIT_SSL_NO_VERIFY=1, to resolve this problem.
Cloning into art...
error: SSL certificate problem, verify that the CA cert is OK. Details:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed while accessing https://android.googlesource.com/platform/art/info/refs


* program
** python
*** 模块、插件和框架
**** Mechanize
+ 相关链接
官方网站 ：http://wwwsearch.sourceforge.net/mechanize/

**** scrapy
+ 相关链接
官网 http://scrapy.org/
****


**** HTTP
***** HTTPServer
@python @httpserver @cgi @server

用python来实现一个server可以这样来实现
#!/usr/bin/python

from BaseHTTPServer import HTTPServer
from CGIHTTPServer import CGIHTTPRequestHandler
serve = HTTPServer(("",8081),CGIHTTPRequestHandler)
serve.serve_forever() 


这个server调用的cgi脚本，用python可以这样来实现
#!/usr/bin/python
import cgi
print("Content-type:text/html\n")
print("hello")

form = cgi.FieldStorage()
if "name" not in form or "addr" not in form:
    print "<H1>Error</H1>"
    print "Please fill in the name and addr fields."
else:
    print "<p>name:", form["name"].value
    print "<p>addr:", form["addr"].value


这两个东西的目录组织是这样的
server code  hs.py  is in httpserver/test/

cgi script h.py is in httpserver/test/cgi-bin/

the cgi script h.py need be set to execute-able .

  /home/wyao/samba_share/httpserver/test:
  total used in directory 3316 available 49266400
  drwxr-xr-x 3 wyao wyao    4096 Jun  6 09:07 .
  drwxr-xr-x 3 wyao wyao    4096 Jun  6 08:46 ..
  drwxrwxrwx 2 wyao wyao    4096 Jun  6 09:42 cgi-bin
  -rw-r--r-- 1 wyao wyao 3365855 May 29 21:28 emacs.html
  -rwxrwxrwx 1 wyao wyao      41 Jun  6 08:51 h.py~
  -rwxr-xr-x 1 wyao wyao     180 Jun  6 08:48 hs.py
  -rwxr-xr-x 1 wyao wyao     180 Jun  6 08:47 hs.py~

wyao@wylinux:~/samba_share/httpserver$ cd test
wyao@wylinux:~/samba_share/httpserver/test/cgi-bin$ ls -al
total 28
drwxrwxrwx 2 wyao wyao 4096 Jun  6 14:58 .
drwxr-xr-x 3 wyao wyao 4096 Jun  6 09:07 ..
-rwxr-xr-x 1 wyao wyao   35 Jun  6 09:39 a.py
-rwxr-xr-x 1 wyao wyao 9926 Jun  6 14:58 h.py
-rwxr-xr-x 1 wyao wyao  319 Jun  6 09:42 h.py~
wyao@wylinux:~/samba_share/httpserver/test/cgi-bin$

***** HTTPClient
@python  @httpclient  @client


用python来实现httpclient，可以这样来实现

#!/usr/bin/python

import httplib, urllib
params = urllib.urlencode({'name': 'www', 'eggs': 2, 'addr': 'mxy'})
headers = {"Content-type": "application/x-www-form-urlencoded","Accept": "text/plain"}
conn = httplib.HTTPConnection("127.0.0.1:8081")
conn.request("POST", "/cgi-bin/h.py", params, headers)
response = conn.getresponse()
print response.status, response.reason
data = response.read()
print data
conn.close() 

**** moinmoin
+ 有用的网址
@moin  @moinmoin


http://doujiu.javaeye.com/blog/629966

http://forum.ubuntu.org.cn/viewtopic.php?t=6983 (按照这个安装的）

http://yp.oss.org.cn/software/show_resource.php?resource_id=199

http://wiki.apache.org/httpd/%E5%B8%AE%E5%8A%A9-%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E8%A1%A8#A.2BkU1.2Fbg-


http://blog.endlesscode.com/2010/01/26/moinmoin/

+ 配置文件的位置
＠moin
配置文件的位置可能在/etc/moin下的farmconfig.py

+ 我的安装配置经历
root@wyubuntu:/etc/apache2/sites-available# cd /etc
root@wyubuntu:/etc# cd /usr/share/moin
root@wyubuntu:/usr/share/moin# ls
config  data  htdocs  server  underlay
root@wyubuntu:/usr/share/moin# sudo mkdir mywiki
root@wyubuntu:/usr/share/moin# sudo cp -R data mywiki
root@wyubuntu:/usr/share/moin# sudo cp -R underlay mywiki
root@wyubuntu:/usr/share/moin# sudo cp -R server/moin.cgi mywiki
root@wyubuntu:/usr/share/moin# sudo chown -R www-data.www-data mywiki
root@wyubuntu:/usr/share/moin# sudo chmod -R ug+rwX mywiki
root@wyubuntu:/usr/share/moin# sudo chmod -R o-rwx mywiki

在/etc/apache2/sites-available/default中修改
        ### moin
        ScriptAlias /mywiki "/usr/share/moin/mywiki/moin.cgi"
        alias /wiki "/usr/share/moin/htdocs"
        alias /moin_static182/ /usr/share/moin/htdocs/
        <Directory /usr/share/moin/htdocs>
        Order allow,deny
        allow from all
        </Directory>
        ### end moin



修改/etc/moin/farmconfig.py
wikis = [

    # wikiname, url regular expression
    # ---------------------------------------------------------------
    ("mywiki", r".*")   # this is ok for a single wiki
    # for multiple wikis, do something like this:
    #("wiki1", r"^http://wiki1\.example\.org/.*$"),
    #("wiki2", r"^https?://wiki2\.example\.org/.*$"),
]


修改/etc/moin/mywiki.py 在末尾增加    
data_dir = '/usr/share/moin/mywiki/data'
data_underlay_dir = '/usr/share/moin/mywiki/underlay'



原理： apache根据/etc/apache2/sites-available/default中的配置找到moin.gui （这个位置通常在用户自己的目录下）
moin.gui会配置system路劲sys.path.insert(0, '/etc/moin')（这个路径通常在系统路径下）
然后moin.gui就会在这个路径下面找到farmconfig.py 
farmconfig.py根据wikilist里面的内容定位到mywiki.py
mywiki.py中如下配置指明wiki的具体位置
data_dir = '/usr/share/moin/mywiki/data'
data_underlay_dir = '/usr/share/moin/mywiki/underlay' （这些路径通常和moin.gui同在用户的目录下面）





	
**** pygame
http://blog.csdn.net/b2b160/archive/2009/04/08/4057586.aspx

**** pyUnit
+ 文章一
@pyUnit

http://pyunit.sourceforge.net/pyunit_cn.html#INSTALL

概况

Python单元测试框架（The Python unit testing framework），简称为PyUnit， 是Kent Beck和Erich Gamma这两位聪明的家伙所设计的 JUnit 的Python版本。 而JUnit又是Kent设计的Smalltalk测试框架的Java版本。它们都是各自语言的标准测试框架。

此文档仅阐述针对Python的单元测试PyUnit的设计与使用。如需单元测试框架基本设计的背景 信息，请查阅Kent的原始文章"Simple Smalltalk Testing: With Patterns"。

自从 Python 2.1 版本后，PyUnit成为 Python标准库的一部分。

以下内容默认您已经了解Python。我觉得Python 非常简单易学而且让人欲罢不能。
系统要求

PyUnit可以在Python 1.5.2及更高版本上运行。

作者已经在Linux（Redhat 6.0和6.1以及Debian Potato）和Python 1.5.2, 2.0和2.1上对PyUnit 进行了测试。而且PyUnit已知可以在其它操作系统平台上工作，如Windows和Mac。如果您在 任何系统平台或Python版本中遇到麻烦，请让我知道。

如需了解在JPython和Jython中使用PyUnit的细节，请阅读 在JPython和Jython中使用PyUnit部分。
使用PyUnit构建自己的测试
安装

编写测试所需的类可以在“unittest”模块中找到。此模块是Python 2.1和更高版本的标准 库的一部分。如果你在使用更早版本的Python，你应该从单独的PyUnit发布中获得此模块。

为使此模块能在你的代码中正常工作,你只需确保包含“unittest.py”文件的目录 在你的Python搜索路径中。为此，你可以修改环境变量“$PYTHONPATH”或将此文件 放入当前Python搜索路径中的某一个目录中，比如在Redhat Linux系统中的 /usr/lib/python1.5/site-packages目录。

注意，你只有完成此项工作才能运行PyUnit所自带的例子，除非你将“unittest.py”复制到 例子目录。
测试用例介绍

单元测试是由一些测试用例（Test Cases）构建组成的。测试用例是被设置用来检测正确性的 单独的场景。在PyUnit中，unittest模块中的TestCase 类代表测试用例。

TestCase类的实例是可以完全运行测试方法和可选的设置 （set-up）以及清除（tidy-up）代码的对象。

TestCase实例的测试代码必须是自包含的，换言之，它可以单独运行或与其它任意数量的测试用例共同运行。
创建一个简单测试用例

通过覆盖runTest方法即可得到最简单的测试用例子类以运行一些测试代码：

        import unittest

        class DefaultWidgetSizeTestCase(unittest.TestCase):
            def runTest(self):
                widget = Widget("The widget")
                assert widget.size() == (50,50), 'incorrect default size'
    

注意：为进行测试，我们只是使用了Python内建的“assert”语句。如果在测试用例运行时断言（assertion）为假，AssertionError异常会被抛出，并且测试框架会认为测试用例失败。其它非“assert”检查所抛出的异常会被测试框架认为是“errors”。（参见"更多关于测试条件"）

运行测试用例的方法会在后面介绍。现在我们只是通过调用无参数的构造器（constructor）来创建一个测试用例的实例：

        testCase = DefaultWidgetSizeTestCase()
    

复用设置代码：创建固件

现在，这样的测试用例数量巨大且它们的设置需要很多重复性工作。在上面的测试用例中，如若在100个Widget测试用例的每一个子类中都创建一个“Widget”，那会导致难看的重复。

幸运的是，我们可以将这些设置代码提取出来并放置在一个叫做setUp的钩子方法（hook method）中。测试框架会在运行测试时自动调用此方法：

        import unittest

        class SimpleWidgetTestCase(unittest.TestCase):
            def setUp(self):
                self.widget = Widget("The widget")

        class DefaultWidgetSizeTestCase(SimpleWidgetTestCase):
            def runTest(self):
                assert self.widget.size() == (50,50), 'incorrect default size'

        class WidgetResizeTestCase(SimpleWidgetTestCase):
            def runTest(self):
                self.widget.resize(100,150)
                assert self.widget.size() == (100,150), \
                       'wrong size after resize'
    

如果setUp方法在测试运行时抛出异常，框架会认为测试遇到了错误并且 runTest不会被执行。

类似的，我们也可以提供一个tearDown方法来完成在runTest运行之后的清理工作：

        import unittest

        class SimpleWidgetTestCase(unittest.TestCase):
            def setUp(self):
                self.widget = Widget("The widget")
            def tearDown(self):
                self.widget.dispose()
                self.widget = None
    

如果setUp执行成功， 那么无论runTest是否成功，tearDown方法都将被执行。

Such a working environment for the testing code is termed a fixture. 这个测试代码的运行环境被称为固件(fixture，译者注：此为暂定译法，意为固定的构件或方法)。
包含多个测试方法的测试用例类

很多小型测试用例经常会使用相同的固件。在这个用例中，我们最终从SimpleWidgetTestCase继承产生很多仅包含一个方法的类，如 DefaultWidgetSizeTestCase。这是很耗时且不被鼓励的，因此，沿用JUnit的风格，PyUnit提供了一个更简便的方法：

        import unittest

        class WidgetTestCase(unittest.TestCase):
            def setUp(self):
                self.widget = Widget("The widget")
            def tearDown(self):
                self.widget.dispose()
                self.widget = None
            def testDefaultSize(self):
                assert self.widget.size() == (50,50), 'incorrect default size'
            def testResize(self):
                self.widget.resize(100,150)
                assert self.widget.size() == (100,150), \
                       'wrong size after resize'
    

在这个用例中，我们没有提供runTest方法，而是两个不同的测试方法。类实例将创建和销毁各自的self.widget并运行某一个test方法。当创建类实例时，我们必须通过向构造器传递方法的名称来指明哪个测试方法将被运行：

        defaultSizeTestCase = WidgetTestCase("testDefaultSize")
        resizeTestCase = WidgetTestCase("testResize")
    

将测试用例聚合成测试套件

测试用例实例可以根据它们所测试的特性组合到一起。PyUnit为此提供了一个机制叫做”测试套件“（test suite)。它由unittest模块中的TestSuite类表示：

        widgetTestSuite = unittest.TestSuite()
        widgetTestSuite.addTest(WidgetTestCase("testDefaultSize"))
        widgetTestSuite.addTest(WidgetTestCase("testResize"))
    

我们稍后会看到，在每个测试模块中提供一个返回已创建测试套件的可调用对象，会是一个使测试更加便捷的好方法：

       def suite():
           suite = unittest.TestSuite()
           suite.addTest(WidgetTestCase("testDefaultSize"))
           suite.addTest(WidgetTestCase("testResize"))
           return suite
    

甚至可写成:

       class WidgetTestSuite(unittest.TestSuite):
           def __init__(self):
               unittest.TestSuite.__init__(self,map(WidgetTestCase,
                                                     ("testDefaultSize",
                                                      "testResize")))
    

(诚然，第二种方法不是为胆小者准备的)

因为创建一个包含很多相似名称的测试方法的TestCase子类是一种很常见的模式，所以unittest模块提供一个便捷方法，makeSuite，来创建一个由测试用例类内所有测试用例组成的测试套件：

       suite = unittest.makeSuite(WidgetTestCase,'test')
    

需要注意的是，当使用makeSuite方法时，测试套件运行每个测试用例的顺序是由测试方法名根据Python内建函数cmp所排序的顺序而决定的。
嵌套测试套件

我们经常希望将一些测试套件组合在一起来一次性的测试整个系统。这很简单，因为多个TestSuite可以被加入进另一个TestSuite，就如同多个TestCase被加进一个TestSuite中一样：

       suite1 = module1.TheTestSuite()
       suite2 = module2.TheTestSuite()
       alltests = unittest.TestSuite((suite1, suite2))
    

在发布的软件包中的“examples”目录中，"alltests.py”提供了使用嵌套测试套件的例子
测试代码放置位置

你可以将测试用例定义与被测试代码置于同一个模块中（例如“widget.py”），但是将测试代码放置在单独的模块中（如“widgettests.py”）会有一些优势：

    测试模块可以从命令行单独执行
    测试代码可以方便地从发布代码中分离
    少了在缺乏充足理由的情况下为适应被测试代码而更改测试代码的诱惑
    相对于被测试代码，测试代码不应该被频繁的修改
    被测试代码可以更方法的进行重构
    既然C语言代码的测试应该置于单独的模块，那何不保持这个一致性呢？
    如果测试策略改变，也无需修改被测试源代码 

交互式运行测试

我们编写测试的主要目的是运行它们并检查我们的软件是否工作正常。测试框架使用“TestRunner”类来为运行测试提供环境。最常用的TestRunner是TextTestRunner，它可以以文字方式运行测试并报告结果：

        runner = unittest.TextTestRunner()
        runner.run(widgetTestSuite)
    

TextTestRunner默认将输出发送到sys.stderr，但是你可以通过向它的构造器传递一个不同的类似文件（file-object）对象来改变默认方式。

如需在Python解释器会话中运行测试，这样使用TextTestRunner是一个理想的方法。
从命令行运行测试

unittest模块包含一个main方法，可以方便地将测试模块转变为可以运行测试的脚本。main 使用unittest.TestLoader类来自动查找和加载模块内测试用例。

因此，如果你之前已经使用test*惯例对测试方法进行命名，那么你就可以将以下代码插入测试模块的结尾：

        if __name__ == "__main__":
            unittest.main()
    

这样，当你从命令行执行你的测试模块时，其所包含的所有测试都将被运行。使用“-h”选项运行模块可以查看所有可用的选项。

如需从命令行运行任意测试，你可以将unittest模块作为脚本运行，并将所需执行的测试套件中的测试用例名称作为参数传递给此脚本：

        % python unittest.py widgettests.WidgetTestSuite
    

or

        % python unittest.py widgettests.makeWidgetTestSuite
    

你还可以在命令行指明特定的测试（方法）来执行。如要运行“listtests”模块中的TestCase类的子类 'ListTestCase'（参见发布软件包中的“examples”子目录），你可以执行以下命令：

        % python unittest.py listtests.ListTestCase.testAppend
    

“testAppend”是测试用例实例将要执行的测试方法的名称。你可以执行以下代码来创建ListTestCase类实例并执行其所包含的所有“test*”测试方法：

        % python unittest.py listtests.ListTestCase
    

在用户界面窗口运行测试

你还可以使用图形化窗口运行你的测试。它是用Tkinter编写的。在多数平台上，这个窗口工具与Python是捆绑在一起发布的。它看上去和JUnit窗口很相似。

你只需运行以下命令来使用测试运行窗口：

        % python unittestgui.py
    

or

        % python unittestgui.py widgettests.WidgetTestSuite
    

这里需要注意的是，所输入的测试名称必须是一个可以返回TestCase或TestSuite类实例的对象名称，不可以是事先创建好的测试名称，因为每个测试必须在每次运行是重新创建。

使用窗口测试会因为更新那些窗口而带来额外的时间开销。在我系统上，每一千个测试，它会多花七秒钟。你的消耗可能会不同。
为测试编写文档

通常当测试运行时，TestRunner将显示其名称。这个名称是由测试用例类名和所运行的测试方法名组成的。

但是如果你为测试方法提供了doc-string，则当测试运行时，doc-string的第一行将被显示出来。这为编写测试文档提供了一个很便捷的机制：

        class WidgetTestCase(unittest.TestCase):
            def testDefaultSize(self):
                """Check that widgets are created with correct default size"""
                assert self.widget.size() == (50,50), 'incorrect default size'
    

更多关于测试条件

我之前建议过应使用Python内建断言机制来检查测试用例中的条件，而不应使用自己编写的替代品，因为assert更简单，简明且为大家所熟悉。

但是值得注意的是，如果在运行测试的同时Python优化选项被打开（生成“.pyo"字节码文件），那么assert语句将会被跳过，使得测试用例变得无用。

我为那些需要使用Python优化选项的用户编写了一个assert_方法并添加进TestCase类内。它的功能和内建的assert相同且不会被优化删除，但是使用较麻烦且所输出错误信息帮助较小：

        def runTest(self):
            self.assert_(self.widget.size() == (100,100), "size is wrong")
    

我还在TestCase类中提供了failIf和failUnless两个方法：

        def runTest(self):
            self.failIf(self.widget.size() <> (100,100))
    

测试方法还可以通过调用fail方法使得测试立即失败：

        def runTest(self):
            ...
            if not hasattr(something, "blah"):
                self.fail("blah missing")
                # or just 'self.fail()'
    

测试相等性

最常用的断言是测试相等性。如果断言失败，开发者通常希望看到实际错误值。

TestCase包含一对方法assertEqual和assertNotEqual用于此目的（如果你喜欢，你还可以使用别名：failUnlessEqual 和 failIfEqual）：

        def testSomething(self):
            self.widget.resize(100,100)
            self.assertEqual(self.widget.size, (100,100))
    

测试异常

测试经常希望检查在某个环境中是否出现异常。如果期待的异常没有抛出，测试将失败。这很容易做到：

        def runTest(self):
            try:
                self.widget.resize(-1,-1)
            except ValueError:
                pass
            else:
                fail("expected a ValueError")
    

通常，预期异常源（译者注：将抛出异常的代码）是一个可调用对象；为此，TestCase有一个assertRaises方法。此方法的前两个参数是应该出现在“except”语句中的异常和可调用对象。剩余的参数是应该传递给可调用对象的参数。

        def runTest(self):
            self.assertRaises(ValueError, self.widget.resize, -1, -1)
    

通过PyUnit复用旧测试代码

一些用户希望将已有的测试代码不需转变为TestCase子类而直接从PyUnit中运行。

为此，PyUnit提供了一个FunctionTestCase类。这个TestCase子类可以用来包装已有测试函数。设置和清理函数也可以选择性地被包装。

对于以下测试函数：

        def testSomething():
            something = makeSomething()
            assert something.name is not None
            ...
    

我们可以创建一个等同的测试用例实例：

        testcase = unittest.FunctionTestCase(testSomething)
    

如果有附加的设置和清理方法需要由测试用例调用，可以如下操作：

        testcase = unittest.FunctionTestCase(testSomething,
                                             setUp=makeSomethingDB,
                                             tearDown=deleteSomethingDB)
    

在JPython和Jython中使用PyUnit

虽然PyUnit主要是为“C” Python所编写，你仍然可以用Jython编写PyUnit测试，来测试你的Java或Jython软件。这比用Jython编写JUnit测试更可取。PyUnit也可以正确的与Jython前期版本，Jython 1.0和1.1协同工作。

当然，Java不包含TK GUI接口，所以PyUnit的基于TKinter的GUI是不能在Jython下工作的，但是基于文本的接口是可以正常工作的。

要在Jython中使用PyUnit的文本接口，只需简单的将标准C Python库模块文件‘traceback.py', 'linecache.py', 'stat.py' 和 'getopt.py'复制到可以被JPython引用到的位置上。你可以在任何C Python发布版中找到这些文件。（这是针对C Python 1.5.x版本的标准库，可能对其它版本Python不适用）

现在你完全可以像在C Python中那样编写你的PyUnit测试了。
注意事项
断言

参见 "更多关于测试条件" 部分所述注意事项。
内存使用

当异常在测试套件运行过程中被抛出时，因此产生的追溯（traceback）对象将被保存，以使失败信息可以在测试运行结束后被格式化输出。除了简便性，这样做的另一个优点就是未来的GUI TestRunner可以在后期查看保存在追溯对象中的本地和全局变量。

一个可能的副作用就是，当运行一个失败频率很高的测试套件时，为保存所有这些追溯对象而需要的内存使用量将成为一个问题。当然，如果很多测试是失败的，内存的消耗也只是你的问题中最微不足道的一个。
使用条款

你可以依据Python所使用的自由条款来自由的使用，更改和重新发布此软件。我只要求我的名字，email地址和项目URL保留在代码和随行文档中，给予我作为原作者的尊重。

我编写此软件的初衷是为改进世界上软件质量而贡献微薄之力；我不求金钱回报。（这不是说我不欢迎赞助）
未来计划

一个关键的未来计划是将TK GUI和IDLE IDE整合在一起，欢迎加入！

除此之外，我没有要扩展此模块功能的庞大计划。我使PyUnit尽可能的简单（希望不能再简单了）因为我相信一些常用的辅助性的模块，比如日志文件比较，最好还是由测试编写者自行编写。
更新与社区

新闻，更新以及更多信息可以在项目网站获得。

欢迎各种评论，建议和错误报告；只需给我发送电子邮件或者这个非常小量的邮件列表并发表你的评论。现在有大量的PyUnit使用者，他们都有智慧与大家分享。
鸣谢

Many thanks to Guido and his disciples for the Python language. In tribute, I have written the following haiku (or 'pyku', if you will):

    Guido van Rossum
    'Gawky Dutchman' gave birth to
    Beautiful Python 

I gratefully acknowledge the work of Kent Beck and Erich Gamma for their work on JUnit, which made the design of PyUnit a no-brainer.

Thanks also to Tim Voght; I discovered after I had implemented PyUnit that he had also implemented a 'pyunit' module as part of his 'PyWiki' WikiWikiWeb clone. He graciously gave me the go-ahead to submit my version to the community at large.

Many thanks to those who have written to me with suggestions and questions. I've tried to add appropriate credits in the CHANGES file in the download package.

Particular thanks to J¨鑽鑪e Marant, who packaged PyUnit for Debian. 

**** struct
struct的pack和unpack对应的类型
[[./pic/20110507_01.jpg]]

**** gc
如果想处理一些垃圾回收方面的python的事物。可以考虑使用gc这个模块

*** 通过UDP传递文件
使用一个简单的python脚本将一个本地文件以码流的形式，通过UDP协议发送到对端：
import socket
import os
import stat
import struct

MAX_PACK_SIZE = 100
DEST_IP = 'localhost'
DEST_PORT = 17800

filename = raw_input("input filename")

filesize = os.stat(filename)[stat.ST_SIZE]

f = open(filename, "rb")

chList = []
for i in range(0, filesize):
    (ch,) = struct.unpack("B", f.read(1))
    chList.append(ch)

client = socket.socket( socket.AF_INET, socket.SOCK_DGRAM )

packSize = 0
string = ""
args = []
for i in range(0, filesize):
    packSize = packSize + 1
    string = string + struct.pack("B", chList[i])
    if (MAX_PACK_SIZE == packSize or i == filesize - 1):
        client.sendto(string, (DEST_IP, DEST_PORT))
        packSize = 0
        string = ""
client.close()

使用到的知识点：
1、UDP客户端最简单的实现:
client = socket.socket( socket.AF_INET, socket.SOCK_DGRAM )
client.sendto(string, (DEST_IP, DEST_PORT))
client.close()

2、python中对码流的操作：struct.pack 和 struct.unpack的使用
(ch,) = struct.unpack("B", f.read(1))
string = string + struct.pack("B", chList[i])

3、二进制文件的读取：
f = open(filename, "rb")

4、获得系统中某个文件的字节数
filesize = os.stat(filename)[stat.ST_SIZE]




*** 如何获得命令行参数
sys.argv[1]  sys.argv[2] 就这么简单
*** 如何运行linux的命令或者其他进程或者脚本
**** os.popen(commond , mod , bufsize)
这个命令的mod是'w'或者'r'，不能同时是'wr'
返回值是一个file，可以read或者write
**** os.popen2(command , mod , bufsize)
这个命令的mod可以使'wr'，
返回值是一个file的list，
如p = os.popen2('sudo ifconfig', mod, bufsize)
p[0]是command的标准输入，可以p[0].write("lalala")
p[1]是command的标准输出，可以p[1].read()
**** os.popen3(command, mod, bufsize)
和os.popen2一样，不过返回值多了一个p[2]，对应command的标准错误信息，可以p[2].read()，很有用


*** 如何解析html
**** 编码转换的问题
     通过urlopen和read结合，获取的html文件不一定是普通的string编码格式，可能是utf-8或者gb的编码格式，
        fp = urllib2.urlopen(url)
        orihtml = fp.read()
     如果不是普通的string的编码格式，那么后续在html文件中查找诸如"中文"，就会查找不到，
        orihtml.find("股票")，这样查找，是找不到结果的，即便网页中存在““股票”这两个汉字
     而如果使用orihtml.find(u"股票")的方法来进行查找，就会出现异常，python会抛出异常。
     解决方法是使用如下代码，将orihtml解成unicode编码格式
        try:
            html = orihtml.decode('utf-8')
            html.find(u"编码")
        except:
            try:
                html = orihtml.decode('gb2312')
                html.find(u"编码")
            except:
                try:
                    html = orihtml.decode('gb18030')
                    html.find(u"编码")
                except:
                    continue
     然后就可以用html.find(u"股票")的方式来进行解码了。

**** beautifulsoup
寻找所有连接的方法
def grepHrefFromHtml(html):
    soup = BeautifulSoup(html)
    a_list = soup.findAll('a')
    hrefs = []
    for a in a_list:
        try:
            hrefs.append(a['href'])
        except:
            continue
    return hrefs


**** chardet
可以使用detectRes这个库来识别html的编码方式,chardet.detect(str)这个函数会返回一个dict，，其中的'encode'这一项就对应的编码方式
    detectRes = chardet.detect(orihtml)
    print detectRes
    html = orihtml.decode(detectRes['encoding'], 'ignore')
    return html


** cpp/c
*** expat
其中值得一提的是demoloaderxml.c使用了expat这个库，
expat是一个经典的基于c的轻量级xml解析器。
demoloader主要使用的接口如下：
    //将xml读入到pBuff中
    iRes = loadXmlFileAndCreateBuffer("./democase.xml",
                               &pBuff,
                               &len);
    //创建解析器
    XML_Parser p = XML_ParserCreate(NULL);
  
    //在解析器上设置回调函数，
    XML_SetUserData(p, pTmpData);
    XML_SetCharacterDataHandler(p, dataHandle);
    XML_SetElementHandler(p, start, end);


    //进行解析，解析过程中调用回调函数
    XML_Parse(p, pBuff, len, done) == XML_STATUS_ERROR)
    
    //解析完成，释放资源
    XML_ParserFree(p);
    unloadXmlFileAndDestroyBuffer(&pBuff);



*** cppunit
+ 文章一
@cppunit

2003 年 8 月 03 日

本文从开发人员的角度，介绍 CppUnit 框架，希望能够使开发人员用最少的代价尽快掌握这种技术。下面从基本原理，CppUnit 原理，手动使用步骤，通常使用步骤，其他实际问题等方面进行讨论。以下讨论基于 CppUnit1.8.0。
背景

CppUnit 是个基于 LGPL 的开源项目，最初版本移植自 JUnit，是一个非常优秀的开源测试框架。CppUnit 和 JUnit 一样主要思想来源于极限编程（XProgramming）。主要功能就是对单元测试进行管理，并可进行自动化测试。这样描述可能没有让您体会到测试框架的强大威力，那您在开发过程中遇到下列问题吗？如果答案是肯定的，就应该学习使用这种技术：

测试代码没有很好地维护而废弃，再次需要测试时还需要重写； 
投入太多的精力，找 bug，而新的代码仍然会出现类似 bug； 
写完代码，心里没底，是否有大量 bug 等待自己； 
新修改的代码不知道是否影响其他部分代码； 
由于牵扯太多，导致不敢进行修改代码； 
... 
这些问题下文都会涉及。这个功能强大的测试框架在国内的 C++ 语言开发人员中使用的不是很多。本文从开发人员的角度，介绍这个框架，希望能够使开发人员用最少的代价尽快掌握这种技术。下面从基本原理，CppUnit 原理，手动使用步骤，通常使用步骤，其他实际问题等方面进行讨论。以下讨论基于 CppUnit1.8.0。

一、 基本原理

对于上面的问题仅仅说明 CppUnit 的使用是没有效果的，下面先从测试的目的，测试原则等方面简要说明，然后介绍 CppUnit 的具体使用。

首先要明确我们写测试代码的目的，就是验证代码的正确性或者调试 bug。这样写测试代码时就有了针对性，对那些容易出错的，易变的编写测试代码；而不用对每个细节，每个功能编写测试代码，当然除非有过量精力或者可靠性要求。

编码和测试的关系是密不可分的，推荐的开发过程并不要等编写完所有或者很多的代码后再进行测试，而是在完成一部分代码，比如一个函数，之后立刻编写测试代码进行验证。然后再写一些代码，再写测试。每次测试对所有以前的测试都进行一遍。这样做的优点就是，写完代码，也基本测试完一遍，心里对代码有信心。而且在写新代码时不断地测试老代码，对其他部分代码的影响能够迅速发现、定位。不断编码测试的过程也就是对测试代码维护的过程，以便测试代码一直是有效的。有了各个部分测试代码的保证，有了自动测试的机制，更改以前的代码没有什么顾虑了。在极限编程（一种软件开发思想）中，甚至强调先写测试代码，然后编写符合测试代码的代码，进而完成整个软件。

根据上面说的目的、思想，下面总结一下平时开发过程中单元测试的原则：

先写测试代码，然后编写符合测试的代码。至少做到完成部分代码后，完成对应的测试代码； 
测试代码不需要覆盖所有的细节，但应该对所有主要的功能和可能出错的地方有相应的测试用例； 
发现 bug，首先编写对应的测试用例，然后进行调试； 
不断总结出现 bug 的原因，对其他代码编写相应测试用例； 
每次编写完成代码，运行所有以前的测试用例，验证对以前代码影响，把这种影响尽早消除； 
不断维护测试代码，保证代码变动后通过所有测试； 
有上面的理论做指导，测试行为就可以有规可循。那么 CppUnit 如何实现这种测试框架，帮助我们管理测试代码，完成自动测试的？下面就看看 CppUnit 的原理。

二、 CppUnit 的原理

在 CppUnit 中，一个或一组测试用例的测试对象被称为 Fixture（设施，下文为方便理解尽量使用英文名称）。Fixture 就是被测试的目标，可能是一个对象或者一组相关的对象，甚至一个函数。

有了被测试的 fixture，就可以对这个 fixture 的某个功能、某个可能出错的流程编写测试代码，这样对某个方面完整的测试被称为TestCase（测试用例）。通常写一个 TestCase 的步骤包括：

对 fixture 进行初始化，及其他初始化操作，比如：生成一组被测试的对象，初始化值； 
按照要测试的某个功能或者某个流程对 fixture 进行操作； 
验证结果是否正确； 
对 fixture 的及其他的资源释放等清理工作。 
对 fixture 的多个测试用例，通常（1）（4）部分代码都是相似的，CppUnit 在很多地方引入了 setUp 和 tearDown 虚函数。可以在 setUp 函数里完成（1）初始化代码，而在 tearDown 函数中完成（4）代码。具体测试用例函数中只需要完成（2）（3）部分代码即可，运行时 CppUnit 会自动为每个测试用例函数运行 setUp，之后运行 tearDown，这样测试用例之间就没有交叉影响。

对 fixture 的所有测试用例可以被封装在一个 CppUnit::TestFixture 的子类（命名惯例是[ClassName]Test）中。然后定义这个fixture 的 setUp 和 tearDown 函数，为每个测试用例定义一个测试函数（命名惯例是 testXXX）。下面是个简单的例子：

 class MathTest : public CppUnit::TestFixture {
 protected:
   int m_value1, m_value2;
 public:
   MathTest() {}
	// 初始化函数
   void setUp () {
     m_value1 = 2;
     m_value2 = 3;
   }
   // 测试加法的测试函数
   void testAdd () {
   		// 步骤(2),对 fixture 进行操作
     int result = m_value1 + m_value2;
     	// 步骤(3),验证结果是否争取
     CPPUNIT_ASSERT( result == 5 );
   }
   // 没有什么清理工作没有定义 tearDown. 
 }
  


在测试函数中对执行结果的验证成功或者失败直接反应这个测试用例的成功和失败。CppUnit 提供了多种验证成功失败的方式：

		CPPUNIT_ASSERT(condition)					// 确信condition为真
	CPPUNIT_ASSERT_MESSAGE(message, condition)	// 当condition为假时失败, 并打印message
	CPPUNIT_FAIL(message)						// 当前测试失败, 并打印message
	CPPUNIT_ASSERT_EQUAL(expected, actual)		// 确信两者相等
	CPPUNIT_ASSERT_EQUAL_MESSAGE(message, expected, actual)	// 失败的同时打印message
	CPPUNIT_ASSERT_DOUBLES_EQUAL(expected, actual, delta)	// 当expected和actual之间差大于delta时失败
	 


要把对 fixture 的一个测试函数转变成一个测试用例，需要生成一个 CppUnit::TestCaller 对象。而最终运行整个应用程序的测试代码的时候，可能需要同时运行对一个 fixture 的多个测试函数，甚至多个 fixture 的测试用例。CppUnit 中把这种同时运行的测试案例的集合称为 TestSuite。而 TestRunner 则运行测试用例或者 TestSuite，具体管理所有测试用例的生命周期。目前提供了 3 类TestRunner，包括：

		CppUnit::TextUi::TestRunner 	// 文本方式的TestRunner
	CppUnit::QtUi::TestRunner		// QT方式的TestRunner
	CppUnit::MfcUi::TestRunner		// MFC方式的TestRunner
	 


下面是个文本方式 TestRunner 的例子：

		CppUnit::TextUi::TestRunner runner;
	CppUnit::TestSuite *suite= new CppUnit::TestSuite();
	
	// 添加一个测试用例
	suite->addTest(new CppUnit::TestCaller<MathTest> (
	              "testAdd", testAdd));
	
	// 指定运行TestSuite 
	runner.addTest( suite );
	// 开始运行, 自动显示测试进度和测试结果
	runner.run( "", true );    // Run all tests and wait
	 


对测试结果的管理、显示等功能涉及到另一类对象，主要用于内部对测试结果、进度的管理，以及进度和结果的显示。这里不做介绍。

下面我们整理一下思路，结合一个简单的例子，把上面说的思路串在一起。

三、 手动使用步骤

首先要明确测试的对象 fixture，然后根据其功能、流程，以及以前的经验，确定测试用例。这个步骤非常重要，直接关系到测试的最终效果。当然增加测试用例的过程是个阶段性的工作，开始完成代码后，先完成对功能的测试用例，保证其完成功能；然后对可能出错的部分，结合以前的经验（比如边界值测试、路径覆盖测试等）编写测试用例；最后在发现相关 bug 时，根据 bug 完成测试用例。

比如对整数加法进行测试，首先定义一个新的 TestFixture 子类，MathTest，编写测试用例的测试代码。后期需要添加新的测试用例时只需要添加新的测试函数，根据需要修改 setUp 和 tearDown 即可。如果需要对新的 fixture 进行测试，定义新的 TestFixture 子类即可。注：下面代码仅用来表示原理，不能编译。

/// MathTest.h
// A TestFixture subclass.
// Announce: use as your owner risk.
// Author  : liqun (liqun@nsfocus.com)
// Data    : 2003-7-5
#include "cppunit/TestFixture.h"
class MathTest : public CppUnit::TestFixture {
protected:
	int m_value1, m_value2;
	
public:
	MathTest() {}
	
	// 初始化函数
	void setUp ();
	// 清理函数
	void tearDown();
	
	// 测试加法的测试函数
	void testAdd ();
	// 可以添加新的测试函数
};
/// MathTest.cpp
// A TestFixture subclass.
// Announce: use as your owner risk.
// Author  : liqun (liqun@nsfocus.com)
// Data    : 2003-7-5
#include "MathTest.h"
#include "cppunit/TestAssert.h"
void MathTest::setUp()
{
     m_value1 = 2;
     m_value2 = 3;
}
void MathTest::tearDown()
{
}
void MathTest::testAdd()
{
     int result = m_value1 + m_value2;
     CPPUNIT_ASSERT( result == 5 );
}
 


然后编写 main 函数，把需要测试的测试用例组织到 TestSuite 中，然后通过 TestRuner 运行。这部分代码后期添加新的测试用例时需要改动的不多。只需要把新的测试用例添加到 TestSuite 中即可。

/// main.cpp
// Main file for cppunit test.
// Announce: use as your owner risk.
// Author  : liqun (liqun@nsfocus.com)
// Data    : 2003-7-5
// Note	   : Cannot compile, only for study.	
#include "MathTest.h"
#include "cppunit/ui/text/TestRunner.h"
#include "cppunit/TestCaller.h"
#include "cppunit/TestSuite.h"
int main()
{
	CppUnit::TextUi::TestRunner runner;
	CppUnit::TestSuite *suite= new CppUnit::TestSuite();
	
	// 添加一个测试用例
	suite->addTest(new CppUnit::TestCaller<MathTest> (
	              "testAdd", testAdd));
	
	// 指定运行TestSuite 
	runner.addTest( suite );
	// 开始运行, 自动显示测试进度和测试结果
	runner.run( "", true );    // Run all tests and wait
}
 
四、 常用使用方式

按照上面的方式，如果要添加新的测试用例，需要把每个测试用例添加到 TestSuite 中，而且添加新的 TestFixture 需要把所有头文件添加到 main.cpp 中，比较麻烦。为此 CppUnit 提供了 CppUnit::TestSuiteBuilder，CppUnit::TestFactoryRegistry 和一堆宏，用来方便地把 TestFixture 和测试用例注册到 TestSuite 中。下面就是通常的使用方式：

/// MathTest.h
// A TestFixture subclass.
// Announce: use as your owner risk.
// Author  : liqun (liqun@nsfocus.com)
// Data    : 2003-7-5
#include "cppunit/extensions/HelperMacros.h"
class MathTest : public CppUnit::TestFixture {
	// 声明一个TestSuite
	CPPUNIT_TEST_SUITE( MathTest );
	// 添加测试用例到TestSuite, 定义新的测试用例需要在这儿声明一下
	CPPUNIT_TEST( testAdd );
	// TestSuite声明完成
	CPPUNIT_TEST_SUITE_END();
	// 其余不变
protected:
	int m_value1, m_value2;
	
public:
	MathTest() {}
	
	// 初始化函数
	void setUp ();
	// 清理函数
	void tearDown();
	
	// 测试加法的测试函数
	void testAdd ();
	// 可以添加新的测试函数
};
/// MathTest.cpp
// A TestFixture subclass.
// Announce: use as your owner risk.
// Author  : liqun (liqun@nsfocus.com)
// Data    : 2003-7-5
#include "MathTest.h"
// 把这个TestSuite注册到名字为"alltest"的TestSuite中, 如果没有定义会自动定义
// 也可以CPPUNIT_TEST_SUITE_REGISTRATION( MathTest );注册到全局的一个未命名的TestSuite中.
CPPUNIT_TEST_SUITE_NAMED_REGISTRATION( MathTest, "alltest" );
// 下面不变
void MathTest::setUp()
{
     m_value1 = 2;
     m_value2 = 3;
}
void MathTest::tearDown()
{
}
void MathTest::testAdd()
{
     int result = m_value1 + m_value2;
     CPPUNIT_ASSERT( result == 5 );
}
/// main.cpp
// Main file for cppunit test.
// Announce: use as your owner risk.
// Compile : g++ -lcppunit MathTest.cpp main.cpp
// Run     : ./a.out
// Test    : RedHat 8.0 CppUnit1.8.0
// Author  : liqun ( a litthle modification. liqun@nsfocus.com)
// Data    : 2003-7-5
// 不用再包含所有TestFixture子类的头文件
#include <cppunit/extensions/TestFactoryRegistry.h>
#include <cppunit/ui/text/TestRunner.h>
// 如果不更改TestSuite, 本文件后期不需要更改. 
int main()
{
	CppUnit::TextUi::TestRunner runner;
	
	// 从注册的TestSuite中获取特定的TestSuite, 没有参数获取未命名的TestSuite.
	CppUnit::TestFactoryRegistry &registry = CppUnit::TestFactoryRegistry::getRegistry("alltest");
	// 添加这个TestSuite到TestRunner中
	runner.addTest( registry.makeTest() );
	// 运行测试
	runner.run();
}
 


这样添加新的测试用例只需要在类定义的开始声明一下即可。


五、 其他实际问题

通常包含测试用例代码和被测试对象是在不同的项目中。应该在另一个项目（最好在不同的目录）中编写 TestFixture，然后把被测试的对象包含在测试项目中。

对某个类或者某个函数进行测试的时候，这个 TestFixture 可能引用了别的类或者别的函数，为了隔离其他部分代码的影响，应该在源文件中临时定义一些桩程序，模拟这些类或者函数。这些代码可以通过宏定义在测试项目中有效，而在被测试的项目中无效

+ cppunit中的核心类
@cppunit

二、概念

　　在使用之前，我们有必要认识一下CppUnit中的主要类，当然你也可以先看后面的例子，遇到问题再回过头来看这一节。

　　CppUnit核心内容主要包括一些关键类：

Test：所有测试对象的基类。
　　CppUnit采用树形结构来组织管理测试对象（类似于目录树，如下图所示），因此这里采用了组合设计模式（Composite Pattern），Test的两个直接子类TestLeaf和TestComposite分别表示“测试树”中的叶节点和非叶节点，其中TestComposite主要起组织管理的作用，就像目录树中的文件夹，而TestLeaf才是最终具有执行能力的测试对象，就像目录树中的文件。

　　

　　Test最重要的一个公共接口为：

virtual void run(TestResult *result) = 0;
　　其作用为执行测试对象，将结果提交给result。

　　在实际应用中，我们一般不会直接使用Test、TestComposite以及TestLeaf，除非我们要重新定制某些机制。


TestFixture：用于维护一组测试用例的上下文环境。　　在实际应用中，我们经常会开发一组测试用例来对某个类的接口加以测试，而这些测试用例很可能具有相同的初始化和清理代码。为此，CppUnit引入TestFixture来实现这一机制。

　　TestFixture具有以下两个接口，分别用于处理测试环境的初始化与清理工作：

　　virtual void setUp(); 　　virtual void tearDown(); 　　TestCase：测试用例，从名字上就可以看出来，它便是单元测试的执行对象。　　TestCase从Test和TestFixture多继承而来，通过把Test::run制定成模板函数（Template Method）而将两个父类的操作融合在一起，run函数的伪定义如下： 

// 伪代码 void TestCase::run(TestResult* result){    result->startTest(this); // 通知result测试开始    if( result->protect(this, &TestCase::setUp) ) // 调用setUp，初始化环境        result->protect(this, &TestCase::runTest); // 执行runTest，即真正的测试代码    result->protect(this, &TestCase::tearDown); // 调用tearDown，清理环境    result->endTest(this); // 通知result测试结束}  

　　这里要提到的是函数runTest，它是TestCase定义的一个接口，原型如下：
　　virtual void runTest(); 　　用户需从TestCase派生出子类并实现runTest以开发自己所需的测试用例。
另外还要提到的就是TestResult的protect方法，其作用是对执行函数（实际上是函数对象）的错误信息（包括断言和异常等）进行捕获，从而实现对测试结果的统计。

　　TestSuit：测试包，按照树形结构管理测试用例　　TestSuit是TestComposite的一个实现，它采用vector来管理子测试对象（Test），从而形成递归的树形结构。

　　TestFactory：测试工厂　　这是一个辅助类，通过借助一系列宏定义让测试用例的组织管理变得自动化。参见后面的例子。

　　TestRunner：用于执行测试用例　　TestRunner将待执行的测试对象管理起来，然后供用户调用。其接口为：

　　virtual void addTest( Test *test ); 　　virtual void run( TestResult &controller, const std::string &testPath = "" ); 　　这也是一个辅助类，需注意的是，通过addTest添加到TestRunner中的测试对象必须是通过new动态创建的，用户不能删除这个对象，因为TestRunner将自行管理测试对象的生命期。

三、CppUnit 的使用

　　以上工作完成以后,就可以正式使用CppUnit了，由于单元测试是TDD（测试驱动开发）的利器，一般人会先写测试代码，然后再写产品代码，不过笔者认为先写产品代码框架后再写测试代码，然后通过慢慢补充产品代码以使得能通过测试的方法会好些。不管先写谁只要写得舒服安全就可以。本文决定先写测试代码。

　　前面我们提到过，CppUnit最小的测试单位是TestCase，多个相关TestCase组成一个TestSuite。要添加测试代码最简单的方法就是利用CppUnit为我们提供的几个宏来进行（当然还有其他的手工加入方法，但均是殊途同归，大家可以查阅CppUnit头文件中的演示代码）。这几个宏是：

    CPPUNIT_TEST_SUITE() 开始创建一个TestSuite；　　CPPUNIT_TEST() 添加TestCase；　　CPPUNIT_TEST_SUITE_END() 结束创建TestSuite；　　CPPUNIT_TEST_SUITE_NAMED_REGISTRATION() 添加一个TestSuite到一个指定的TestFactoryRegistry工厂。 

　　感兴趣的朋友可以在HelperMacros.h看看这几个宏的声明，本文在此不做详述。

　　假定我们要实现一个类，类名暂且取做CPlus，它的功能主要是实现两个数相加（多简单的一个类啊，这也要测试吗？不要紧，我们只是了解怎样加入测试代码来测试它就行了，所以越简单越好）。 假定这个类要实现的相加的方法是:

　　int Add(int nNum1, int nNum2);　　OK，那我们先来写测试这个方法的代码吧。TDD 可是先写测试代码，后写产品代码(CPlus)的哦！先写的测试代码往往是不能运行或编译的，我们的目标是在写好测试代码后写产品代码，使之编译通过，然后再进行重构。这就是Kent Beck说的“red/green/refactor”。所以，上面的类名和方法应该还只是在你的心里，还只是你的idea而已。

　　根据测试驱动的原理，我们需要先建立一个单元测试框架。我们在VC中为测试代码建立一个project。通常，测试代码和被测试对象（产品代码）是处于不同的project中的。这样就不会让你的产品代码被测试代码所“污染 ”。

　　由于在CppUnit下, 可以选择控制台方式和UI方式两种表现方案，我们选择UI方式。在本例中，我们将建立一个基于GUI 方式的测试环境。因此我们建立一个基于对话框的Project。假设名为UnitTest。

　　建立了UnitTest project之后，我们首先配置这个工程。

+ linux下使用cppunit
@cppunit


一、系统环境：
Red Hat Enterprise Linux4.0
 Kernel:2.6.9-5 EL
二、Red Hat Enterprise Linux4.0下CppUnit1.12.0的安装
取得：


http://sourceforge.net/projects/cppunit/ 最新的稳定版本为1.12.0。下载：cppunit-1.12.0.tar.gz。

解压缩：

tar -xzf cppunit-1.12.0.tar.gz


生成make file：

./configure


安装：

make
make install


配置共享库：

vi ld.so.conf
添加：/usr/local/lib
保存
可以使用

ldconfig -v | grep cppunit
命令查看是否配置成功。

三、实例

#include <cppunit/extensions/HelperMacros.h>
#include <cppunit/BriefTestProgressListener.h>
#include <cppunit/CompilerOutputter.h>
#include <cppunit/extensions/TestFactoryRegistry.h>
#include <cppunit/TestResult.h>
#include <cppunit/TestResultCollector.h>
#include <cppunit/TestRunner.h>

#include "ldap_util.h"
#include "sequence_operator.h"

//test COther_Operator
class COther_TestCase : public CPPUNIT_NS::TestFixture
{
    CPPUNIT_TEST_SUITE( COther_TestCase );
        CPPUNIT_TEST( CSequence_Operator_testGetNextSeq );
        CPPUNIT_TEST( testBackupRestore );
    CPPUNIT_TEST_SUITE_END();

protected:
    LDAP *ld;
    CSequence_Operator *base;

public:
    void setUp()
    {
        CLDAP_Util::GetConnection(&ld);
        base = new CSequence_Operator();
    }
    void tearDown()
    {
        CLDAP_Util::CloseConnection(&ld);
        delete base;
    }

protected:
    void CSequence_Operator_testGetNextSeq()
    {
        int seq,nextseq;
        CPPUNIT_ASSERT_NO_THROW(seq = base->GetNextSeq(ld,1));
        CPPUNIT_ASSERT_NO_THROW(nextseq = base->GetNextSeq(ld,1));
        CPPUNIT_ASSERT_EQUAL(seq+1,nextseq);
    }
    void testBackupRestore()
    {
        CDiscoveryDomain_Operator dd_operator;
        CDiscoveryDomainSet_Operator dds_operator;
        vector<ISNS_ATTR> keyAttr_dd;
        vector<ISNS_ATTR> addAttr_dd;
        vector<ISNS_ATTR> keyAttr_dds;
        vector<ISNS_ATTR> addAttr_dds;
        
        ISNS_ATTR temp;
        
        temp.tag = 2065;
        temp.len = 1;
        temp.val.dd_id = 0;
        keyAttr_dd.push_back(temp);
        addAttr_dd.push_back(temp);
        
        temp.tag = 2066;
        temp.len = 16;
        strcpy(temp.val.dd_sym_name,"DD Symbolic Name");
        addAttr_dd.push_back(temp);
        
        temp.tag = 2049;
        temp.len = 1;
        temp.val.dd_id = 0;
        keyAttr_dds.push_back(temp);
        addAttr_dds.push_back(temp);
        
        temp.tag = 2050;
        temp.len = 1;
        strcpy(temp.val.dds_sym_name,"DDS Name");
        addAttr_dds.push_back(temp);

        //insert dd
        CPPUNIT_ASSERT_NO_THROW(dd_operator.Insert(ld,keyAttr_dd,addAttr_dd));

        //backup db
        CPPUNIT_ASSERT_EQUAL(CLDAP_Util::Backup(),LDAP_SUCCESS);
        
        //remove dd
        CPPUNIT_ASSERT_NO_THROW(dd_operator.Remove(ld,keyAttr_dd));
        //insert dds
        CPPUNIT_ASSERT_NO_THROW(dds_operator.Insert(ld,keyAttr_dds,addAttr_dds));
        
        //restore db
        CPPUNIT_ASSERT_EQUAL(CLDAP_Util::Restore(),LDAP_SUCCESS);
        
        //check dd exist
        vector<ISNS_ATTR> rstAttr;
        CPPUNIT_ASSERT_NO_THROW(rstAttr = dd_operator.Search(ld,keyAttr_dd,keyAttr_dd));
        int size = rstAttr.size();
        CPPUNIT_ASSERT_EQUAL(size,1);
        //remove dd
        CPPUNIT_ASSERT_NO_THROW(dd_operator.Remove(ld,keyAttr_dd));
        //check dds exist
        CPPUNIT_ASSERT_NO_THROW(rstAttr = dds_operator.Search(ld,keyAttr_dds,addAttr_dds));
        size = rstAttr.size();
        CPPUNIT_ASSERT_EQUAL(size,0);
    }
};

//注册测试用例，很重要，只有在这里注册了才会运行测试方法
CPPUNIT_TEST_SUITE_REGISTRATION( COther_TestCase );

//main方法中的东西都不需要改动，直接copy就可以了。

int main( int argc, char* argv[] )
{   
    // Create the event manager and test controller
    CPPUNIT_NS::TestResult controller;

    // Add a listener that colllects test result
    CPPUNIT_NS::TestResultCollector result;
    controller.addListener( &result );                

    // Add a listener that print dots as test run.
    CPPUNIT_NS::BriefTestProgressListener progress;
    controller.addListener( &progress );            

    // Add the top suite to the test runner
    CPPUNIT_NS::TestRunner runner;
    runner.addTest( CPPUNIT_NS::TestFactoryRegistry::getRegistry().makeTest() );
    runner.run( controller );

    // Print test in a compiler compatible format.
    CPPUNIT_NS::CompilerOutputter outputter( &result, CPPUNIT_NS::stdCOut() );
    outputter.write(); 

    return result.wasSuccessful() ? 0 : 1;
}

四、编译

g++ -ggdb testcase.cpp -o testcase.o
g++ -lstdc++ -lcppunit -f -0 testcase.o ....

*** automake
+ 文章一
@automake


5.3.2  自动生成Makefile的流程

在进行自动化生成Makefile之前，务必要设定好工作的根目录，在当前环境下，至少要保证autoscan、autoconf、aclocal、automake这些命令能够正常运行。在这一节中，我们就以一个最简单的示例来说明automake和autoconf的基本使用方法，这个例子是一个平坦模式的模型。自动生成Makefile的流程如图5-1所示。

  
（点击查看大图）图5-1  自动生成Makefile的流程 

在这里使用标准的sntp客户端源代码进行示例，该源代码只有一个源文件和一个头文件，分别是ntp.h和sntp.c。

（1）首先把所有的源代码文件复制到当前的根目录下，然后运行autoscan扫描所有的代码，并得到autoscan.log和configure.scan两个文件。

其中autoscan.log是一个空文件，而configure.scan文件则需要用户手动进行编辑，在该例中，修改之前configure.scan的内容应该如下：

#-*- Autoconf -*-# Process this file with autoconf to produce a configure script.AC_PREREQ(2.57)AC_INIT(FULL-PACKAGE-NAME, VERSION, BUG-REPORT-ADDRESS)AC_CONFIG_SRCDIR([sntp.c])AC_CONFIG_HEADER([config.h])# Checks for programs.AC_PROG_CC# Checks for libraries.# Checks for header files.AC_HEADER_STDCAC_CHECK_HEADERS([netdb.h netinet/in.h stdlib.h string.h sys/socket.h sys/time.h unistd.h])# Checks for typedefs, structures, and compiler characteristics.AC_HEADER_TIMEAC_STRUCT_TM# Checks for library functions.AC_FUNC_ERROR_AT_LINEAC_FUNC_MALLOCAC_FUNC_SELECT_ARGTYPESAC_CHECK_FUNCS([bzero gethostbyname gettimeofday select socket strchr])AC_OUTPUT 
这是一个标准的config模板，后面针对configure文件的修改都是基于这个文件进行的，configure.scan的基本格式如下：
AC_INIT测试程序 AC_PROG_CC测试函数库 （在源文件中没有用到函数库）测试头文件 AC_HEADER_STDC，AC_CHECK_HEADERS测试类型定义 AC_HEADER_TIME测试结构 AC_STRUCT_TM测试编译器特性 测试库函数 AC_FUNC_ERROR_AT_LINE，AC_FUNC_MALLOC   AC_FUNC_SELECT_ARGTYPES 测试系统调用 AC_CHECK_FUNCSAC_OUTPUT 

这个文件中有几个非常重要的语句，一般来说所有的configure.scan文件都是以AC_INIT开头和以AC_OUTPUT结束的；而且中间的顺序一般不要进行随意的改变，因为通常在本列表中靠后的项目依赖于表中靠前的项目。例如，库函数可能受到typedefs和库的影响。

（2）configure.scan文件准备好之后，就开始准备把它改造成自己定制的configure.in文件，先把它的名字修改为configure.in，然后打开该文件进行编辑。在configure.in文件中，必须修改的内容有：

将AC_CONFIG_HEADER([config.h])修改为AM_CONFIG_HEADER([config.h])，也就是说把AC改成AM。

在AM_CONFIG_HEADER下面添加一行AM_INIT_AUTOMAKE(sntp，1.0)，这一行命令说明了使用automake最终要得到的结果和版本号。

如果工程中使用了外部的库，比如pthread线程库，在# Checks for libraries这一行的下面还会生成像下面这样的行：

AC_CHECK_LIB([pthread],[pthread_rwlock_init])
 

最后，还要在AC_OUTPUT后面加上要创建的文件名称：AC_OUTPUT([Makefile])。

如果是混合模式或者是深层模式的结构，还需要添加子目录的目标Makefile文件路径到AC_OUTPUT后面的输入中。

此时，configure.in文件的最终内容应该如下：

#-*- Autoconf -*-# Process this file with autoconf to produce a configure script.AC_PREREQ(2.57)AC_INIT(sntp, 1.0, author@gmail.com)AC_CONFIG_SRCDIR([sntp.c])AM_CONFIG_HEADER([config.h])AM_INIT_AUTOMAKE(sntp, 1.0)# Checks for programs.AC_PROG_CC# Checks for libraries.# Checks for header files.AC_HEADER_STDCAC_CHECK_HEADERS([netdb.h netinet/in.h stdlib.hstring.h sys/socket.h sys/time.h unistd.h])# Checks for typedefs, structures, and compiler characteristics.AC_HEADER_TIMEAC_STRUCT_TM# Checks for library functions.AC_FUNC_ERROR_AT_LINEAC_FUNC_MALLOCAC_FUNC_SELECT_ARGTYPESAC_CHECK_FUNCS([bzero gethostbyname gettimeofday select socket strchr])AC_OUTPUT 
完成了configure.in文件的编写后，还有一个文件需要用户手动编写，就是Makefile.am文件，针对本工程的一个标准的简易Makefile.am模板如下：
AUTOMAKE_OPTIONS = foreign# Note:target partbin_PROGRAMS = sntp# noinst_PROGRAMS = sntp# Note:source partsntp_SOURCES = sntp.c# sntp_LDADD =# sntp_LDFLAGS =# sntp_DEPENDENCIES =# Note:lib part# lib_LIBRARIES =# sntp_a_SOURCES =# sntp_a_LDADD =# sntp_a_LIBADD =# sntp_a_LDFLAGS =# Note:header partinclude_HEADERS = ntp.h# Note:data part# data_DATA = 

可以看到Makefile.am文件主要由五个部分组成，分别是目标描述部分、源代码描述部分、库描述部分、头描述部分和数据描述部分。在本例中，由于只有源代码文件和头文件，没有数据和依赖的库，所以对不用的段用井号"#"进行注释。

在目标描述部分，一般有两种选择，如果描述为bin_PROGRAMS，则表明该程序是需要进行安装的，而如果描述为noinst_PROGRAMS，则表明不需要安装。

一般来说，如果不显式地进行声明，默认的几个全局路径如下：

安装路径前缀：$(prefix) = /usr/local

目标文件安装路径：bindir = $(prefix)/bin

库文件安装路径：libdir = $(prefix)/lib

数据文件安装路径：datadir = $(prefix)/share

系统配置安装路径：sysconfdir = $(prefix)/etc

写完了Makefile.am文件之后，生成Makefile的前期准备工作就做完了。接下来就是使用auto系列工具生成的过程，按照如下顺序输入命令：

$./aclocal  # 得到aclocal.m4文件$./autoconf  # 得到configure文件$./automake -a # 得到Makefile.in文件
 

到此为止，就完成了所有自动化的配置任务，把生成的一系列相关文件压缩打包，就可以进行版本的发布了。

用户拿到这个安装包解压后，就可以按照一般软件包的方式进行Makefile的最后生成、编译和安装，也就是输入以下命令：

$ ./configure   （得到makefile文件）$ make $ make install 

知识点：使用autoconf和automake来进行自动化配置和生成Makefile的流程可以概括如下：

（1）运行autoscan命令。

（2）将configure.scan文件重命名为configure.in，并修改configure.in文件。

（3）运行aclocal命令得到aclocal.m4文件。

（4）运行autoconf命令得到configure文件。

（5）在工程目录下新建Makefile.am文件，如果存在子目录，子目录中也要创建此文件。

（6）将/usr/share/automake-1.X/目录下的depcomp和compile文件复制到需要处理目录下。

（7）运行automake -a命令得到Makefile.in文件。

（8）运行./configure脚本（这一步已经属于使用自动化管理的范畴了

+ 文章二
本文介绍了在 linux 系统中，通过 Gnu autoconf 和 automake 生成 Makefile 的方法。主要探讨了生成 Makefile 的来龙去脉及其机理，接着详细介绍了配置 Configure.in 的方法及其规则。
引子

无论是在Linux还是在Unix环境中，make都是一个非常重要的编译命令。不管是自己进行项目开发还是安装应用软件，我们都经常要用到make或 make install。利用make工具，我们可以将大型的开发项目分解成为多个更易于管理的模块，对于一个包括几百个源文件的应用程序，使用make和 makefile工具就可以轻而易举的理顺各个源文件之间纷繁复杂的相互关系。

但是如果通过查阅make的帮助文档来手工编写Makefile,对任何程序员都是一场挑战。幸而有GNU 提供的Autoconf及Automake这两套工具使得编写makefile不再是一个难题。

本文将介绍如何利用 GNU Autoconf 及 Automake 这两套工具来协助我们自动产生 Makefile文件，并且让开发出来的软件可以像大多数源码包那样，只需"./configure", "make","make install" 就可以把程序安装到系统中。



 


 回页首 
 



模拟需求

假设源文件按如下目录存放，如图1所示，运用autoconf和automake生成makefile文件。


图 1文件目录结构
 
 

假设src是我们源文件目录，include目录存放其他库的头文件，lib目录存放用到的库文件，然后开始按模块存放，每个模块都有一个对应的目录，模块下再分子模块，如apple、orange。每个子目录下又分core，include，shell三个目录，其中core和shell目录存放.c文件，include的存放.h文件，其他类似。

样例程序功能：基于多线程的数据读写保护（联系作者获取整个autoconf和automake生成的Makefile工程和源码，E-mail：normalnotebook@126.com）。



 


 回页首 
 



工具简介

所必须的软件：autoconf/automake/m4/perl/libtool（其中libtool非必须）。

autoconf是一个用于生成可以自动地配置软件源码包，用以适应多种UNIX类系统的shell脚本工具，其中autoconf需要用到 m4，便于生成脚本。automake是一个从Makefile.am文件自动生成Makefile.in的工具。为了生成Makefile.in，automake还需用到perl，由于automake创建的发布完全遵循GNU标准，所以在创建中不需要perl。libtool是一款方便生成各种程序库的工具。

目前automake支持三种目录层次：flat、shallow和deep。

1 flat指的是所有文件都位于同一个目录中。

就是所有源文件、头文件以及其他库文件都位于当前目录中，且没有子目录。Termutils就是这一类。

2 shallow指的是主要的源代码都储存在顶层目录，其他各个部分则储存在子目录中。

就是主要源文件在当前目录中，而其它一些实现各部分功能的源文件位于各自不同的目录。automake本身就是这一类。

3 deep指的是所有源代码都被储存在子目录中；顶层目录主要包含配置信息。

就是所有源文件及自己写的头文件位于当前目录的一个子目录中，而当前目录里没有任何源文件。 GNU cpio和GNU tar就是这一类。

flat类型是最简单的，deep类型是最复杂的。不难看出，我们的模拟需求正是基于第三类deep型，也就是说我们要做挑战性的事情：)。注：我们的测试程序是基于多线程的简单程序。



 


 回页首 
 



生成 Makefile 的来龙去脉

首先进入 project 目录，在该目录下运行一系列命令，创建和修改几个文件，就可以生成符合该平台的Makefile文件，操作过程如下：

1 运行autoscan命令

2 将configure.scan 文件重命名为configure.in，并修改configure.in文件

3 在project目录下新建Makefile.am文件，并在core和shell目录下也新建makefile.am文件

4 在project目录下新建NEWS、 README、 ChangeLog 、AUTHORS文件

5 将/usr/share/automake-1.X/目录下的depcomp和complie文件拷贝到本目录下

6 运行aclocal命令

7 运行autoconf命令

8 运行automake -a命令

9 运行./confiugre脚本

可以通过图2看出产生Makefile的流程，如图所示：


图 2生成Makefile流程图
 
 

 


 回页首 
 



Configure.in的八股文

当我们利用autoscan工具生成confiugre.scan文件时，我们需要将confiugre.scan重命名为confiugre.in文件。confiugre.in调用一系列autoconf宏来测试程序需要的或用到的特性是否存在，以及这些特性的功能。

下面我们就来目睹一下confiugre.scan的庐山真面目：


# Process this file with autoconf to produce a configure script.
AC_PREREQ(2.59)
AC_INIT(FULL-PACKAGE-NAME, VERSION, BUG-REPORT-ADDRESS)
AC_CONFIG_SRCDIR([config.h.in])
AC_CONFIG_HEADER([config.h])
# Checks for programs.
AC_PROG_CC
# Checks for libraries.
# FIXME: Replace `main' with a function in `-lpthread':
AC_CHECK_LIB([pthread], [main])
# Checks for header files.
# Checks for typedefs, structures, and compiler characteristics.
# Checks for library functions.
AC_OUTPUT
 


每个configure.scan文件都是以AC_INIT开头，以AC_OUTPUT结束。我们不难从文件中看出confiugre.in文件的一般布局：


AC_INIT
 测试程序
 测试函数库
 测试头文件
 测试类型定义
 测试结构
 测试编译器特性
 测试库函数
 测试系统调用
AC_OUTPUT
 


上面的调用次序只是建议性质的，但我们还是强烈建议不要随意改变对宏调用的次序。

现在就开始修改该文件：


$mv configure.scan configure.in
$vim configure.in
 


修改后的结果如下：


		
#                                -*- Autoconf -*-
# Process this file with autoconf to produce a configure script.

AC_PREREQ(2.59)
AC_INIT(test, 1.0, normalnotebook@126.com)
AC_CONFIG_SRCDIR([src/ModuleA/apple/core/test.c])
AM_CONFIG_HEADER(config.h)
AM_INIT_AUTOMAKE(test,1.0)

# Checks for programs.
AC_PROG_CC
# Checks for libraries.
# FIXME: Replace `main' with a function in `-lpthread':
AC_CHECK_LIB([pthread], [pthread_rwlock_init])
AC_PROG_RANLIB
# Checks for header files.
# Checks for typedefs, structures, and compiler characteristics.
# Checks for library functions.
AC_OUTPUT([Makefile
		src/lib/Makefile
		src/ModuleA/apple/core/Makefile
		src/ModuleA/apple/shell/Makefile
		])
		 


其中要将AC_CONFIG_HEADER([config.h])修改为：AM_CONFIG_HEADER(config.h), 并加入AM_INIT_AUTOMAKE(test,1.0)。由于我们的测试程序是基于多线程的程序，所以要加入AC_PROG_RANLIB，不然运行automake命令时会出错。在AC_OUTPUT输入要创建的Makefile文件名。

由于我们在程序中使用了读写锁，所以需要对库文件进行检查，即AC_CHECK_LIB([pthread], [main])，该宏的含义如下：

 
 

其中，LIBS是link的一个选项，详细请参看后续的Makefile文件。由于我们在程序中使用了读写锁，所以我们测试pthread库中是否存在pthread_rwlock_init函数。

由于我们是基于deep类型来创建makefile文件，所以我们需要在四处创建Makefile文件。即：project目录下，lib目录下，core和shell目录下。 

Autoconf提供了很多内置宏来做相关的检测，限于篇幅关系，我们在这里对其他宏不做详细的解释，具体请参看参考文献1和参考文献2，也可参看autoconf信息页。



 


 回页首 
 



实战Makefile.am

Makefile.am是一种比Makefile更高层次的规则。只需指定要生成什么目标，它由什么源文件生成，要安装到什么目录等构成。

表一列出了可执行文件、静态库、头文件和数据文件，四种书写Makefile.am文件个一般格式。


表 1Makefile.am一般格式
  

对于可执行文件和静态库类型，如果只想编译，不想安装到系统中，可以用noinst_PROGRAMS代替bin_PROGRAMS，noinst_LIBRARIES代替lib_LIBRARIES。

Makefile.am还提供了一些全局变量供所有的目标体使用：


表 2 Makefile.am中可用的全局变量
 
 

在Makefile.am中尽量使用相对路径，系统预定义了两个基本路径：


表 3Makefile.am中可用的路径变量
 
 

在上文中我们提到过安装路径，automake设置了默认的安装路径：

1 标准安装路径

默认安装路径为：$(prefix) = /usr/local，可以通过./configure --prefix=<new_path>的方法来覆盖。

其它的预定义目录还包括：bindir = $(prefix)/bin, libdir = $(prefix)/lib, datadir = $(prefix)/share, sysconfdir = $(prefix)/etc等等。

2 定义一个新的安装路径

比如test, 可定义testdir = $(prefix)/test, 然后test_DATA =test1 test2，则test1，test2会作为数据文件安装到$(prefix)/ /test目录下。

我们首先需要在工程顶层目录下（即project/）创建一个Makefile.am来指明包含的子目录：


SUBDIRS=src/lib src/ModuleA/apple/shell src/ModuleA/apple/core 
CURRENTPATH=$(shell /bin/pwd)
INCLUDES=-I$(CURRENTPATH)/src/include -I$(CURRENTPATH)/src/ModuleA/apple/include 
export INCLUDES
 


由于每个源文件都会用到相同的头文件，所以我们在最顶层的Makefile.am中包含了编译源文件时所用到的头文件，并导出，见蓝色部分代码。

我们将lib目录下的swap.c文件编译成libswap.a文件，被apple/shell/apple.c文件调用，那么lib目录下的Makefile.am如下所示：


noinst_LIBRARIES=libswap.a
libswap_a_SOURCES=swap.c
INCLUDES=-I$(top_srcdir)/src/includ
 


细心的读者可能就会问：怎么表1中给出的是bin_LIBRARIES，而这里是noinst_LIBRARIES？这是因为如果只想编译，而不想安装到系统中，就用noinst_LIBRARIES代替bin_LIBRARIES，对于可执行文件就用noinst_PROGRAMS代替bin_PROGRAMS。对于安装的情况，库将会安装到$(prefix)/lib目录下，可执行文件将会安装到${prefix}/bin。如果想安装该库，则Makefile.am示例如下：


bin_LIBRARIES=libswap.a
libswap_a_SOURCES=swap.c
INCLUDES=-I$(top_srcdir)/src/include
swapincludedir=$(includedir)/swap
swapinclude_HEADERS=$(top_srcdir)/src/include/swap.h
 


最后两行的意思是将swap.h安装到${prefix}/include /swap目录下。

接下来，对于可执行文件类型的情况，我们将讨论如何写Makefile.am？对于编译apple/core目录下的文件，我们写成的Makefile.am如下所示：


noinst_PROGRAMS=test
test_SOURCES=test.c 
test_LDADD=$(top_srcdir)/src/ModuleA/apple/shell/apple.o $(top_srcdir)/src/lib/libswap.a 
test_LDFLAGS=-D_GNU_SOURCE
DEFS+=-D_GNU_SOURCE
#LIBS=-lpthread
 


由于我们的test.c文件在链接时，需要apple.o和libswap.a文件，所以我们需要在test_LDADD中包含这两个文件。对于Linux下的信号量/读写锁文件进行编译，需要在编译选项中指明-D_GNU_SOURCE。所以在test_LDFLAGS中指明。而test_LDFLAGS只是链接时的选项，编译时同样需要指明该选项，所以需要DEFS来指明编译选项，由于DEFS已经有初始值，所以这里用+=的形式指明。从这里可以看出，Makefile.am中的语法与Makefile的语法一致，也可以采用条件表达式。如果你的程序还包含其他的库，除了用AC_CHECK_LIB宏来指明外，还可以用LIBS来指明。

如果你只想编译某一个文件，那么Makefile.am如何写呢？这个文件也很简单，写法跟可执行文件的差不多，如下例所示：


noinst_PROGRAMS=apple
apple_SOURCES=apple.c
DEFS+=-D_GNU_SOURCE
 


我们这里只是欺骗automake，假装要生成apple文件，让它为我们生成依赖关系和执行命令。所以当你运行完automake命令后，然后修改apple/shell/下的Makefile.in文件，直接将LINK语句删除，即：


…….
clean-noinstPROGRAMS:
	-test -z "$(noinst_PROGRAMS)" || rm -f $(noinst_PROGRAMS)
apple$(EXEEXT): $(apple_OBJECTS) $(apple_DEPENDENCIES) 
	@rm -f apple$(EXEEXT)
#$(LINK) $(apple_LDFLAGS) $(apple_OBJECTS) $(apple_LDADD) $(LIBS)
…….
 


通过上述处理，就可以达到我们的目的。从图1中不难看出为什么要修改Makefile.in的原因，而不是修改其他的文件。

*** mini_httpd
+ cgi
@cgi  @mini_httpd



用 mini_httpd.c 做服务器，我们可以用c来实现cgi


#include <stdio.h>
#include <unistd.h>
#include <errno.h>
#include <string.h>

int main(int argnum, char *args[]) {
	printf("Content-type: text/html\n\n");
	printf("11122222333333hohoho hellow 1  !!!  wwww\n\n");
	char *a = args[0];
	while(0 != *a)
	{
		printf("\n\n--------------\n\n");
		printf("%s", a);
		a += strlen(a) + 1;
	}
	printf("%s", args[1]);

	return 0;

}


浏览器上这样输入
http://192.168.1.102:9000/run.cgi?name=wwww&addr=mxy

浏览器上显示出来的结果是
11122222333333hohoho hellow 1 !!! wwww -------------- run.cgi -------------- PATH=/usr/local/bin:/usr/ucb:/bin:/usr/bin -------------- LD_LIBRARY_PATH=/usr/local/lib:/usr/lib -------------- SERVER_SOFTWARE=mini_httpd/1.19 19dec2003 -------------- SERVER_NAME=wylinux -------------- GATEWAY_INTERFACE=CGI/1.1 -------------- SERVER_PROTOCOL=HTTP/1.0 -------------- SERVER_PORT=9000 -------------- REQUEST_METHOD=GET -------------- SCRIPT_NAME=/run.cgi -------------- QUERY_STRING=name=wwww&addr=mxy -------------- REMOTE_ADDR=192.168.1.102 -------------- HTTP_USER_AGENT=Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.19) Gecko/2010040116 Ubuntu/9.04 (jaunty) Firefox/3.0.19 -------------- HTTP_HOST=192.168.1.102:9000 -------------- run.cgi(null)





------------------------------------

*** dynamiclib
+ 文章一

@so  @dynamic

http://www.yolinux.com/TUTORIALS/LibraryArchives-StaticAndDynamic.html

Why libraries are used:  

This methodology, also known as "shared components" or "archive libraries", groups together multiple compiled object code files into a single file known as a library. Typically C functions/C++ classes and methods which can be shared by more than one application are broken out of the application's source code, compiled and bundled into a library. The C standard libraries and C++ STL are examples of shared components which can be linked with your code. The benefit is that each and every object file need not be stated when linking because the developer can reference the individual library. This simplifies the multiple use and sharing of software components between applications. It also allows application vendors a way to simply release an API to interface with an application. Components which are large can be created for dynamic use, thus the library remain separate from the executable reducing it's size and thus disk space used. The library components are then called by various applications for use when needed. 



--------------------------------------------------------------------------------
Linux Library Types:  

There are two Linux C/C++ library types which can be created: 

Static libraries (.a): Library of object code which is linked with, and becomes part of the application. 
Dynamically linked shared object libraries (.so): There is only one form of this library but it can be used in two ways. 
Dynamically linked at run time but statically aware. The libraries must be available during compile/link phase. The shared objects are not included into the executable component but are tied to the execution. 
Dynamically loaded/unloaded and linked during execution (i.e. browser plug-in) using the dynamic linking loader system functions. 

Library naming conventions:
Libraries are typically names with the prefix "lib". This is true for all the C standard libraries. When linking, the command line reference to the library will not contain the library prefix or suffix. 
Thus the following link command: gcc src-file.c -lm -lpthread 
The libraries referenced in this example for inclusion during linking are the math library and the thread library. They are found in /usr/lib/libm.a and /usr/lib/libpthread.a. 



--------------------------------------------------------------------------------
Static Libraries: (.a) 

How to generate a library: 

Compile: cc -Wall -c ctest1.c ctest2.c 
Compiler options: 
-Wall: include warnings. See man page for warnings specified. 
Create library "libctest.a": ar -cvq libctest.a ctest1.o ctest2.o 
List files in library: ar -t libctest.a 
Linking with the library: 
cc -o executable-name prog.c libctest.a 
cc -o executable-name prog.c -L/path/to/library-directory -lctest 
Example files: 
ctest1.c void ctest1(int *i){   *i=5;}             

ctest2.c void ctest2(int *i){   *i=100;}             

prog.c #include <stdio.h>void ctest1(int *);void ctest2(int *);int main(){   int x;   ctest1(&x);   printf("Valx=%d\n",x);   return 0;}             

Historical note: After creating the library it was once necessary to run the command: ranlib ctest.a. This created a symbol table within the archive. Ranlib is now embedded into the "ar" command. 
Note for MS/Windows developers: The Linux/Unix ".a" library is conceptually the same as the Visual C++ static ".lib" libraries. 



--------------------------------------------------------------------------------
Dynamically Linked "Shared Object" Libraries: (.so) 

How to generate a shared object: (Dynamically linked object library file.) Note that this is a two step process. 

Create object code 
Create library 
Optional: create default version using a symbolic link. 
Library creation example: 
    gcc -Wall -fPIC -c *.c
    gcc -shared -Wl,-soname,libctest.so.1 -o libctest.so.1.0   *.o
    mv libctest.so.1.0 /opt/lib
    ln -sf /opt/lib/libctest.so.1.0 /opt/lib/libctest.so
    ln -sf /opt/lib/libctest.so.1.0 /opt/lib/libctest.so.1
          This creates the library libctest.so.1.0 and symbolic links to it. 
Compiler options: 

-Wall: include warnings. See man page for warnings specified. 
-fPIC: Compiler directive to output position independent code, a characteristic required by shared libraries. Also see "-fpic". 
-shared: Produce a shared object which can then be linked with other objects to form an executable. 
-W1: Pass options to linker. 
In this example the options to be passed on to the linker are: "-soname libctest.so.1". The name passed with the "-o" option is passed to gcc. 
Option -o: Output of operation. In this case the name of the shared object to be output will be "libctest.so.1.0" 
Library Links: 

The link to /opt/lib/libctest.so allows the naming convention for the compile flag -lctest to work. 
The link to /opt/lib/libctest.so.1 allows the run time binding to work. See dependency below. 
Compile main program and link with shared object library: 

Compiling for runtime linking with a dynamically linked libctest.so.1.0: 
    gcc -Wall -I/path/to/include-files -L/path/to/libraries prog.c -lctest -o prog
Use:
    gcc -Wall -L/opt/lib prog.c -lctest -o prog
      Where the name of the library is libctest.so. (This is why you must create the symbolic links or you will get the error "/usr/bin/ld: cannot find -lctest".) 
The libraries will NOT be included in the executable but will be dynamically linked during runtime execution. 
List Dependencies: 

The shared library dependencies of the executable can be listed with the command: ldd name-of-executable 


Example: ldd prog 
        libctest.so.1 => /opt/lib/libctest.so.1 (0x00002aaaaaaac000)
        libc.so.6 => /lib64/tls/libc.so.6 (0x0000003aa4e00000)
        /lib64/ld-linux-x86-64.so.2 (0x0000003aa4c00000)
    Run Program: 

Set path: export LD_LIBRARY_PATH=/opt/lib:$LD_LIBRARY_PATH 
Run: prog 
Man Pages: 

gcc - GNU C compiler 
ld - The GNU Linker 
ldd - List dependencies 
Links: 

LDP: Shared libraries 


--------------------------------------------------------------------------------
Library Path: 

In order for an executable to find the required libraries to link with during run time, one must configure the system so that the libraries can be found. Methods available: (Do at least one of the following) 

Add library directories to be included during dynamic linking to the file /etc/ld.so.conf 
Sample: /etc/ld.so.conf 

/usr/X11R6/lib
/usr/lib
...
..
/usr/lib/sane
/usr/lib/mysql
/opt/lib
                     

Add the library path to this file and then execute the command (as root) ldconfig to configure the linker run-time bindings. 
You can use the "-f file-name" flag to reference another configuration file if you are developing for different environments. 
See man page for command ldconfig. 
OR 


Add specified directory to library cache: (as root) 
ldconfig -n /opt/lib 
Where /opt/lib is the directory containing your library libctest.so 
(When developing and just adding your current directory: ldconfig -n . Link with -L.) 
This will NOT permanently configure the system to include this directory. The information will be lost upon system reboot. 

OR 


Specify the environment variable LD_LIBRARY_PATH to point to the directory paths containing the shared object library. This will specify to the run time loader that the library paths will be used during execution to resolve dependencies. 
(Linux/Solaris: LD_LIBRARY_PATH, SGI: LD_LIBRARYN32_PATH, AIX: LIBPATH, Mac OS X: DYLD_LIBRARY_PATH, HP-UX: SHLIB_PATH) 
Example (bash shell): export LD_LIBRARY_PATH=/opt/lib:$LD_LIBRARY_PATH or add to your ~/.bashrc file: 

...
if [ -d /opt/lib ];
then
   LD_LIBRARY_PATH=/opt/lib:$LD_LIBRARY_PATH
fi

...

export LD_LIBRARY_PATH
       


This instructs the run time loader to look in the path described by the environment variable LD_LIBRARY_PATH, to resolve shared libraries. This will include the path /opt/lib. 
Library paths used should conform to the "Linux Standard Base" directory structure. 



--------------------------------------------------------------------------------
Library Info: 

The command "nm" lists symbols contained in the object file or shared library. 

Use the command nm -D libctest.so.1.0 
(or nm --dynamic libctest.so.1.0) 

0000000000100988 A __bss_start
000000000000068c T ctest1
00000000000006a0 T ctest2
                 w __cxa_finalize
00000000001007b0 A _DYNAMIC
0000000000100988 A _edata
0000000000100990 A _end
00000000000006f8 T _fini
0000000000100958 A _GLOBAL_OFFSET_TABLE_
                 w __gmon_start__
00000000000005b0 T _init
                 w _Jv_RegisterClasses
      Man page for nm 
Symbol Type Description 
A The symbol's value is absolute, and will not be changed by further linking. 
B Un-initialized data section 
D Initialized data section 
T Normal code section 
U Undefined symbol used but not defined. Dependency on another library. 
W Doubly defined symbol. If found, allow definition in another library to resolve dependency. 

Also see: objdump man page 



--------------------------------------------------------------------------------
Library Versions: 

Library versions should be specified for shared objects if the function interfaces are expected to change (C++ public/protected class definitions), more or fewer functions are included in the library, the function prototype changes (return data type (int, const int, ...) or argument list changes) or data type changes (object definitions: class data members, inheritance, virtual functions, ...). 

The library version can be specified when the shared object library is created. If the library is expected to be updated, then a library version should be specified. This is especially important for shared object libraries which are dynamically linked. This also avoids the Microsoft "DLL hell" problem of conflicting libraries where a system upgrade which changes a standard library breaks an older application expecting an older version of the the shared object function. 

Versioning occurs with the GNU C/C++ libraries as well. This often make binaries compiled with one version of the GNU tools incompatible with binaries compiled with other versions unless those versions also reside on the system. Multiple versions of the same library can reside on the same system due to versioning. The version of the library is included in the symbol name so the linker knows which version to link with. 

One can look at the symbol version used: nm csub1.o 

00000000 T ctest1
No version is specified in object code by default. 
ld and object file layout 
There is one GNU C/C++ compiler flag that explicitly deals with symbol versioning. Specify the version script to use at compile time with the flag: --version-script=your-version-script-file 
Note: This is only useful when creating shared libraries. It is assumed that the programmer knows which libraries to link with when static linking. Runtime linking allows opportunity for library incompatibility. 

GNU/Linux, see examples of version scripts here: sysdeps/unix/sysv/linux/Versions 

Some symbols may also get version strings from assembler code which appears in glibc headers files. Look at include/libc-symbols.h. 

Example: nm /lib/libc.so.6 | more 

00000000 A GCC_3.0
00000000 A GLIBC_2.0
00000000 A GLIBC_2.1
00000000 A GLIBC_2.1.1
00000000 A GLIBC_2.1.2
00000000 A GLIBC_2.1.3
00000000 A GLIBC_2.2
00000000 A GLIBC_2.2.1
00000000 A GLIBC_2.2.2
00000000 A GLIBC_2.2.3
00000000 A GLIBC_2.2.4
...
..
      Note the use of a version script. 
Library referencing a versioned library: nm /lib/libutil-2.2.5.so 

..
...
         U strcpy@@GLIBC_2.0
         U strncmp@@GLIBC_2.0
         U strncpy@@GLIBC_2.0
...
..
      Links: 

Symbol versioning 
GNU.org: ld version scripts 


--------------------------------------------------------------------------------
Dynamic loading and un-loading of shared libraries using libdl: 

These libraries are dynamically loaded / unloaded and linked during execution. Usefull for creating a "plug-in" architecture. 

Prototype include file for the library: ctest.h 

#ifndef CTEST_H
#define CTEST_H

#ifdef __cplusplus
extern "C" {
#endif

void ctest1(int *);
void ctest2(int *);

#ifdef __cplusplus
}
#endif

#endif
       
Use the notation extern "C" so the libraries can be used with C and C++. This statement prevents the C++ from name mangling and thus creating "unresolved symbols" when linking. 
Load and unload the library libctest.so (created above), dynamically: 

#include <stdio.h>
#include <dlfcn.h>
#include "ctest.h"

int main(int argc, char **argv) 
{
   void *lib_handle;
   double (*fn)(int *);
   int x;
   char *error;

   lib_handle = dlopen("/opt/lib/libctest.so", RTLD_LAZY);
   if (!lib_handle) 
   {
      fprintf(stderr, "%s\n", dlerror());
      exit(1);
   }

   fn = dlsym(lib_handle, "ctest1");
   if ((error = dlerror()) != NULL)  
   {
      fprintf(stderr, "%s\n", error);
      exit(1);
   }

   (*fn)(&x);
   printf("Valx=%d\n",x);

   dlclose(lib_handle);
   return 0;
}
                  

gcc -rdynamic -o progdl progdl.c -ldl 

Explanation: 

dlopen("/opt/lib/libctest.so", RTLD_LAZY); 
Open shared library named "libctest.so". 
The second argument indicates the binding. See include file dlfcn.h. 
Returns NULL if it fails. 
Options: 
RTLD_LAZY: If specified, Linux is not concerned about unresolved symbols until they are referenced. 
RTLD_NOW: All unresolved symbols resolved when dlopen() is called. 
RTLD_GLOBAL: Make symbol libraries visible. 
dlsym(lib_handle, "ctest1"); 
Returns address to the function which has been loaded with the shared library.. 
Returns NULL if it fails. 
Note: When using C++ functions, first use nm to find the "mangled" symbol name or use the extern "C" construct to avoid name mangling. 
i.e. extern "C" void function-name(); 
Object code location: Object code archive libraries can be located with either the executable or the loadable library. Object code routines used by both should not be duplicated in each. This is especially true for code which use static variables such as singleton classes. A static variable is global and thus can only be represented once. Including it twice will provide unexpected results. The programmer can specify that specific object code be linked with the executable by using linker commands which are passed on by the compiler. 

Use the "-Wl" gcc/g++ compiler flag to pass command line arguments on to the GNU "ld" linker. 

Example makefile statement: g++ -rdynamic -o appexe $(OBJ) $(LINKFLAGS) -Wl,--whole-archive -L{AA_libs} -laa -Wl,--no-whole-archive $(LIBS) 

--whole-archive: This linker directive specifies that the libraries listed following this directive (in this case AA_libs) shall be included in the resulting output even though there may not be any calls requiring its presence. This option is used to specify libraries which the loadable libraries will require at run time. 
-no-whole-archive: This needs to be specified whether you list additional object files or not. The gcc/g++ compiler will add its own list of archive libraries and you would not want all the object code in the archive library linked in if not needed. It toggles the behavior back to normal for the rest of the archive libraries. 
Man pages: 

dlopen() - gain access to an executable object file 
dclose() - close a dlopen object 
dlsym() - obtain the address of a symbol from a dlopen object 
dlvsym() - Programming interface to dynamic linking loader. 
dlerror() - get diagnostic information 
Links: 

Shared Libraries-Dynamic Loading and Unloading 
GNOME Glib dynamic loading of modules - cross platform API for dynamically loading "plug-ins". 


--------------------------------------------------------------------------------
C++ class objects and dynamic loading: 

C++ and name mangling: 

When running the above "C" examples with the "C++" compiler one will quickly find that "C++" function names get mangled and thus will not work unless the function definitions are protected with extern "C"{}. 

Note that the following are not equivalent: extern "C"
{
   int functionx();
}
       extern "C" int functionx();
       


The following are equivalent: extern "C"
{
   extern int functionx();
}
       extern "C" int functionx();
       


Dynamic loading of C++ classes: 

The dynamic library loading routines enable the programmer to load "C" functions. In C++ we would like to load class member functions. In fact the entire class may be in the library and we may want to load and have access to the entire object and all of its member functions. Do this by passing a "C" class factory function which instantiates the class. 

The class ".h" file: 
class Abc {

...
...

};

// Class factory "C" functions

typedef Abc* create_t;
typedef void destroy_t(Abc*);
       


The class ".cpp" file: 
Abc::Abc()
{
    ...
}

extern "C"
{
   // These two "C" functions manage the creation and destruction of the class Abc

   Abc* create()
   {
      return new Abc;
   }

   void destroy(Abc* p)
   {
      delete p;   // Can use a base class or derived class pointer here
   }
}
       
This file is the source to the library. The "C" functions to instantiate (create) and destroy a class defined in the dynamically loaded library where "Abc" is the C++ class. 

Main executable which calls the loadable libraries: 
// load the symbols
    create_t* create_abc = (create_t*) dlsym(lib_handle, "create");

...
...

    destroy_t* destroy_abc = (destroy_t*) dlsym(lib_handle, "destroy");

...
...
       


Pitfalls: 
The new/delete of the C++ class should both be provided by the executable or the library but not split. This is so that there is no surprise if one overloads new/delete in one or the other. 

Links: 
LinuxJournal.com: Dynamic Class Loading for C++ on Linux 
dlopen howto 


--------------------------------------------------------------------------------
Comparison to the Microsoft DLL: 

The Microsoft Windows equivalent to the Linux / Unix shared object (".so") is the ".dll". The Microsoft Windows DLL file usually has the extension ".dll", but may also use the extension ".ocx". On the old 16 bit windows, the dynamically linked libraries were also named with the ".exe" suffix. "Executing" the DLL will load it into memory. 

The Visual C++ .NET IDE wizard will create a DLL framework through the GUI, and generates a ".def" file. This "module definition file" lists the functions to be exported. When exporting C++ functions, the C++ mangled names are used. Using the Visual C++ compiler to generate a ".map" file will allow you to discover the C++ mangled name to use in the ".def" file. The "SECTIONS" label in the ".def" file will define the portions which are "shared". Unfortunately the generation of DLLs are tightly coupled to the Microsoft IDE, so much so that I would not recomend trying to create one without it. 

The Microsoft Windows C++ equivalent functions to libdl are the following functions: 

::LoadLibrary() - dlopen() 
::GetProcAddress() - dlsym() 
::FreeLibrary() - dlclose() 
[Potential Pitfall]: Microsoft Visual C++ .NET compilers do not allow the linking controll that the GNU linker "ld" allows (i.e. --whole-archive, -no-whole-archive). All symbols need to be resolved by the VC++ compiler for both the loadable library and the application executable individually and thus it can cause duplication of libraries when the library is loaded. This is especially bad when using static variables (i.e. used in singleton patterns) as you will get two memory locations for the static variable, one used by the loadable library and the other used by the program executable. This breaks the whole static variable concept and the singleton pattern. Thus you can not use a static variable which is referenced by by both the loadable library and the application executable as they will be unique and different. To use a unique static variable, you must pass a pointer to that static variable to the other module so that each module (main executable and DLL library) can use the same instatiation. On MS/Windows you can use shared memory or a memory mapped file so that the main executable and DLL library can share a pointer to an address they both will use. 

Cross platform (Linux and MS/Windows) C++ code snippet: 

Include file declaration: (.h or .hpp) 
class Abc{
public:
   static Abc* Instance(); // Function declaration. Could also be used as a public class member function.

private:
   static Abc *mInstance;      // Singleton. Use this declaration in C++ class member variable declaration.
   ...
}
       


C/C++ Function source: (.cpp) 
/// Singleton instantiation
Abc* Abc::mInstance = 0;   // Use this declaration for C++ class member variable
                           // (Defined outside of class definition in ".cpp" file)

// Return unique pointer to instance of Abc or create it if it does not exist.
// (Unique to both exe and dll)

static Abc* Abc::Instance() // Singleton
{
#ifdef WIN32
    // If pointer to instance of Abc exists (true) then return instance pointer else look for 
    // instance pointer in memory mapped pointer. If the instance pointer does not exist in
    // memory mapped pointer, return a newly created pointer to an instance of Abc.

    return mInstance ? 
       mInstance : (mInstance = (Abc*) MemoryMappedPointers::getPointer("Abc")) ? 
       mInstance : (mInstance = (Abc*) MemoryMappedPointers::createEntry("Abc",(void*)new Abc));
#else
    // If pointer to instance of Abc exists (true) then return instance pointer 
    // else return a newly created pointer to an instance of Abc.

    return mInstance ? mInstance : (mInstance = new Abc);
#endif
}
       

Windows linker will pull two instances of object, one in exe and one in loadable module. Specify one for both to use by using memory mapped pointer so both exe and loadable library point to same variable or object. 
Note that the GNU linker does not have this problem. 

For more on singletons see the YoLinux.com C++ singleton software design pattern tutorial. 


--------------------------------------------------------------------------------
Cross platform programming of loadable libraries: 


#ifndef USE_PRECOMPILED_HEADERS
#ifdef WIN32
#include <direct.h>
#include <windows.h>
#else
#include <sys/types.h>
#include <dlfcn.h>
#endif
#include <iostream>
#endif

    using namespace std;

#ifdef WIN32
    HINSTANCE lib_handle;
#else
    void *lib_handle;
#endif

    // Where retType is the pointer to a return type of the function
    // This return type can be int, float, double, etc or a struct or class.

    typedef retType* func_t;  

    // load the library -------------------------------------------------
#ifdef WIN32
    string nameOfLibToLoad("C:\opt\lib\libctest.dll");
    lib_handle = LoadLibrary(TEXT(nameOfLibToLoad.c_str()));
    if (!lib_handle) {
        cerr << "Cannot load library: " << TEXT(nameOfDllToLoad.c_str()) << endl;
    }
#else
    string nameOfLibToLoad("/opt/lib/libctest.so");
    lib_handle = dlopen(nameOfLibToLoad.c_str(), RTLD_LAZY);
    if (!lib_handle) {
        cerr << "Cannot load library: " << dlerror() << endl;
    }
#endif

...
...
...

    // load the symbols -------------------------------------------------
#ifdef WIN32
    func_t* fn_handle = (func_t*) GetProcAddress(lib_handle, "superfunctionx");
    if (!fn_handle) {
        cerr << "Cannot load symbol superfunctionx: " << GetLastError() << endl;
    }
#else
    // reset errors
    dlerror();

    // load the symbols (handle to function "superfunctionx")
    func_t* fn_handle= (func_t*) dlsym(lib_handle, "superfunctionx");
    const char* dlsym_error = dlerror();
    if (dlsym_error) {
        cerr << "Cannot load symbol superfunctionx: " << dlsym_error << endl;
    }
#endif

...
...
...

    // unload the library -----------------------------------------------

#ifdef WIN32
    FreeLibrary(lib_handle);
#else
    dlclose(lib_handle);
#endif
       



--------------------------------------------------------------------------------
Tools: 

Man pages: 

ar - create, modify, and extract from archives 
ranlib - generate index to archive 
nm - list symbols from object files 
ld - Linker 
ldconfig - configure dynamic linker run-time bindings 
ldconfig -p : Print the lists of directories and candidate libraries stored in the current cache. 
i.e. /sbin/ldconfig -p |grep libGL 
ldd - print shared library dependencies 
gcc/g++ - GNU project C and C++ compiler 
man page to: ld.so - a.out dynamic linker/loader 


--------------------------------------------------------------------------------
Notes: 


Direct loader to preload a specific shared library before all others: export LD_PRELOAD=/usr/lib/libXXX.so.x; exec program. This is specified in the file /etc/ld.so.preload and extended with the environment variable LD_PRELOAD. 
Also see: 
man page to: ld.so - a.out dynamic linker/loader 
LD_PRELOAD and Linux function interception. 

Running Red Hat 7.1 (glibc 2.2.2) but compiling for Red Hat 6.2 compatibility. 
See RELEASE-NOTES 

        export LD_ASSUME_KERNEL=2.2.5        . /usr/i386-glibc21-linux/bin/i386-glibc21-linux-env.sh    
Environment variable to highlight warnings, errors, etc: export CC="colorgcc" 





*** stl
**** hash_map
@stl  @std  @hash_map

有时可能要用到名字空间__gnu_cxx
另外需要自己定义str_hash str_equal这两个方法类


/*
 * mainctrl.h
 *
 *  Created on: 2010-7-8
 *      Author: wyao
 */

#ifndef MAINCTRL_H_
#define MAINCTRL_H_

#include "Poco/ThreadPool.h"
#include "Poco/Semaphore.h"
#include <string>
#include <list>
#include <map>
#include <ext/hash_map>




struct str_hash
{
	size_t operator()(const std::string& str) const
	{
		return 0;
	}
};

struct str_equal{
        bool operator()(const std::string & a1, const std::string & a2)const{
                return a1 == a2;
        }
};

namespace wr
{

const int POP_ACTLIST_WAIT = 100000;

class Actioner;
class Calc;

class MainCtrl
{
public:

	MainCtrl();

	int start();
	int mainLoop();

	int pushActioner(Actioner * pActioner);
	int popActioner(Actioner *& pActioner);
	Calc* getCalc();

private:
	Poco::ThreadPool m_threadPool;
	//std::hash_map<std::string, Actioner*, str_hash, str_equal> m_actMap;
	__gnu_cxx::hash_map<std::string, Actioner*> m_actMap;
	std::list<Actioner*> m_actList;
	Poco::Semaphore m_actListSem;
	Poco::Mutex m_actListMut;
};

}

#endif /* MAINCTRL_H_ */

*** makefile
**** 如何让obj和可执行文件输出到其他目录
test : test.o
	gcc -o ../bin/test ../lib/test.o

test.o : test.c
	gcc -c  test.c -o ../lib/test.o

clean:
	rm ../bin/test ../lib/*.o 

*** 有用的一些函数
**** system()
system会同步地执行一个应用程序
**** execlp(path, arg1 , arg2, ... ,argn)
同步调用一个程序，path是路径及可执行文件名，arg1，是第一个参数，一般是可执行文件名，后面是后续的参数，最后一个参数一般需要是NULL。
**** dup2(dfA, dfB)
将dfB重定向到dfA ,
如
f=open("a.txt","W");
dup2(f, 1)
本来文件标准输出是指向tty的，通过dup2，标准输出文件就不再指向tty了，而是指向a.txt了

**** pipe
用来创建一个管道，在和fork联合使用后，特别易于做进程间通信！



*** 调用一个脚本
#include <stdio.h>
#include <unistd.h>
#include <fcntl.h> 


#define MAX_BUF_SIZE 100
int testCase1 (void * pData){
    int df[2];
    pid_t pid;
    int res;
    char buffer[MAX_BUF_SIZE + 1];
    int si;
    if (pipe(df)) {
        print("ERROR: pipe failed\n");
        return -1;
    }
    
    pid = fork();
    if (0 == pid){   // child process
        close(df[0]);
        dup2(df[1], 1);
        dup2(df[1], 2);

        execlp("/bin/ls", "ls",  "-al", "/home",  NULL);
        close(df[1]);
        exit(0);
    }
    else if(pid > 0){   // parent process
        wait(pid);
        close(df[1]);
        si = 1;
        while(si > 0){
            si = read(df[0], buffer, MAX_BUF_SIZE);
            buffer[si] = '\0';
            printf(buffer);
        }
        printf("Run the driver install shell finished.\n");
        return 0;
    }
    else if(pid < 0){
        print("ERROR: fork failed.\n");
        return -1;
    }

    return 0;
}

int testCase2 (void * pData){
    printf("run the testcase2 successfully\n");
    return 0;
}


** java
*** 编译运行java程序
1、如何在命令行运行一个class

比如在\目录下面有一个packege名字叫kernal，kernal下面有一个entry的class
那么要运行entry这个class，就应该在\目录下面运行java kernal.entry这样的命令就可以运行到entry这个class




2、如何命令行运行一个jar

 java   -jar   file.jar   

同时这个jar中需要包含一些信息，具体见如下：
示例——生成能通过鼠标双击就执行的.jar文件   
    
  一、编写Java源程序Test.java如下：   
    
  //   Test.java   
    
  import   javax.swing.*;   
    
  /**   
    *   @(#)   Test.java   
    *   Copyleft   (c)   2002   RatKing   
    *   @author   <a   href="ratking@ynet.com">RatKing</a>   
    *   @version   0.1,   2002-11-7   
    *   描述：一个测试用的Java   Application   
    */   
  public   class   Test   extends   JFrame   {   
          public   Test(String   title)   {   
                  super(title);   
                  this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);   
                  this.getContentPane().add(new   JLabel("测试！",   JLabel.CENTER),   SwingConstants.CENTER);   
                  this.pack();   
          }   
    
          public   static   void   main(String[]   args)   {   
                  try   {   
                          //UIManager.setLookAndFeel(UIManager.getCrossPlatformLookAndFeelClassName());   
                          UIManager.setLookAndFeel(UIManager.getSystemLookAndFeelClassName());   
                  }   catch(Exception   e)   {   
                          e.printStackTrace();   
                  }   
                  Test   t   =   new   Test("Test   -   测试");   
                  t.setVisible(true);   
          }   
  }   
    
  二、编译Test.java为Test.class（当然假设你事先已经设置好了JDK的环境变量PATH和CLASSPATH）   
  在命令行执行编译命令：   
  javac   Test.java   
    
  三、用文本编辑器（比如记事本/UltraEdit等   -   甚至用ECHO命令加管道“>>”）编写如下manifest文件，并保存为abc.txt   
    
  Manifest-Version:   1.0   
  Main-Class:   Test   
    
  【注意】文件abc.txt内必须是3行文本：   
  第一行的内容依次是：“Manifest”、英文减号、“Version”、英文冒号、英文空格、数字“1”、英文句号、数字“0”   
  第二行的英文冒号与Test之间必须要有一个英文空格！！！   
  第三行是一个空行，也就是说，你要在Test之后键入一个回车，然后才可以存盘退出！！！   
  如果冒号后面没有空格，可以生成jar文件但不能执行；如果Test后没有回车符，则生成jar文件时会报错。   
    
  四、将Test.class打包成.jar文件，并使用abc.txt指明哪一个是带有public   static   void   main()的“主函数”   
  在命令行执行编译命令：   
  jar   cvfm   Test.jar   abc.txt   *.class   
    
  你可以使用WinZip之类的解压软件看一看刚刚生成的Test.jar文件里到底有什么。   
    
  五、用鼠标双击Test.jar的图标，应该可以看到Test执行后的窗口。   
    
  〖说明〗如果你正确地安装了Java运行环境（JRE），那么.jar的图标应该是象一页纸并有一个A的形状，就如同写字板的图标。   
  如果你的.jar文件默认的打开关联不对，可以重新设置：   
  我的电脑->查看(Win9x)或工具(Win2k)->文件夹选项->文件类型->选择JAR文件->编辑该类型文件的属性->操作栏填入[   open   ](不填引号和中括号[])，并在“执行操作的应用程序”栏填入[   "C:\Program   Files\Java\j2re1.4.1\bin\javaw.exe"   -jar   "%1"   %*   ](填两对英文引号，不填[])   
  并按“确定”、“关闭”退出对.jar文件关联的编辑。   
  （你的javaw.exe文件是不是位于C:\Program   Files\Java\j2re1.4.1\bin\路径下，视你自己电脑的情况而定） 


或者用elipse生成jar的时候注意设置也可以


*** gdbc
@gdbc
3、如何使用gdbc
首先import java.sql.*
然後在odbc上設置數據源，指向access的某个mdb文件，
然后在java程序中通过如下方法建立gdbc的连接（java->gdbc->odbc->mdb）
			Class.forName("sun.jdbc.odbc.JdbcOdbcDriver");
			System.out.println("after class.forName");
			connection = DriverManager.getConnection("jdbc:odbc:Fortest");		查询的时候这样查询	
		    statement  = connection.prepareStatement("select * from fortest1");
		    ResultSet res = statement.executeQuery();
		    while (res.next())
		    {
		        System.out.println(res.getString("name"));
		    }
修改的时候这样修改
		    String sql = "insert into fortest1(ID1,id_2,name_user) values(" + i + ",0," + "'" +str + "')";
		    statement = connection.prepareStatement(sql);
		    statement.executeUpdate();
		    statement.close();
		    connection.commit();
或者
			String sql = "update fortest1 set name_user='" + str +"'";
			sql += "where ID1=" + i;
			statement = connection.prepareStatement(sql);
			statement.executeUpdate();
			statement.close();
			connection.commit();
注意修改后要使用commit来把事务提交
最后要把连接给断掉用connect.close（）;

statement 是一个语句预编译的对象，
connect  面向整个连接，如果调用commit，则是完成一个事务
**** 锁表
4、如何锁表
Access的MDB数据库可以锁住一个表，但能不能只锁住一条记录呢？ 
问题点数：20、回复次数：3
Top
 

1 楼changechange（http://access911.net 是我的个人网站，欢迎光临）回复于 2003-11-20 22:57:18 得分 20可以   
    
    
  注意   adLockOptimistic     常数   
  －－－－－－－－－－－－－－－－－－－－－－－－－   
    
  Open   方法   (ADO   Recordset)   
                
    
  打开游标。   
    
  语法   
    
  recordset.Open   Source,   ActiveConnection,   CursorType,   LockType,   Options   
    
  参数   
    
  Source       可选。Variant，计算有效的   Command   对象、SQL   语句、表名、存储过程调用、URL   或包含持久存储的   Recordset   的文件或   Stream   对象的名称。   
    
  ActiveConnection       可选。Variant   或   String，Variant   用于计算有效的   Connection   对象变量的名称；String   包含   ConnectionString   参数。   
    
  CursorType       可选。CursorTypeEnum   值，确定当打开   Recordset   时提供者应使用的游标类型。默认值为   adOpenForwardOnly。   
    
  LockType       可选。LockTypeEnum   值，确定打开   Recordset   时提供者应使用的锁定类型（并发）。默认值为   adLockReadOnly。   
    
  Options       可选。Long   值，指示如果   Source   参数表示的不是   Command   对象，提供者应如何计算该参数；或者指示应从先前保存   Recordset   的文件中恢复   Recordset。可以是一个或者多个   CommandTypeEnum   或   ExecuteOptionEnum   值。   
    
  注意       如果从包含持久   Recordset   的   Stream   中打开   Recordset，那么使用   adAsyncFetchNonBlocking   的   ExecuteOptionEnum   值将不起作用；提取将同步进行并阻塞。   
    
  说明   
    
  用   Recordset   对象的   Open   方法打开表示记录的游标，这些记录来自基本表、查询结果或先前保存的   Recordset。   
    
  用可选的   Source   参数指定使用下列内容之一的数据源：Command   对象变量、SQL   语句、存储过程、表名、URL   或完整的文件路径名。如果   Source   是文件路径名，它可能是完整路径（“c:\dir\file.rst”）、相对路径（“..\file.rst”）或   URL（“http://files/file.rst”）。   
    
  ActiveConnection   参数对应于   ActiveConnection   属性，并指定在哪个连接中打开   Recordset   对象。如果传递此参数的连接定义，ADO   将用指定的参数打开新连接。打开   Recordset   后，可以更改此属性的值以便将更新发送到另一个提供者。或者，可以将此属性设置为   Nothing（在   Microsoft   Visual   Basic   中）以断开   Recordset   与所有提供者的连接。   
    
  对于直接对应于   Recordset   对象的属性的其他参数（Source、CursorType   和   LockType），参数与属性的关系如下：     
    
  打开   Recordset   对象前，属性为读/写。   
    
    
  只有在执行   Open   方法过程中传递对应参数时，才使用该属性设置。如果传递某个参数，它将覆盖对应的属性设置，属性设置将用该参数值进行更新。   
    
    
  打开   Recordset   对象后，这些属性变为只读。     
  注意       对于其   Source   属性被设置为有效   Command   对象的   Recordset   对象，即使   Recordset   对象未打开，ActiveConnection   属性也是只读的。     
    
  如果在   Source   参数中传递   Command   对象并且传递   ActiveConnection   参数，将发生错误。Command   对象的   ActiveConnection   属性必须已被设置为有效的   Connection   对象或连接字符串。   
    
  如果在   Source   参数中传递的不是   Command   对象，可以用   Options   参数优化   Source   参数的计算。如果未定义   Options   参数，系统性能将会降低，因为   ADO   必须调用提供者来确定该参数是   SQL   语句、存储过程、URL   还是表名。如果知道正在使用的   Source   的类型，设置   Options   参数可以指示   ADO   直接跳至相关代码。如果   Options   参数与   Source   类型不匹配，将发生错误。   
    
  如果在   Source   参数中传递   Stream   对象，不应将信息再传递到其他参数。   
    
  否则将产生错误。   
    
  如果从   Stream   打开   Recordset，将不保留   ActiveConnection   信息。   
    
  如果没有与   Recordset   相关联的连接，Options   参数的默认值将为   adCmdFile。对于持久存储的   Recordset   对象尤其如此。   
    
  如果数据源未返回记录，提供者将把   BOF   和   EOF   属性都设置为   True，并且未定位当前记录的位置。如果游标类型允许，仍可向此空   Recordset   对象中添加新数据。   
    
  如果已经结束对打开的   Recordset   对象的操作，使用   Close   方法释放所有相关联的系统资源。关闭对象并不是将对象从内存中删除，将来还可以更改其属性设置并使用   Open   方法再次打开。若要从内存中彻底删除对象，请将对象变量设置为   Nothing。   
    
  在设置   ActiveConnection   属性之前，调用不带操作数的   Open   通过向   Recordset   Fields   集合中追加字段来创建一个   Recordset   的实例。   
    
  如果已将   CursorLocation   属性设置为   adUseClient，可以用两种方式之一异步检索行。推荐方法是将   Options   设置为   adAsyncFetch。另外，也可以使用   Properties   集合中的“Asynchronous   Rowset   Processing”动态属性，但如果未将   Options   参数设置为   adAsyncFetch，则可能导致已检索的相关事件丢失。   
    
  注意       只有通过   Open   方法的   Options   参数才能支持   MS   Remote   提供者中的后台提取。   
  －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－   
  LockTypeEnum   
          
    
  指定在编辑过程中记录上的锁定类型。   
    
  常量   值   说明     
  adLockBatchOptimistic     
    4   指示开放式批更新。需要批更新模式。     
  adLockOptimistic     
    3   指示逐个记录开放式锁定。提供者使用开放式锁定，仅在调用   Update   方法时锁定记录。     
  adLockPessimistic     
    2   指示逐个记录保守式锁定。提供者要确保记录编辑成功，通常在编辑之后立即在数据源锁定记录。     
  adLockReadOnly     
    1   指示只读记录。无法改变数据。     
  adLockUnspecified     
    -1   未指定锁定类型。创建副本时，副本与源对象使用相同的锁定类型。     
    
    
    
  ADO/WFC   等价内容   
    
  包：com.ms.wfc.data   
    
  常量     
  AdoEnums.LockType.BATCHOPTIMISTIC     
  AdoEnums.LockType.OPTIMISTIC     
  AdoEnums.LockType.PESSIMISTIC     
  AdoEnums.LockType.READONLY     
  AdoEnums.LockType.UNSPECIFIED     
    
  
Top

2 楼aycn（木乃伊）回复于 2003-11-21 13:45:51 得分 0 用   adLockOptimistic   不行，我试过了，在SQL   Server就可以，   
  在Access它也会锁定，不过是锁定整个表。
*** java获取时间
@time  @date  @时间


3、java中如何获取系统时间
第一种方式：     
  <html>     
  <head><title>取得系统时间</title></head>     
  <body>     
  <%java.util.Date   date=new   java.util.Date();%>     
  现在是：<%=date%>     
  </body>     
  </html>     
  运行结果：     
  现在是：Tue   Jul   31   10:32:52   CST   2001     
    
  第二种方式：     
  <%@   page   import="java.util.*,   java.text.*"   %>     
  <HTML>     
  <HEAD><TITLE>显示当前时间</TITLE></HEAD>     
  <BODY>     
  当前时间：     
  <%     
  Date   now   =   new   Date();     
  out.println(DateFormat.getTimeInstance().format(now));     
  %>     
  </BODY>     
  </HTML>     
  运行结果：     
  10:31:42   AM  


** makefile
*** 在脚本行的头上加上'-'，这行的错误会忽略

** common-lisp

*** sbcl
安装common-lisp要装sbcl
*** asdf
(require 'asdf)

(setf asdf:*central-registry*
      '(*default-pathname-defaults*
    #p"/path/to/asd/file/directory/"))

asdf:*central-registry*是一个指向一个url的变量，在这个url下，你可以放一些asd的链接
如
$ cd /path/to/asdf/file/directory
$ ln -s ../cl-ppcre/cl-ppcre.asd .
然后
(asdf:operate 'asdf:load-op 'cl-ppcre)

当然也可以
(require 'asdf)
(asdf:operate 'asdf:load-op 'asdf-install) 
(asdf-install:install 'cl-ppcre) #从网上自动下载asdf-install至一个临时目录，再解开，将asd文件的链接放到应该放的地方
(asdf:operate 'asdf:load-op 'cl-ppcre)

* Linux

** ubuntu
*** 安装man手册
@man

sudo apt-get install binutils-doc cpp-doc gcc-4.0-doc gcc-doc glibc-doc libstdc++6-4.0-doc stl-manual   cpp-4.0-doc manpages manpages-dev
*** samba
+ server
@samba

1 apt-get install samba

2 编辑/etc/samba/ smb.conf 增加如下内容
[myshare]
path=/home/wyao/samba_share
public=no
valid users=wyao


3 在samba中增加wyao这个对象
smbpasswd -a wyao

4 重新启动samba
/etc/init.d/samba restart


+ client
@samba  @smb

假定您的网络连接已经正确设定好。

网络主机的 IP: 192.168.0.1

网络主机的使用者名称: myusername

网络主机的登录密码: mypassword

分享中的目录名称: linux

主机上要挂载的目录: /media/sharename

 

要挂载网络共享目录时

sudo mkdir /media/sharename

sudo mount //192.168.0.1/linux /media/sharename/ -o username=myusername,password=mypassword,dmask=777,fmask=777

 

要卸载网络共享目录时

sudo umount /media/sharename/

======================更简单访问windows目录=============================

1、安装samba和smbfs

sudo apt-get install samba
sudo apt-get install smbfs

2、打开一个文件浏览窗口，按快捷键ctrl + L，输入smb://192.168.0.*既可以访问windows的共享目录了。当然会要求输入访问用户名和密码，正确输入后就可以访问了。

*** 常用安装
sudo apt-get install ntfs-3g ntfs-config #ntfs写入支持，装完后运行ntfs-config,把两个钩打上即可。楼下方法作废
sudo apt-get install googleearth googlizer gtalk#google相关，skyx友情提示:不推荐马甲 gtalk
sudo apt-get install ghex #GNOME 上的十六进制文件编辑器
sudo apt-get install kvm #Full virtualization on x86 hardware 华主席推荐
sudo apt-get install vmware-player #Free virtual machine player from VMware
sudo apt-get install makeself #utility to generate self-extractable archives
sudo apt-get install sun-java6-jre#安装JAVA6环境
sudo apt-get install sun-java6-jdk #安装JAVA6环境#
sudo update-alternatives --config java#设定JAVA环境
sudo apt-get install rox-filer#一个简单的文件管理软件
sudo apt-get install socks4-server socks4-clients #一个socks 代理服务器/soks4代理客户端
sudo apt-get install mc #类似norton commander 工具，skyx 吐血推荐
sudo apt-get install liferea #超强的rss reader ，明显比akregator好用，由zhuqin_83吐血推荐
sudo apt-get install axel-kapt gwget aria2#多线程下载工具,也可在论坛search 超强工具prozilla，由雕啸长空吐血推荐
sudo apt-get install privoxy tor mixmaster anon-proxy socat#突破风锁线和雁过无痕
sudo apt-get install kdebluetooth #超简单的ubuntu与蓝牙手机互传文件工具
#蓝牙请参见：　　　http://forum.ubuntu.org.cn/viewtopic.php?t=61426&;highlight=
sudo apt-get install build-essential #build-essential
sudo apt-get install proxychains #一个socks4 socks5代理软件，可以支持apt-get代理
sudo apt-get install language-support-zh language-pack-zh#安装中文语言支持
sudo apt-get install stardict stardict-common stardict-cdict-gbstardict-cedict-gb stardict-hanzim stardict-langdao-ce-gbstardict-langdao-ec-gb stardict-oxford-gb stardict-xdict-ce-gbstardict-xdict-ec-gb stardict-jcedict stardict-jedictstardict-jmdict-en-ja stardict-jmdict-ja-en wyabdcrealpeopletts#安装StarDict
sudo apt-get install rxvt yakuake tilda kuake konsole multi-gnome-terminal pyqonsole #几个终端
sudo apt-get install viewglob #一个shell相关的工具
sudo apt-get install nautilus-open-terminal #在右键菜单中加入打开终端
sudo apt-get instll eva amsn wengophone skype licq #安装im语音视频聊天软件
sudo apt-get install beryl emerald emerald-themes#安装beryl
sudo apt-get install pcmanx-gtk2 qterm mozilla-plugin-pcmanx #安装bbs 客户端
sudo apt-get install gkrell* #很好的一个东东，装了就知道了
sudo apt-get install conky# 有意思的一个系统monitor
sudo apt-get install nmapfe #nmap前端
sudo apt-get install meld #一个文件、目录比较器
sudo apt-get install imagemagick# e主席(ee)大力推荐的批量修改图片的软件，现在论坛个别人在搞个人崇拜
sudo apt-get install kolourpaint #又一个画图软件
sudo apt-get install tuxpaint #好玩的画图软件
rgbpaint #getdeb上有，最弱，但很小巧的画图软件
mtpaint（getdeb上有，比gpaint强一点的画图软件）。
sudo apt-get install kompare # 又一个文件比较器
sudo apt-get install gnome-commander #gnome 上类似Total commander的工具
sudo apt-get install krusader #kde 上类似Total commander的工具
sudo sudo apt-get install bum #系统服务管理软件
sudo apt-get install rbot # ruby写的irc bot
sudo apt-get install sysv-rc-conf #一款基于perl的开机进程调整工具,sysv-rc-conf执行命令即可
sudo apt-get install rcconf # Debian Runlevel configuration tool
sudo apt-get install rar unrar p7zip* #安装rar 7zip
sudo apt-get install rpm alien #安装rpm支持
sudo apt-get install xpdf xpdf-chinese-simplified #安装pdf查看软件
sudo apt-get install xchm xpdf-chinese* #安装chm查看软件
sudo apt-get install chmsee 也是不错的看chm的软件。
sudo apt-get install gqview #一个图片浏览器
sudo apt-get install gnomebaker k3b#安装刻录软件
sudo apt-get install brasero #gnome上的刻录软件
sudo apt-get install ksnapshot #一个抓屏程序
sudo apt-get install kinstaller #application installer
sudo apt-get install vncserver #vncserver,vncview默认已经安装了
sudo apt-get install tightvncserver tightvnc-java #另一个vnc
sudo apt-get install apt-build #frontend to apt to build, optimize and install packages
sudo apt-get install vim-full #vim无法高亮显示,然后编辑 /etc/vim/vimrc,取消syntax on前面的"注释符号
sudo apt-get install firestarter #图形接口的防火墙设定程序
sudo apt-get install smbfs #smbfs挂载支持
sudo apt-get install flashplugin-nonfree #安装浏览器Flash插件
sudo apt-get install gftp kftpgrabber filezilla kasablanca#安装ftp客户端
sudo apt-get install sun-java5-jdk #安装Java环境
sudo apt-get install sun-java5-plugin #安装Java环境
sudo apt-get install build-essential # 安装编译环境
sudo apt-get install yum rpm #redhat相关
sudo apt-get install mysql-client mysql-server #安装mysql服务
sudo apt-get install kde-i18n-zhcn kde-i18n-zhtw#k程序中文支持，很讨厌kde ,但不太讨厌qt程序可以这样装
sudo apt-get install qt4-qtconfig#qt4 gui配制工具, 如字体等，很讨厌kde ,但不太讨厌qt程序可以这样装
sudo apt-get install kcontrol #k程序gui配制工具，很讨厌kde ,但不太讨厌qt程序可以这样装
sudo apt-get apache2 mysql-server php4 php4-gd php4-mysql #安装LAMP
sudo apt-get install d4x azureus amule ktorrent mldonkey-servermldonkey-gui rtorrent qtorrent bittornado-gui bittorrent-guitorrentflux deluge-torrent# 几个下载/bt/电驴 工具
sudo apt-get install sysstat #安装sar, iostat and mpstat
sudo apt-get install nmap #网络端口扫描工具
sudo apt-get install nfs-common #nfs
sudo apt-get install samba nfs-kernel-server #samba
sudo apt-get install xvidcap gnome-splashscreen-manager #安装屏幕视频录制 / splash 管理
sudo apt-get install istanbul #Desktop session recorder
sudo apt-get install sysinfo xsysinfo#系统信息查看


网络
[pre]$ sudo apt-get install d4x //这是linux上的flashget，在apt中可以找到
$ sudo apt-get install amule //这是linux上的emule，在apt中可以找到
$ sudo apt-get install eva //这是linux下的qq，只不过狡猾的腾讯修改了协议，用了eva以后再用就必须输入验证码才能进入，但eva并不支持验证码，所以最终的结果就是eva再也没法用了。
$ sudo apt-get install tor privoxy //匿名动态代理，与之类似的还有JAP和freedom，据说freedom速度更快一些
$ sudo apt-get install liferea //一个GTK的离线RSS阅读器
$ sudo apt-get install curl //一个利用URL语法在命令行下工作的文件传输工具
[/pre]

系统
[pre]$ sudo apt-get install rar //安装rar支持，装了以后，压缩包管理器就可以支持rar格式了
$ sudo apt-get install bum //一个不错的安装系统启动程序管理器
$ sudo apt-get install xpdf-chinese-simplified  //xpdf的中文字体支持，不过经过试用，貌似乱码依旧，这个问题可以参考ubuntu 下Evince看pdf文档的乱码解决方案
$ sudo apt-get install gnome-commander //类似norton-commander的文件管理器，功能还不错，比较适合用惯了norton-commander的用户
$ sudo apt-get install nautilus-open-terminal //在nautilus的右键菜单里打开终端，要重登录才起效
$ sudo apt-get install nautilus-gksu //在nautilus中以管理员身份打开，要重登录才起效
$ sudo apt-get install ntp //系统时间与internet时间保持同步
$ sudo apt-get install meld //基于gonme的目录差异比较工具，可以比较文件夹和文件的变化
$ sudo apt-get install enca //一个非常不错的编码转换工具
$ sudo apt-get install keepassx //一个密码管理软件，具有windows版本和linux版本
$ sudo apt-get gparted //图形化分区工具
$ sudo apt-get install gcolor2 //一个不错的基于gtk的图形化吸取颜色的工具。
$ sudo apt-get install unison-gtk //一个基于gtk的文件和目录同步工具，具有比较和合并功能。
$ sudo apt-get install conduit //一个很牛的资源同步工具，可以同步网络相册，文件夹，邮件、照片等等资源，非常牛X
$ sudo apt-get install manpages-zh //中文man手册，linux操作系统的必备资料
[/pre]
办公软件
[pre]$ sudo apt-get install scribus //一个类似microsoft publisher的排版软件
$ sudo apt-get install kchmviewer-nokde //一个看chm的小软件，支持中文，只是安装后只能用命令行启动，执行kchmviewer即可
[/pre]
多媒体
[pre]$ sudo apt-get install ksnapshot //抓图工具
$ sudo apt-get install ogle ogle-gui  //dvd 播放器
$ sudo apt-get install mkisofs //貌似是和刻录光盘有关
$ sudo apt-get install wink //一个屏幕录像工具，可以用来制作视频教程
$ sudo apt-get install gsopcast //一个网络电视
$ sudo apt-get install gonmebaker //一个gonme下的刻录光盘软件
$ sudo apt-get install isomaster //一个管理和生成ISO镜像的小工局，可以提取、修改、删除添加文件，功能挺全的。
$ sudo apt-get krita //一个小巧的图像编辑软件，比GIMP小巧，但功能对付一般的照片修改已经足够了。
$ sudo apt-get install xaralx imagemagick //一个巨好的免费矢量图绘制工具，功能不是一般的强，windows下收费，linux下免费。
$ sudo apt-get install gnome-subtitles //linux下的divx电影的字幕调校工具，可视化的哦
[/pre]
游戏
$ sudo apt-get install wormux //百战天虫linux版，据本人体验，比起百战天虫差不少
[pre]$ sudo apt-get install assaultCube //一个类似CS的FPS游戏，不过据本人体验，效果比起CS差远了
$ sudo apt-get install glest glest-data //一个类似魔兽争霸的3D即时战略游戏，相当不错，强烈推荐。
*** virtualbox
**** network
@virtualbox  @vbox  @ifconfig @tunctl  @brctl  @dhclient

其中 方案二 : Transparent Bridge (Layer 2)  很经典
将方案二的脚本加入到root 的 .bashrc


文章标题 : [转帖]VirtualBox网络配置详解
帖子发表于 : 2007-03-02 16:22 

注册: 2005-12-25 1:42
帖子: 84 	
欢迎转载, 转载请注明作者, 谢谢

下面简单介绍一下Test-bed Environment:

Host : 偶的本本
OS : Arch Linux (Kernel Version 2.6.20) 已安装uml_utilities(包含tunctl工具)和bridge-utils(包含brctl工具)两个包.
Username : leemars
LAN IP : 192.168.1.106/24
Interface : ath0

Guest : 偶的本本上的一个虚拟机
OS : Win2003
Host Interface : tap0

Non-Host : 偶的台式机
OS : WinXP
LAN IP : 192.168.1.120/24

Wireless Router:
LAN IP : 192.168.1.1/24 Gateway
WAN IP : 172.18.60.55/24 绑定MAC
Router开启了DHCP

Network Environment :
Non-Host直接接在无线路由上, Host通过无线网卡与无线路由连接. 无线路由开启了DHCP功能.

===================================

最简单的方案 : NAT(by VirtualBox)

Host :
直接使用VirtualBox提供的NAT功能.

Guest :
网卡设置为使用DHCP.

Guest -> WAN :
由VirtualBox的NAT提供WAN的访问服务.

Guest -> Host :
需要注意的是, 如果直接访问Guest拿到的网关IP, 会发现这个IP似乎是Host. 不过事实上不能直接访问网关IP来访问Host. 因为这个IP是由VirtualBox负责的, 只实现了NAT的功能, 其他的一些功能并不能正常运行(如FTP). 如果要访问Host, 应该访问Host的真实IP.

Host -> Guest :
不可访问. 虽然VirtualBox的NAT功能中包括了Port Forwarding的功能, 但截至到1.3.6 Snapshot, 这个功能仍没有出现在GUI中. 不过在OSE Version中已经可以使用这个功能. 通过Port Forwarding可以实现部分的向内访问.

VirtualBox NAT没有什么玩法了. 下面的方案都是使用VirtualBox的Host Interface功能.

-----------------------------------------------------------------------------
方案一 : NAT(by Linux) + Route

Host :
#echo 1 > /proc/sys/net/ipv4/ip_forward #打开转发功能
#iptables -t nat -A POSTROUTING -j MASQUERADE #利用iptables完成NAT功能

#chmod 0666 /dev/net/tun #设置访问权限
#tunctl -t tap0 -u leemars #建立一个tap设备, 名字为tap0, 所有者为leemars
#ifconfig tap0 up #激活tap0
#ifconfig tap0 10.10.10.1 netmask 255.255.255.0 #为tap0指定IP和网段, 为10.10.10.1/24.

Guest :
网卡设置如下:
IP : 10.10.10.10
Netmask : 255.255.255.0
Gateway : 10.10.10.1

Guest -> WAN :
由Linux的iptables完成NAT功能, 提供WAN的访问服务.

Guest -> Host :
10.10.10.1是真实的Host. Guest对Host的任何访问都可以通过访问10.10.10.1来完成.

Host -> Guest :
10.10.10.10是真实的Guest. Host对Guest的任何访问都可以通过访问10.10.10.10来完成.

Non-Host -> Guest :
因为Guest是在Host的NAT之后的一个私有子网中, 所以直接访问是不行的. 不过可以通过iptables来完成Port Forwarding, 实现部分的向内访问.

-----------------------------------------------------------------------------

方案二 : Transparent Bridge (Layer 2)

在我的机器上测试下来的结果很遗憾, 无线网卡似乎不能配合Bridge工作. 建好Bridge之后, Guest只能访问Host, 连网关都访问不到. 所以我改用有线网卡来进行测试, 有线网卡为eth0, IP地址同ath0.

Host :

#chmod 0666 /dev/net/tun #设置访问权限
#tunctl -t tap0 -u leemars #建立一个tap设备, 名字为tap0, 所有者为leemars

#ifconfig eth0 0.0.0.0 promisc #使eth0进入promiscuous模式
#ifconfig tap0 0.0.0.0 promisc #使tap0进入promiscuous模式
#brctl addbr br0 #增加一个网桥
#brctl addif br0 eth0 #将eth0加入网桥
#ifconfig eth0 up #激活eth0
#dhclient br0 #为br0设置IP地址
#brctl addif br0 tap0 #将tap0加入网桥
#ifconfig tap0 up #激活tap0

Guest :
网卡设置为DHCP. 或者在设置为Host的Subnet中的一个IP地址, 如下例:
IP : 192.168.1.201
Netmask : 255.255.255.0
Gateway : 192.168.1.1

Guest -> WAN :
由网关提供WAN的访问服务.

Guest -> Host :
直接访问Host的IP地址即可.

Host -> Guest :
直接访问Guest的IP地址即可.

Non-Host -> Guest :
直接访问Guest的IP地址即可.
(由于建立了eth0和tap0的Bridge, Non-Host的ARP包被eth0接收到后, 被Brideg转发至tap0上, 数据链路得以建立.)

-----------------------------------------------------------------------------

方案三 : Transparent IP (Layer 3) proxy ARP bridge (by parprouted)

Host :
#echo 1 > /proc/sys/net/ipv4/ip_forward #打开转发功能

#chmod 0666 /dev/net/tun #设置访问权限
#tunctl -t tap0 -u leemars #建立一个tap设备, 名字为tap0, 所有者为leemars
#ip link set tap0 up #激活tap0
#ip addr add 169.1.1.1/32 dev tap0 #为tap0任意指定一个私有地址
#parprouted [-d] ath0 tap0 #启动parprouted监听ath0和tap0. -d参数为Debug模式

Guest :
网卡设置如下:
IP : 192.168.1.201
Netmask : 255.255.255.0
Gateway : 192.168.1.1

Guest -> WAN :
由网关来提供WAN的访问服务.

Guest -> Host :
直接访问Host的IP地址即可.

Host -> Guest :
直接访问Guest的IP地址即可.

Non-Host -> Guest :
直接访问Guest的IP地址即可.

Troubleshooting:
这个parprouted软件有时会出现无法连通的情况. 这时可以尝试更换Guest的IP地址来解决问题. 这个貌似是parprouted软件的BUG.

-----------------------------------------------------------------------------

方案四 : ARP Proxy(by Linux) + Route

Host :
#echo 1 > /proc/sys/net/ipv4/ip_forward #打开转发功能

#chmod 0666 /dev/net/tun #设置访问权限
#tunctl -t tap0 -u leemars #建立一个tap设备, 名字为tap0, 所有者为leemars
#ip link set tap0 up #激活tap0
#route add -host 192.168.1.201 dev tap0 #增加一个路由, 将192.168.1.201定向到tap0
#echo 1 > /proc/sys/net/ipv4/conf/ath0/proxy_arp #打开ath0上的ARP Proxy
#echo 1 > /proc/sys/net/ipv4/conf/tap0/proxy_arp #打开tap0上的ARP Proxy

Guest :
网卡设置如下:
IP : 192.168.1.201
Netmask : 255.255.255.0
Gateway : 192.168.1.1

Guest -> WAN :
由网关来提供WAN的访问服务.

Guest -> Host :
直接访问Host的IP地址即可.

Host -> Guest :
直接访问Guest的IP地址即可.

Non-Host -> Guest :
直接访问Guest的IP地址即可.

作者：leemars（linuxsir论坛）

原文位于：http://www.linuxsir.org/bbs/showthread.php?t=293771


	
页首 
**** 安装
@virtualbox  @vbox

   下载DEEPIN-LITEXP-6.2.iso
       virtualbox_1.6.6-35336_Ubuntu_hardy_amd64.deb

    安装sudo apt-get install libxalan110 libqt3-mt 

    安装  sudo dpkg -i virtualbox_1.6.6-35336_Ubuntu_hardy_amd64.deb


    安装 sudo apt-get install build-essential
        sudo apt-get install linux-headers-$(uname -r) 


    将自己的用户加入到virtualbox用户组  sudo usermod -G vboxusers -a 您的登录名称

    重新编译内核sudo /etc/init.d/vboxdrv setup


    删除配置文件/home/wyao/.VirtualBox/VirtualBox.xml

    reboot

    ok
**** usb
@vbox @virtualbox  @usb


 Re: USB Error In VirtualVox NS_ERROR_FAILURE (0x00004005)
Copy and paste this into a root (i.e. sudo bash) terminal
Code:

VBOX=$(grep vboxusers /etc/group | sed 's/vboxusers:x:\(.*\):.*/\1/')
mount -t usbfs -o devgid=$VBOX,devmode=664,nodev,noexec,nosuid none /proc/bus/usb

QB89Dragon is offline   	Reply With Quote

*** x-windows
+ 序列号
@xmanager @序列号
Serial:100501-116431-000686
Serial:100501-116421-000966
Serial:100501-156941-000646
Serial:100501-156991-000134
Serial:100501-116391-000542

xmanager4   101210-450789-147200

+ 安装
@xwindow

# apt-get install xserver-xorg 
# apt-get install x-window-system-core 
# dpkg-reconfigure xserver-xorg 
# apt-get install gnome-core 
# apt-get install gdm xscreensaver 
# apt-get install ttf-arphic* 
# startx



需要gdm -configure
然后把生成的gdm.conf.new拷贝到/etc/gdm/gdm/gdm.conf


xmanager的配置
用xmanager的xstart来启动，
  ssh 
 /usr/bin/gnome-session --display $DISPLAY

$DISPLAY要配置为windows的ip地址
advanced 选项里面用xdmcp

有的时候gnome-session会启动失败，有时会出现空白的desktop的情况。
也不知道是怎么造成的，对于这种情况，我直接在用被动xmanager，然后用putty登陆到ubuntu上直接执行gnome-panel，就可以在windows上出现ubuntu的窗体，不过是分裂独立的方式展开的，这样也能用，也没有什么不好的。



+ 原理文章
Linux跨网络运行X Window程序798173375 2008-11-19 12:23:14    收藏  |  打印  | 投票(14)  |  评论(1)  |  阅读(74815)  ◇字体：［大 中 小］Linux跨网络运行X Window程序Sat, 2006-04-22 16:09 — Marchday 
X Window在设计上就是跨网络的,X Client是需要图形显示的应用程序, X Server则负责具体显示和传递用户交互行为。二者之间通信的协议称为 X Protocol，X协议。

基于主机验证的X Window配置

(1) 在X Server端，加入允许发送X Request的机器地址。

$ xhost +192.168.0.1关于xhost的用法示例：

$ xhost -192.168.0.1 #取消192.168.0.1发送X Request到本机$ xhost + #允许所有主机发送X Request到本机$ xhost + #再次执行该命令取消允许所有主机的授权此外，可在/etc/X*.hosts中永久加入某些授权主机，其中*是本机显示编号，比如X0.hosts。细节可看man xhost的说明。

192.168.0.1192.168.0.2(2) 现在，就可以ssh(可能需要配置ssh转发X11数据，我没尝试过)或者telnet到X Client机器，并运行X Window应用程序，而显示和操作在X Server端。

$ xeyes -display 192.168.0.254:0其中192.168.0.254是（1）中配置的主机，后面的:0表示发送到0号显示屏幕。有些X程序不支持-display参数，此时可考虑导出DISPLAY环境变量。

$ export DISPLAY=192.168.0.254:0也许你会问，一台机器可以有多个显示屏幕吗？有的，默认启动的屏幕为0，不过你还可以启动多个。对于gdm启动X Window的方式，你可以修改/etc/X11/gdm/gdm.conf：

0=/usr/bin/X11/X -bpp 8 vt71=/usr/bin/X11/X -bpp 8 vt9...-bpp.参数指定颜色数，此处为8位色深。vt7表示Ctrl+Alt+F7可切换到该屏幕，vt9表示Ctrl+Alt+F9。你可以指定任意数目的显示屏幕。

如果要配置不同屏幕的登录界面，可执行如下操作：

$ cp /etc/X11/gdm/Init/Default /etc/X11/gdm/Init/:0$ cp /etc/X11/gdm/Init/Default /etc/X11/gdm/Init/:1然后可修改其中的配置命令。

对于startx启动X Window的方式，可直接在命令行指定，比如 startx -- :1。

基于每用户验证的X Window配置

基本步骤是：先在X Server端的用户目录生成用户的cookie，然后把该cookie加入到X Client的用户目录。这样X Client程序运行的时候，会根据当前的DISPLAY搜寻cookie信息，并发送到X Server，从而得到验证。

因此，首先需要在X Server端生成cookie，可用xauth命令。

$ xauthUsing authority file /home/yingyuan/.Xauthorityxauth>list192.168.0.199/unix:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341xauth>add 192.168.0.199:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341xauth>list192.168.0.199/unix:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341192.168.0.199:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341xauth>exit系统原来就有了一个cookie，我们用add命令新加了一个。

那么，如何把cookie传递给X Client呢？实现方法有三种，以下分别介绍。

(1) 直接把~/.Xauthority从X Server复制为X Client下的~/.Xauthority。这是最简单的实现办法。

(2) 用xauth的extract和merge命令。

在X Server端，

$ xauth...xauth>extract MyCookie 192.168.0.199:0xauth>exit然后我们把MyCookie文件传到X Client，并在X Client运行如下命令，

$ xauth...xauth>merge MyCookiexauth>exit(3) 记下X Server端的cookie值(用xauth的list可查看)，

$ xauth...xauth>list192.168.0.199/unix:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341192.168.0.199:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341xauth>exit然后在X Client用xauth的add添加到.Xauthority文件。

$ xauth...xauth>add 192.168.0.199:0 MIT-MAGIC-COOKIE-1 8432567fa3ae2341xauth>exitX Window为我们运行程序提供了很大的灵活性，不是一般的GUI操作系统所能比拟的。Microsoft Windows可以通过运行X OnNet、X-WinPro、Omni-X等程序提供X Server服务，从而可以运行Linux上的X Client程序。

=========================================

Error: can''t open display!


========================================


在Linux/Unix类操作系统上, DISPLAY用来设置将图形显示到何处. 直接登陆图形界面或者登陆命令行界面后使用startx启动图形, DISPLAY环境变量将自动设置为:0:0, 此时可以打开终端, 输出图形程序的名称(比如xclock)来启动程序, 图形将显示在本地窗口上, 在终端上输入printenv查看当前环境变量, 输出结果中有如下内容: 



DISPLAY=:0.0 

使用xdpyinfo可以查看到当前显示的更详细的信息. 

DISPLAY 环境变量格式如下hostname: displaynumber.screennumber,我们需要知道，在某些机器上，可能有多个显示设备共享使用同一套输入设备，例如在一台PC上连接两台CRT显示器，但是它们只共享使用一个键盘和一个鼠标。这一组显示设备就拥有一个共同的displaynumber，而这组显示设备中的每个单独的设备则拥有自己单独的 screennumber。displaynumber和screennumber都是从零开始的数字。这样，对于我们普通用户来说， displaynumber、screennumber就都是0。 hostname指Xserver所在的主机主机名或者ip地址, 图形将显示在这一机器上, 可以是启动了图形界面的Linux/Unix机器, 也可以是安装了Exceed, X-Deep/32等Windows平台运行的Xserver的Windows机器. 如果Host为空, 则表示Xserver运行于本机, 并且图形程序(Xclient)使用unix socket方式连接到Xserver, 而不是TCP方式. 使用TCP方式连接时, displaynumber为连接的端口减去6000的值, 如果displaynumber为0, 则表示连接到6000端口; 使用unix socket方式连接时则表示连接的unix socket的路径, 如果displaynumber为0, 则表示连接到/tmp/.X11-unix/X0 . screennumber则几乎总是0. 

如果使用su username或者su - username切换到别的用户, 并且使用命令

export DISPLAY=:0.0 

设置DISPLAY环境变量, 运行图形程序(如xclock)时会收到如下错误: 

Xlib: connection to ":0.0" refused by server
Xlib: No protocol specified

Error: Can''t open display: :0.0 

这是因为Xserver默认情况下不允许别的用户的图形程序的图形显示在当前屏幕上. 如果需要别的用户的图形显示在当前屏幕上, 则应以当前登陆的用户, 也就是切换身份前的用户执行如下命令

xhost + 

这个命令将允许别的用户启动的图形程序将图形显示在当前屏幕上. 

在2台Linux机器之间, 如果设置服务器端配置文件/etc/ssh/sshd_config中包含

X11Forwarding no 

客户端配置文件/etc/ssh/ssh_config包含

ForwardX11 yes 

则从客户端ssh到服务器端后会自动设置DISPLAY环境变量, 允许在服务器端执行的图形程序将图形显示在客户端上. 在服务器上查看环境变量显示如下(这个结果不同的时候并不相同)

DISPLAY=localhost:10.0 

在客户机上用netstat -lnp可以看到有程序监听了6010端口

tcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN     4827/1 

如 果希望允许远程机器上的图形程序将图形显示在本地机器的Xserver上, 除了要设置远端机器的DISPLAY环境变量以外, 还需要设置本地机器的Xserver监听相应的TCP端口. 而现在的Linux系统出于安全的考虑, 默认情况下不再监听TCP端口. 可通过修改/etc/X11/xinit/xserverrc文件, 将

exec /usr/bin/X11/X -dpi 100 -nolisten tcp 

修改为

exec /usr/bin/X11/X -dpi 100 

允许在直接使用startx启动图形时启动对TCP端口的监听. 

修改/etc/kde3/kdm/kdmrc, 将

ServerArgsLocal=-nolisten tcp 

修改为

ServerArgsLocal= 

允许kdm作为显示管理器时, 启动会话时监听相应的TCP端口. 

修改/etc/gdm/gdm.conf, 在[Security]一节增加

DisallowTCP=false 

或者在登陆窗口选择"Options" -> "Configure Login Manager..."的Security页面, 取消"Deny TCP connections to Xserver", 允许gdm作为显示管理器时, 启动会话时监听相应的TCP端口.
*** deb
@deb  @dpkg

http://blog.sina.com.cn/s/blog_4befea430100bad1.html


Linux安装软件有关的命令(dpkg 安装deb包)(2008-11-17 16:36:29)转载标签：it  
dpkg(底层一些的包管理工具,用上apt（高级包管理工具）之后，一般是不需要处理单个的deb文件的。如果需要，就要用dpkg命令)
1.dpkg -i gedit-2.12.1.deb:安装gedit
2.dpkg -r gedit:卸载gedit,但不删除配置文件
3.dpkg -P gedit:这会连同gedit的配置文件一起删除，只用-r的话是不删除配置文件的
4.dpkg -c gedit-2.12.1.deb:如果不想安装一个deb包，但想看一下它里面有什么文件就用这;如果想多看点信息用,
  dpkg -I gedit-2.12.1.deb
5.dpkg -l gcc*:也可以用通配符来列出机器上的软件,这会列出所有gcc开头的软件包,其中，第1个 i 表示希望安装，第2个 i 表示已经安装，第3个字段是问题（如果有）（这3个字的含义可以看上面那3行，desired, status, err），后面是名字，版本和描述。un就表示，Unknown, not-installed
6.dpkg -s gedit:如果想看某包是否已经安装：
7.dpkg -L gedit:如果想看某软件都有哪些文件，都装到了什么地方;如果只想看其中的某些文件，就加上Grep：
  dpkg -L gedit grep png

来源：(http://blog.sina.com.cn/s/blog_4befea430100bad1.html) - Linux安装软件有关的命令(dpkg 安装deb包)_公子軍_新浪博客

*** mplayer
@mplayer

官方网站：http://www.mplayerhq.hu/design7/dload.html

Mplayer的特点是支持的格式相当多，还有要播放高清视频肯定要用到这个。

    * Mplayer 是一款自由的多媒体文件播放器。
    * 据其手册中所述，Mplayer 是目前这个星球上支持多媒体文件格式最多的软件。 

[编辑] 安装 Mplayer

sudo apt-get install mplayer-nogui  #mplayer无界面版本，一般都是用SMPlayer，所以都是用这个版本

sudo apt-get install mplayer mplayer-fonts 注意使用smplayer等其他界面加强版本，无需这一步 

sudo apt-get install mozilla-mplayer  #web浏览器的在线多媒体插件

注意通常都用gecko-mediaplayer取代过时的mozilla-mplayer，安装gecko_mediaplayer会关联gnome-player一起安装。
[编辑] 加快启动速度

如果启动速度变慢，试试打开mplayer，在preferences ——misc里面把stop xscreensaver前面的对勾去掉
[编辑] 安装解码器
[编辑] FFmpeg

安装mplayer时应该已经同时一并安装了ffmpeg，播放各种多媒体格式都不会有问题，如果没有，这样

sudo apt-get install ffmpeg

[编辑] w32codecs（通常不需要）

安装 w32codecs解码器(通常是不需要，如果有不能播放的可以参考 )。

到Mplayer网站下载最新的解码包，网址是 http://www.mplayerhq.hu/design7/dload.html 选择其中“Binary Codec Packages”标题下的“linux x86 ...”, 如Linux x86 20061022, 下载后解压到 /usr/lib/codecs/ 或 /usr/lib/win32即可。

例如

sudo mkdir /usr/lib/codecs/
cd /tmp
wget -c http://www1.mplayerhq.hu/MPlayer/releases/codecs/essential-20071007.tar.bz2
tar jxvf essential-20071007.tar.bz2
sudo mv essential*/* /usr/lib/codecs/

[编辑] 安装 mplayer 皮肤

假设下载回来的是名字是skin_name.tar.bz2的压缩包：（以下操作以在Nautilus文件管理器下操作为主）

解压缩下载回来的tar.bz2包，得到skin_name这个文件夹。接下来把这个文件夹剪切到 自己home目录下的 .mplayer/skins下，此目录为隐藏属性需要ctrl+h键才能看到。 mplayer皮肤列表中将显示为the_other_name
[编辑] GUI界面

MPlayer自带的界面简陋，常用的是功能异常强大的SMPlayer以及简单的Gnome MPlayer。 

SMPlayer:http: http://wiki.ubuntu.org.cn/SMPlayer
Gnome MPlayer: http://wiki.ubuntu.org.cn/Gnome_MPlayer
*** wine
@wine

mybase 是个人知识管理软件,国内用他的人很多,尤其是程序员,我用mybase差不多有一年多了,在XP下用着很好，没有一点问题，收集了1G＋的资料，这学期改用ubuntu，把XP都删除完了，剩下的软件全都有替代品，唯有mybase一时间找不到替代品，于是只好用虚拟机，结果发现太耗CPU和内存了，接着我就找到了basket,KDE环境，装他还要另外装上一大堆库，而且不稳定，经常crash,接着上sourceforge上继续找，Jreepad, Java环境，不好用，功能上很不成熟，WikidPad 是我找到的最好的了，Python+ Wxpython ,功能上很不错，喜欢Wiki的朋友可以试一下，反正不是很合我口味，而且在gnome下经常冒出一些稀奇古怪的问题，没办法，重新回到mybase.

OK, now I can say I have wined no bad bugs of mybase!

It let me very exciting!

第一步：得到一个绿色破解版的mybase,免去安装的麻烦。

第二步：拷贝xp目录下的mfc42u.dll，MSVCP60.DLL两个DLL文件到~/.wine/drive_c/windows/system32目录下，这一步很总要，mybase只缺这两个DLL。

第三步：OK, 到mybase目录下,执行命令：wine nyfedit.exe,看看是不是成功了？

最上方的字体控制位置出现乱码的解决方法:

打开mybase的配置文件：nyfedit.ini

找到这一行改为：
App.UI.Font.lfFaceName=文泉驿正黑

（这是界面字体设置的位置）

右边的tree结构乱码的问题比较好解决，直接F12修改mybase全局配置，全部改为文泉译正黑，字体为9
*** 调节CPU频率
看到有些朋友希望能调节cpu频率并且对其进行监视，花了点时间查新立得，结果找到这么一个好东西。

//////////////////////////////////更新//////////////////////////////////
其实有个最简单的方法
代码:
sudo dpkg-reconfigure gnome-applets
然后选择ok和yes，把cpu频率监视器添加到面板，就什么都有了，会自动安装cpufreq-selector。不必安装cpufrequtils。
////////////////////////////////////////////////////////////////////////

我们需要安装cpufrequtils。此软件是查看cpu当前频率以及修改频率、选择cpu、选择cpu运行方式的。注意，只支持某些可调节频率的cpu，如intel的笔记本cpu。可能可以超频 :D，没敢实验，那位试试看好了。
代码:
sudo apt-get install cpufrequtils

使用方法
代码:
cpufreq-info, cpufreq-selector, cpufreq-set。

具体用法可以看man，或者在命令后加-h。
比如
代码:
man cpufreq-info

或者
代码:
cpufreq-info -h


1。查看cpu类型、当前频率、支持频率、运行模式等。
代码:
cpufreq-info

这是我的cpu在powersave模式下的情况
代码:
zhuqin@ubuntu:~$ cpufreq-info
cpufrequtils 002: cpufreq-info (C) Dominik Brodowski 2004-2006
Report errors and bugs to linux@brodo.de, please.
analyzing CPU 0:
  driver: centrino
  CPUs which need to switch frequency at the same time: 0
  hardware limits: 798 MHz - 1.73 GHz
  available frequency steps: 1.73 GHz, 1.73 GHz, 1.73 GHz, 1.73 GHz, 1.73 GHz, 1.73 GHz, 1.73 GHz, 1.33 GHz, 1.06 GHz, 798 MHz
  available cpufreq governors: powersave, userspace, ondemand, conservative, performance
  current policy: frequency should be within 798 MHz and 1.73 GHz.
                  The governor "powersave" may decide which speed to use
                  within this range.
  current CPU frequency is 798 MHz.


2。选择需要调整的cpu
代码:
sudo cpufreq-selector -c cpu号
或者
代码:
sudo cpufreq-set -c cpu号
可能对双核或多核cpu进行选择。我的不是双核，没法实验，还请有duo core的朋友实验一下并跟帖汇报情况。

3。调整cpu频率
代码:
sudo cpufreq-selector -f 你所需要的频率
或者
代码:
sudo cpufreq-set -f 你所需要的频率
注意，此处的频率必须是以KHz为单位，并且是可以达到的频率（也就是用cpufreq-info查看到的各个频率），cpu频率＝倍频x外频。以下凡是涉及频率的一律如此。

4。调整cpu频率上下限
代码:
sudo cpufreq-set -d 频率下限

代码:
sudo cpufreq-set -u 频率上限

因此，可能可以对cpu进行降频或者超频。有些人肯定会跃跃欲试的，嘿嘿。

5。调整cpu运行模式
代码:
sudo cpufreq-selecotr -g 模式
或者
代码:
suod cpufreq-set -g 模式

这里，模式就是执行cpufreq-info后看到的所支持的模式。比如我的支持以下几种：powersave, userspace, ondemand, conservative, performance。

powersave，是无论如何都只会保持最低频率的所谓“省电”模式；
userspace，是自定义频率时的模式，这个是当你设定特定频率时自动转变的；
ondemand，默认模式。一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率；
conservative，翻译成保守（中庸）模式，会自动在频率上下限调整，和ondemand的区别在于它会按需分配频率，而不是一味追求最高频率；
performance，顾名思义只注重效率，无论如何一直保持以最大频率运行。

6。添加cpu监视器
监视cpu频率的系统就有，右键单击面板，选择“添加到面板”，里面找到“cpu频率范围监视器”。
另外，如果嫌命令行麻烦，可以这么做
代码:
sudo chmod +s /usr/bin/cpufreq-selector
然后，cpu频率范围监视器的首选项里就会多出一个“频率选择器”，显示菜单选择“频率和调速器”。鼠标左键单击cpu频率范围监视器，会发现“频率”和“调速器”两个菜单，就可以随便调了。在这里特别感谢Vstar。

监视温度的需要自己安装，
代码:
sudo apt-get install sensors-applet
然后也是这样添加到面板，名字叫“Hardware sensors monitor”。

鉴于超频或者更改频率一定的风险，大家千万小心，万一烧了就不好玩了。用本本的朋友可以考虑买一个cooler，挺管用的。

*** 装机
重新装机的过程


1 从别的机器上获取一份适合中国的/etc/apt/sources.list

2 sudo apt-get update

3 sudo apt-get install wine
   这样可以最快时间的获得以前的经验总结




----------------------- 如果要装amule， 要依次装这些东西 －－－－－－－－－－－－－－－
4  sudo apt-get install  libxcb1

5  sudo apt-get install  libxcb-render-util0

6  sudo apt-get install  libcairo2

7 sudo apt-get install libgtk2.0-0

8  sudo apt-get install libwxgtk2.8-0
 
9 sudo apt-get install amule

－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－

10 sudo apt-get install sun-java6-jre

*** 显卡驱动和3D桌面
＠ubuntu @3d  @桌面 @desktop @显卡驱动

参考网址  http://forum.ubuntu.org.cn/viewtopic.php?t=140531

安装显卡驱动 :

可选  运行 sh ati-driver-installer-9-3-x86.x86_64.run



通过窗口软件安装系统安装envyng

然后用envyng直接傻瓜安装


安装3D桌面：

方法b、使用fusion-icon启动compiz（推荐）
总结众多网友的经验，由于各位使用的显卡各不相同，不是所有的显卡都能启用系统自带的“桌面效果”。
有的即使能启动系统自带的“桌面效果”，但得到的3D桌面也很不稳定，
有时会出现系统缓慢、花屏、3D设置无法保存、开机自动变为“无”等等问题。
所以，我（一善鱼）不推荐使用系统自带的“桌面效果”来启用3D桌面，
推荐使用fusion-icon来启动compiz运行和设置3D桌面，以得到最稳定可靠的3D桌面效果。

首先，点击“系统”->“首选项”->“外观”->“视觉效果”，选择最上方的“无”。
然后，点击“系统”－>“系统管理”－>“新立得软件包管理器”，
在菜单栏里点击“搜索”按钮。在弹出的“查找”窗口的“搜索”栏中输入“compiz”，点击“搜索”按钮，
在搜索出来的列表中，确保下列选项已经安装，若未安装请勾选上（右键点击并选择“标记以便安装”）。
python-compizconfig
compizconfig-settings-manager
compiz-plugins
compiz-wrapper
compiz-core
compiz-gnome
libemeraldengine0
emerald
libdecoration0
compiz-fusion-plugins-extra
fusion-icon
compizconfig-backend-gconf
提示：由于Linux的软件包一直处于不断的更新状态中，
因此在新版本推出后，上述所列的软件包可能会有增有减，
如果你不放心，那么把所有带有“compiz”字样的软件包和emerald、fusion-icon全部选上就行了。
然后点击“应用”按钮进行安装。

安装完成后，点击“应用程序”－>“系统工具”->“compiz fusion icon”，
然后在桌面的右上角，可以看到一个蓝色的立方体图标。
此时，默认状态下，打开一个新窗口，鼠标按着窗口标题栏拖动，你会发现窗口像有弹性一样可以抖动。
这说明， 3D桌面的一部分特效已经成功开启，要实现3D桌面的其他特效请参见本教程 第二部分 。




*** webqq/qq
@qq @webqq

sudo ifconfig eth0 mtu 1412

*** 图形界面
@图形界面  @gdm

怎么从文本界面进入图形界面呢？  用 sudo gdm

*** freemind
@freemind

安装：
 sudo apt-get install freemind


运行

freemind

*** 禁用、启用网卡
ifdown eth0
ifup eth0
*** ubuntu11.04重新编译内核
有个同学问到自己的无线网卡在Ubuntu 11.04下面无法工作。即使重新安装驱动也无济于事。Ubuntu中文论坛很多同学，提出重新编译内核，或许是一个解决的方法。但是，这家伙编译内核，万一有所差池，是不是完蛋了？

笨兔兔根据专家建议，给大家说下如何重新编译Ubuntu 11.04 内核。我没有测试过，您最好自己先在虚拟机下测试看看，然后拿到真机下大动手脚比较合适。

 

Ubuntu 11.04 内核版本是2.6.38.可以使用命令 uname -r 查看下。

#1，安装所需软件包

sudo apt-get install kernel-wedge kernel-package libncurses5-dev

#2，运行命令

sudo apt-get build-dep --no-install-recommends linux-image-$(uname -r)

#3，创建源目录

mkdir ~/src

cd ~/src

#4，下载内核源码

apt-get source linux-image-$(uname -r)

#5，配置内核

cd linux-2.6.38

make menuconfig

#6，加速构建

export CONCURRENCY_LEVEL=3

提示，通常是CONCURRENCY_LEVEL=处理器数目+1

#7，若是原先编译过内核，现在清理下temp文件夹

make-kpkg clean

#8，编译内核

time fakeroot make-kpkg --initrd --append-to-version=-Bentutu kernel-image kernel-headers

提示，这里-Bentutu，可以修改成你自己喜欢的名称哟^_^

#9，安装内核

cd ~/src

sudo dpkg -i linux-image-2.6.38.2-Bentutu_2.6.38.2-Bentutu-10.00.Custom_amd64.deb

sudo dpkg -i linux-headers-2.6.38.2-Bentutu_2.6.38.2-Bentutu-10.00.Custom_amd64.deb

#10，重启下，试试看？


** gentoo
*** 安装
+ 系统
按照gentoo的handbook，安装完成，但是在启动的时候，报不支持vfs格式的硬盘，而启动不了
可以参考[[./doc/2011052500.mht][gentoo官网说明]]
+ 网络
逃离抑郁：今天在安装好gentoo的基础上还调好了。
gentoo在vmware上丢失eth0的解决方法在编译内核的时候，在ethernal 10M-100M的模块中选择上AMD pcnet32这个模块
CONFIG_PCNET32 = Y
另外需要在/etc/init.d/net.eth0（应该也可以是在net.lo中）加上如下两句话
modprobe pcnet32
depmod -a


*** 配置
+ 软件源
可以通过配置 /etc/make.conf 来选择软件源

**** XWIN中配置中文显示和输入
1. 安装中文字体
2. 设置locale
2.1 先修改locale.gen文件
2.2 建立 /etc/env.d/100i18n
3. 安装SCIM

1. 安装中文字体
#emerge arphicfonts wqy-bitmapfont cjkuni-fonts corefonts ttf-bitstream-vera
其中wqy-bitmapfont在x86版中被mask了
wqy-bitmapfont cjkuni-fonts在AMD64版中被mask了
保险起见被mask的我都没有安装

2. #gedit /etc/locale.gen
en_US ISO-8859-1
en_US.UTF-8 UTF-8
zh_CN GB18030
zh_CN.GBK GBK
zh_CN.GB2312 GB2312
zh_CN.UTF-8 UTF-8


保存执行locale-gen
#locale-gen

2.2 建立 /etc/env.d/100i18n
#gedit /etc/env.d/100i18n

LANG=en_US.UTF-8
LC_CTYPE=zh_CN.UTF-8
LC_NUMERIC="en_US.UTF-8"
LC_TIME="en_US.UTF-8"
LC_COLLATE="en_US.UTF-8"
LC_MONETARY="en_US.UTF-8"
LC_MESSAGES="en_US.UTF-8"
LC_PAPER="en_US.UTF-8"
LC_NAME="en_US.UTF-8"
LC_ADDRESS="en_US.UTF-8"
LC_TELEPHONE="en_US.UTF-8"
LC_MEASUREMENT="en_US.UTF-8"
LC_IDENTIFICATION="en_US.UTF-8"


保存后执行
#env-update
以保存设置
然后需要重新启动计算机


3. 安装SCIM
#emerge scim scim-pinyin
如果你需要除拼音外的其他输入法如五笔、二笔、自然码还需安装 scim-tables
完成后执行
#scim -d

**** CONSOLE中配置中文显示和输入
安装zhcon如下  ACCEPT_KEYWORDS="~x86" emerge zhcon
安装完之后直接运行zhcon就可以


**** 在putty中设置中文的显示和输入
只要在putty的设置中，将字符集设置为UTF-8，并且支持CJK就可以直接在putty中进行中文的输入
当然前提是环境变量LANG需要设置为LANG=zh_CN.UTF-8


**** 开机启动
写在 /etc/conf.d/local.start 这个文件里
最好在末尾空格後加一个 &>/dev/null ,表示後台播放


*** 工具
**** emerge
Gentoo的包管理工具称为portage。emerge是这个portage的字符界面管理工具，图形界面工具还有portato，porthole，kuroo，himerge等。

ebuild

ebuild是Portage包管理程序的根本。它是一个纯文本文件，而每一个ebuild都会对应一个包（软件包）。ebuild会告诉 portage要下载的文件、该包可运行的平台、如何编译它、它所依赖的ebuild和一些修补代码的patch。Portage内有一个ebuild大集合，称为Portage tree，是gentoo网站所提供的ebuild。它包含了大部份常用的包，并会不时更新。如果要使用的包不在其内，也可以手动加入。

USE标志

USE标志的设置位于Gentoo系统的/etc/make.conf文档中，作用是使得Emerge在处理依赖关系的时候可以做到不安装不需要的软件包（例如安装Gnome的用户没有必要因为一个软件包的依赖关系而安装KDE与Qt），而安装指定的软件包（同样以Gnome举例，Gnome的用户基本上都会安装GTK+），把系统的设置专注化。

Gentoo的emerge命令参数用法详解

查找名称包含mozilla的包

emerge -s mozilla
emerge search mozilla

查找描述包含mozilla

emerge -S mozilla
emerge --searchdesc mozilla

使用本地编好的包，没有就下源码(尽量避免编译)

emerge -k mozilla
emerge --usepkg mozilla

只使用本地编好的，否则不安装(绝对不编译，所有依赖的包都有binary才装)

emerge -K mozilla
emerge --usepkgonly mozilla

卸载

emerge -C mozilla
emerge unmerge mozilla

升级portage树

emerge --sync

下载snapshot包来完成sync

emerge-webrsync

查看已安装包的changelog

emerge -pl mozilla
emerge --pretend --changelog mozilla

查看依赖关系(这个包还没装)
(–pretend保证这一次操作实际上不做任何事情，可以跟任何options组合)

emerge -p mozilla
emerge --pretend mozilla

只下载某个软件的源码(以及它所依赖的)

emerge -f mozilla
emerge --fetchonly mozilla

查看从哪下的源码

emerge -fp mozilla

安装指定版本号的

emerge "..........."

emerge -k "

从网上下binary包来装

emerge -g mozilla
emerge --getbinpkg mozilla

(注意，实际上没有任何binary包存在于官方的mirror中
所以这个基本上是无用，在manpage也没有出现。除非自
己用livecd来setup一个这样的站点。不知道以后会不会
出现这样的mirror。gentoo.org论坛上似乎也有讨论这个。)

查看binary包依赖

emerge -gp mozilla
emrege --getbinpkg --pretend mozilla

查看依赖关系(这个包已经装了)

emerge -ep opera
emerge --emptytree --pretend opera

(不用pretend会重新编译这所有依赖的包，glibc因为安全关系没有列出)

不使用依赖关系安装软件

emerge -O opera
emerge --nodeps opera

只安装其依赖的软件

emerge -o opera
emerge --onlydeps opera

升级软件

emerge -u opera
emerge --update opera

升级系统软件

emerge -u system

升级整个系统

emerge -u world

避免升级覆盖掉版本更高的软件

emerge -uU world
emerge --update --upgradeonly world

查看可用的USE参数
emerge -pv opera


**** gdb
***** 如何产生core文件
Core dumps

Sometimes the crashes are difficult to reproduce, the program is vastly threaded, it's too slow to run in gdb or it's messed up when run through it (shouldn't surprise anybody that running inside the debugger there are more bugs than are reproduceable without the debugger itself). In these cases, there is one tool that comes in useful: the core dump.

A core dump is a file that contains the whole memory area of a program when it crashed. Using that file, it's possible to extract the stack backtrace even if the program has crashed outside gdb, assuming core dumps are enabled. By default core dumps are not enabled on Gentoo Linux (they are, however, enabled by default on Gentoo/FreeBSD), so you have to enable them.

Core dumps can be enabled on the system level or the shell session level. In the first case, everything in the system that crashes and does not have already a crash handler (see later for more notes about KDE's crash handler) will dump. When enabled at shell session level, only the programs started from that session will leave behind a dump.

To enable core dumps on a system level, you have to edit either /etc/security/limits.conf (if you're using PAM, as is the default) or /etc/limits.conf. In the first case, you must define a limit (whether hard or, most commonly, soft; for core files, that might be anywhere from 0 to no limit). In the latter case, you just need to set the variable C to the size limit of a core file (here there's no "unlimited").

Code Listing 1.5: Example of rule to get unlimited core files when using PAM

# /etc/security/limits.conf
 * soft core 0
Code Listing 1.6: Example of rule to get core files up to 20MB when not using PAM

# /etc/limits.conf
 * C20480
To enable core files on a single shell session you can use the ulimit command with the -c option. 0 means disabled; any other positive number is the size in KB of the generated core file, while unlimited simply removes the limit on core file dimension. From that point on, all the programs that exit because of a signal like SIGABRT or SIGSEGV will leave behind a core file that might be called either "core" or "core.pid" (where pid is replaced with the actual pid of the program that died).

Code Listing 1.7: Example of ulimit use

$ ulimit -c unlimited
$ crashing-program
[...]
Abort (Core Dumped)
$ 
      
**** sudo
sudo 不是gentoo默认自带的命令，需要通过emerge sudo来进行安装
安装了sudo之后，也并不是所有的gentoo用户都能通过sudo命令来以其他用户身份执行程序的。
需要在/etc/sudoers文件中添加如下脚本
%wheel ALL=(ALL) ALL
%wyao ALL=(ALL) ALL
这两行脚本可以让wheel和wyao两个grop中的用户具备可以使用sudo命令的权利
如果要针对某个特别用户来进行设定可以在/etc/sudoers中增加类似如下的脚本。
wyao ALL=(ALL) ALL 




** pure-ftpd
*** 重启
@pure-ftpd  @启动 @重启


root@wylinux:/etc/pam.d# pwd
/etc/pam.d

root@wylinux:/etc/pam.d# ls
atd   common-account   common-session  gdm-autologin  passwd  pure-ftpd  su
chfn  common-auth      cron            login          polkit  samba      sudo
chsh  common-password  gdm             other          ppp     sshd


root@wylinux:/etc/pam.d# pure-ftpd&       #/etc/pam.d/pure-ftpd  这个路径不一定对，在gentoo下面是/etc/pure-ftpd
注意：在gentoo下面应该使用pure-ftpd -l unix 才能使用系统用户来登录pure-ftpd



** tool
*** cpulimit
cpulimit是一个开源的cpu使用限制工具，可以针对某个进程名、pid等来限制cpu使用率
 
官方网址:http://cpulimit.sourceforge.net/
 
安装方法非常简单
 
tar zxf cpulimit-xxx.tar.gz
cd cpulimit-xxx
make
make install(默认安装到/usr/local/bin目录)
 
编译后就可以使用cpulimit这个命令了(需要root权限)
 
使用方法如下：
[root@test-22 cpulimit-1.1]# ./cpulimit 
Error: You must specify a target process
Usage: cpulimit TARGET [OPTIONS...]
   TARGET must be exactly one of these:
      -p, --pid=N        pid of the process
      -e, --exe=FILE     name of the executable program file
      -P, --path=PATH    absolute path name of the executable program file
   OPTIONS
      -l, --limit=N      percentage of cpu allowed from 0 to 100 (mandatory)
      -v, --verbose      show control statistics
      -z, --lazy         exit if there is no suitable target process, or if it dies
      -h, --help         display this help and exit
 
可以看到帮助信息
 
[root@test-22 cpulimit-1.1]# ./cpulimit -e perl -l 20

setsid cpulimit -e kjournald  -l 20;setsid cpulimit -e python3.1 -l 40;setsid cpulimit -e python2.7 -l 20;setsid cpulimit -e cc1 -l 10 -l 40


*** ssh server
**** 安装和启动
 apt-get install openssh-server

 Ubuntu缺省安装了openssh-client,所以在这里就不安装了，如果你的系统没有安装的话，再用apt-get安装上即可。

然后确认sshserver是否启动了：
ps -e |grep ssh

如果只有ssh-agent那ssh-server还没有启动，需要/etc/init.d/ssh start，如果看到sshd那说明ssh-server已经启动了。

ssh-server配置文件位于/ etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号;
＃重启sshd服务
 /etc/init.d/ssh resart

*** GCC
**** 创建动态库
@gcc
6.3. 怎样创建动态连接库(shared library)/dlls？
创建动态连接库(shared libraries)的方法根据不同的系统有所不同。这个过程主要分两步；第一步要求包括在动态连接库中的目标必须首先是编译好的，通常需要某个编译选项指示这串代码是位置无关的(position-indepenent)；第二步，是将这些目标连接在一起形成一个库文件。 

这里是一个演示以上道理的小程序： 

     /* shrobj.c 文件 */

     const char *myfunc()
     {
         return "Hello World";
     }

     /* shrobj.c 结束 */

     /* hello.c 文件 */

     #include <stdio.h>

     extern const char *myfunc();

     main()
     {
         printf("%s\n", myfunc());
         return 0;
     }

     /* hello.c 结束 */

     $ gcc -fpic -c shrobj.c
     $ gcc -shared -o libshared.so shrobj.o
     $ gcc hello.c libshared.so
     $ ./a.out
     Hello World
    
到目前为止，如果你希望库文件和它的创建过程是都可以移植的话，那么最好的办法是使用GNU Libtool程序包。它是个小型的工具程序套件，这些工具程序知道建立动态连接库的平台无关性；你可以只发布你的程序必要的部分，从而当一个安装者配置你的软件包时，他能决定生成什么库。Libtool程序包在不支持动态连接库的系统上也能工作得很好。它而且知道与GNU Autoconf程序和GNU Automake程序挂钩(如果你使用这些工具来管理你程序的编译创建过程)。 

如果你不想使用Libtool程序包，那么对于gcc以外的编译器，你需要按照下面所列修改编译器参数： 

AIX 3.2 使用 xlc (未证实)
     取消‘-fpic’选项，以‘-bM:SRE -bE:libshared.exp’取代‘-shared’。你并且
     需要创建一个名为‘libshared.exp’的文件保存一个所有输出符号(symbols to export)
     的列表，比如以上的范例程序，就需要输出‘myfunc’符号。另外，在连接库
     时使用‘-e _nostart’参数(在较新的AIX版本上，我相信应该将其变成‘-bnoentry’)。

SCO OpenServer 5 使用 SCO 开发系统(Development System) (未证实)
     如果你使用ELF(译者注：ELF：执行与连接格式Executable and Linking Forrmat，
     一种Unix可执行目标文件的格式)格式，那么共享库只能在OS5上可用，而它
     需要‘-belf’选项。并以‘-Kpic’取代‘-fpic’，在连接时使用‘cc -belf -G’。

Solaris 使用 SparcWorks 编译器
     以‘-pic’取代‘-fpic’，并以‘ld -G’取代‘gcc -shared’。
    
(鼓励大家提供更多的材料丰富上述列表) 

其它要当心的问题： 


AIX和(我相信)Digital Unix不需要-fpic选项，因为所有代码都是位置无关的。 

AIX一般需要你创建一个‘输出文件’，即一个保存所有动态连接库中输出 符号的列表。一些连接器(linker)版本(可能只有SLHS连接器，是svld?)有一个 选项可以输出所有符号。 

如果你对于连接器想使用普遍的‘-l’参数来引用你的动态连接库，你必须 理解你的系统在实际运行时是怎样寻找动态连接库的。最普通的方法是使用 ‘LD_LIBRARY_PATH’环境变量，但是通常在连接时有一种其它选项可以 设定。 

大多数实现方法是在程序内部记录所希望的动态连接库在运行时的位置。这 样把一个动态连接库从一个目录移到另一个目录将导致程序无法工作。许多 系统对于连接器有一个选项用以设定希望运行时动态连接库的位置(比如在 Solaris系统上是‘-R’连接器选项，或者是‘LD_RUN_PATH’环境变量)。 

ELF和a.out的实现方法可能有一个连接器选项‘-Bsymbolic’，它导致在库本 身内部的引用被解释好。否则，在这些系统上，所有符号的解释将推迟到最 后连接时再进行，这样在main程序中的单一函数将重载库中的对应函数。 


** 用户、用户组、文件权限
linux的用户信息保存在/etc/passwd文件中，另外，/etc/shadow文件存放的是用户密码相关信息。
/etc/passwd文件格式：
用户名:密码:UID:GID:用户信息:HOME目录路径:用户shell
其中UID为0则是用户root，1～499为系统用户，500以上为普通用户


 
/etc/shadow保存用户密码信息，包括加密后的密码，密码过期时间，密码过期提示天数等。


 
用户组信息保存在/etc/group文件中
格式如下：
用户组名:组密码:GID:组内帐号（多个帐号用逗号分隔）


 
用户登录后，/etc/passwd文件里的GID为用户的初始用户组。
用户的初始用户组这一事实不会再/etc/group中体现。


 
查看当前用户的用户组命令：
[root@local opt]#groups
root bin daemon sys adm disk wheel
输出的信息中，第一个用户组为当前用户的有效用户组（当前用户组）


 
切换有效用户组命令：
[root@local opt]#newgrp 用户组名
要离开新的有效用户组，则输入exit回车。


 
新建用户命令：
[root@local opt]#useradd 用户名 -g 初始用户组 -G 其他用户组（修改/etc/group） -c 用户说明 -u 指定UID
语法具体：
usage: useradd [-u uid [-o]] [-g group] [-G group,...]
[-d home] [-s shell] [-c comment] [-m [-k template]]
[-f inactive] [-e expire ] [-p passwd] name
useradd -D [-g group] [-b base] [-s shell]
[-f inactive] [-e expire ]


 
建完用户需要为用户设置密码：
[root@local opt]#passwd 用户名


 
用户要修改自己密码命令：
[root@local opt]#passwd


 
修改用户信息命令：
[root@local opt]#usermod 参数 用户名
参数有 -c 说明
       -g 组名 初始用户组
       -e 过期日期 格式：YYYY-MM-DD
       -G 组名 其他用户组
       -l 修改用户名
       -L 锁定账号（在/etc/shadow文件中用户对应密码密码串的前面加上两个叹号(!!)）
       -U 解锁


 
删除用户命令：
[root@local opt]#userdel [-r] 用户名
其中，参数-r为删除用户的home目录。
其实，可能在系统其他地方也有该用户文件，要完整删除一个用户和其文件要先找到属于他的文件：
[root@local opt]#find / -user 用户名
然后删除，再运行userdel删除用户。


 
查看可用shell命令：
[root@local opt]#chsh -l 
修改自己的shell命令：
[root@local opt]#chsh -s


 
查看自己或某人UID/GID信息：
[root@local opt]#id [用户名]
返回信息中groups为有效用户组


 

新增用户组命令：
[root@local opt]#groupadd 用户组名


 
修改用户组名命令：
[root@local opt]#groupmod -n 名称


 
删除用户组命令：
[root@local opt]#groupdel 用户组名


 
设置用户组密码命令：
[root@local opt]#gpasswd 用户组名


 
如果加上参数则有其他功能


 
设置用户组管理员命令：
[root@local opt]#gpasswd -A 用户名 用户组名


 
添加某帐号到组命令：
[root@local opt]#gpasswd -M 用户名 用户组名


 
从组中删除某帐号命令：
[root@local opt]#gpasswd -d 用户名 用户组名


 
passwd相关参数操作：
-l 锁用户
-u 解锁用户
-n 天数  密码不可改天数
-x 天数  密码过期天数
-w 天数  警告天数


 
 

 
文件权限知识：
先看个实例：
[root@local opt]#ls -al
ls -al 命令是列出目录的所有文件，包括隐藏文件。隐藏文件的文件名第一个字符为'.'


 
-rw-r--r--  1 root root    81 08-02 14:54 gtkrc-1.2-gnome2
-rw-------  1 root root   189 08-02 14:54 ICEauthority
-rw-------  1 root root    35 08-05 10:02 .lesshst
drwx------  3 root root  4096 08-02 14:54 .metacity
drwxr-xr-x  3 root root  4096 08-02 14:54 nautilus


 
列表的列定义如下：
[权限属性信息] [连接数] [拥有者] [拥有者所属用户组] [大小] [最后修改时间] [文件名]


 
权限属性列表为10个字符：
第一个字符表示文件类型，d为目录 -为普通文件 l为连接 b为可存储的接口设备 c为键盘鼠标等输入设备
2、3、4个字符表示所有者权限，5、6、7个字符表示所有者同组用户权限，8、9、10为其他用户权限
第二个字符表示所有者读权限，如果有权限则为r，没有权限则为-
第三个字符表示所有者写权限，如果有权限则为w，没有权限则为-
第四个字符表示所有者执行权限，如果有权限则为x，没有权限则为-
第五个字符表示所有者同组用户读权限，如果有权限则为r，没有权限则为-
第六个字符表示所有者同组用户写权限，如果有权限则为w，没有权限则为-
第七个字符表示所有者同组用户执行权限，如果有权限则为x，没有权限则为-
第八个字符表示其他非同组读权限，如果有权限则为r，没有权限则为-
第九个字符表示其他非同组写权限，如果有权限则为w，没有权限则为-
第十个字符表示其他非同组执行权限，如果有权限则为x，没有权限则为-


 

修改文件所属组命令：
[root@local opt]#chgrp [-R] 组名 文件名
其中-R为递归设置


 
修改文件的所有者和组命令：
[root@local opt]#chown [-R] 用户[:用户组] 文件名


 
修改文件访问权限命令：
[root@local opt]#chmod [-R] 0777 文件名

** adminstrator
*** useful command
1. uptime
Uptime命令的显示结果包括服务器已经运行了多长时间，有多少登陆用户和对服务器性能的总体评估（load average）。load average值分别记录了上个1分钟，5分钟和15分钟间隔的负载情况，load average不是一个百分比，而是在队列中等待执行的进程的数量。如果进程要求CPU时间被阻塞（意味着CPU没有时间处理它），load average值将增加。另一方面，如果每个进程都可以立刻得到访问CPU的时间，这个值将减少。
UP kernel下的load average的最佳值是1，这说明每个进程都可以立刻被CPU处理，当然，更低不会有问题，只说明浪费了一部分的资源。但在不同的系统间这个值也是不同的，例如一个单CPU的工作站，load average为1或者2都是可以接受的， 而在一个多CPU的系统中这个值应除以物理CPU的个数，假设CPU个数为4，而load average为8或者10，那结果也是在2多点而已。

[[./pic/20110412_01.jpg]]

你可以使用uptime判断一个性能问题是出现在服务器上还是网络上。例如，如果一个网络应用运行性能不理想，运行uptime检查系统负载是否比较高，如果不是这个问题更可能出现在你的网络上。

2. pmap
pmap命令显示一个或者多个进程使用内存的数量，你可以用这个工具来确定服务器上哪个进程占用了过多的内存从而导致内存瓶颈。
[[./pic/20110412_02.jpg]]

3. sar
sar程序也是sysstat安装包的一部分。sar命令用于收集、报告和保存系统的信息。Sar命令由三个应用组成：sar，用与显示数据；sa1和sa2，用于收集和存储数据。默认情况下，系统会在crontab中加入自动收集和分析的操作：
引用
[root@rfgz ~]# cat /etc/cron.d/sysstat
# run system activity accounting tool every 10 minutes
*/10 * * * * root /usr/lib/sa/sa1 1 1
# generate a daily summary of process accounting at 23:53
53 23 * * * root /usr/lib/sa/sa2 -A
sar命令所生成的数据保存在/var/log/sa/目录下，数据按照时间保存，可以根据时间来查询相应的性能数据。
你也可以使用sar在命令行下得到一个实时的执行结果，收集的数据可以包括CPU利用率、内存页面、网络I/O等等。下面的命令表示用sar执行5次，间隔时间为3秒。

[[./pic/20110412_03.jpg]]


** 常用命令
*** setid
setid a.out  #则a.out会在后台启动


** mips架构
** 路由器做http服务器
<2011-07-16 周六> 
今天很冲动地决定，要把一个带有USB接口的无线路由器改造成一个HTTP服务器。达到这个目标需要，需要首先搞定以下几件事情：
1. 搞清楚市面上有哪些带USB的wlan路由器
2. 主要型号使用的是什么样的架构和系统(cpu型号，内核版本，使用什么样的工具链等)
3. 网上是否能很容易地down到这些型号对应的编译环境和工具链，
4. 选择一个型号，了解价格
5. 杀到珠江路买
6. telnet到路由器上，了解系统版本、CPU。
7. 上网down对应的编译环境和工具链
8. 找一个hello world来编译一下，在路由器上运行一下。
9. 移植一个简易的httpserver到路由器上


1. 路由器品牌
D-Link的DI-624S
华硕的WL-500g Deluxe


上网查了一些资料后，感觉很难确定一个可以买的品牌，因为不清楚要买的路由器的系统是否开放，能否支持telnet或者ssh，是不是linux系统，能否在上面运行自己的进程。
后来请教了bingbing王，了解到要把路由器改造成HTTPServer的关键在于要看路由器的型号是否可以刷成tomato或者DDWRT这两种固件系统，这两种固件系统都是linux系统的，并且非常开放，可以在系统上运行自己的进程。




** 内核编程
*** 字符设备
**** alloc_chrdev_region() 
alloc_chrdev_region() 用于设备号未知，向系统动态申请未被占用的设备号情况。

参数 dev ，在系统调用成功后，会把得到的设备号方到这个参数中；
参数 firstminor 是请求的第一个次设备号，一般为 0 ；
参数 count   表示一个范围值；
参数 name 表示设备名。 

*** 学习笔记(临时，内有file_operation各函数的原型)
Linux设备驱动开发学习笔记
内核版本:2.6.x

  
  Major and Minor Numbers
内核通过major号来识别设备,下面的命令列出的是系统上所连接的设备及其major number,第一列就是设备的major number.
$ cat /proc/devices 
Character devices:
  1 mem
  4 /dev/vc/0
  4 tty
  5 /dev/tty
  5 /dev/console
  5 /dev/ptmx
  7 vcs
 10 misc
 13 input
 14 sound
116 alsa
128 ptm
136 pts
180 usb
195 nvidia
226 drm
254 devfs

Block devices:
  3 ide0
 22 ide1
$ls -l /dev
..............
crw-------  1 root root 119,   0 Apr 24 11:34 vmnet0
crw-------  1 root root 119,   1 Apr 24 11:34 vmnet1
crw-------  1 root root 119,   2 Apr 24 11:34 vmnet2
crw-------  1 root root 119,   3 Apr 24 11:34 vmnet3
crw-------  1 root root 119,   4 Apr 24 11:34 vmnet4
crw-------  1 root root 119,   5 Apr 24 11:34 vmnet5
crw-------  1 root root 119,   6 Apr 24 11:34 vmnet6
crw-------  1 root root 119,   7 Apr 24 11:34 vmnet7
crw-------  1 root root 119,   8 Apr 24 11:34 vmnet8
..............
可以看到他们的major number 是119,但他们的minor number不同.分别是0~8.
内核只关心major number,而minor number 是由设备驱动来区别的.
内核内部,类型dev_t存储着设备号,且定义了一组宏来维护它.
MKDEV(int major,int minor);//return dev_t
MAJOR( dev_t dev);
MINOR (dev_t dev);
比如,我们用mknod建立一个新的设备文件
#mknod /dev/newchr c 50 0
建立/dev/newchr设备文件,类型是c(char,字符型),major number 是50,minor number 是0.mknod的用法可以用man来查看.
在内核内部,我们用上面的宏来维护:
dev_t mydev;
mydev=MKDEV(50,0);
我们也可以由mydev得到major 和minor number.
int major,minor;
major=MAJOR(mydev);
minor=MINOR(mydev);


  注册设备号
我们定义好major和minor number 后就可以在内核中注册一个设备了.注册一个字符设备需要用到下面几个函数:
int register_chrdev_region(dev_t first,unsigned int count,
char *name);
first是你要注册的设备号范围的开始(其中minor号一般设置为0),count是你所申请的连续设备号的总数.name是设备的名称.它会在/proc/devices中出现.
int alloc_chrdev_region(dev_t *dev,unsigned int firstminor,
unsigned int count,char *name);
这个函数是用来动态分配设备号的.有余开发者不知道所要用的major号是多少,便让内核动态分配一个.参数dev是个output-only参数.
void unregister_chrdev_region(dev_t first,unsigned int count);
一般在模块清除函数中调用.

重要的数据结构
正如你所想象的,注册只是第一步,后面还有更重要的部分,其中一个就是我们一开始提到的如何实现open/read/write/ioctl等用户接口.
首先看一下几个重要的数据结构:
file_operations,file,inode
<linux/fs.h>中定义了这三个结构.
struct file_operations {
        struct module *owner;
        loff_t (*llseek) (struct file *, loff_t, int);
        ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
        ssize_t (*aio_read) (struct kiocb *, char __user *, size_t, loff_t);
        ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
        ssize_t (*aio_write) (struct kiocb *, const char __user *, size_t, loff_t);
        int (*readdir) (struct file *, void *, filldir_t);
        unsigned int (*poll) (struct file *, struct poll_table_struct *);
        int (*ioctl) (struct inode *, struct file *, unsigned int, unsigned long);
        int (*mmap) (struct file *, struct vm_area_struct *);
        int (*open) (struct inode *, struct file *);
        int (*flush) (struct file *);
        int (*release) (struct inode *, struct file *);
        int (*fsync) (struct file *, struct dentry *, int datasync);
        int (*aio_fsync) (struct kiocb *, int datasync);
        int (*fasync) (int, struct file *, int);
        int (*lock) (struct file *, int, struct file_lock *);
        ssize_t (*readv) (struct file *, const struct iovec *, unsigned long, loff_t *);
        ssize_t (*writev) (struct file *, const struct iovec *, unsigned long, loff_t *);
        ssize_t (*sendfile) (struct file *, loff_t *, size_t, read_actor_t, void *);
        ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);
        unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
        int (*check_flags)(int);
        int (*dir_notify)(struct file *filp, unsigned long arg);
}
file_operations结构定义了一组函数指针,每一个打开的文件(用struct file表示)和他自己的一组函数(包含在一个叫f_op的域中,它指向一个struct file_operations结构)相联系.这些操作都是来实现系统调用的,所以才被命名为open,read,等等.对于那些不需要的功能(比如你的设备不需要write功能,即不需要向设备写数据),可以给write指针付NULL.

struct file {
        struct list_head        f_list;
        struct dentry           *f_dentry;
        struct vfsmount         *f_vfsmnt;
        struct file_operations  *f_op;
        atomic_t                f_count;
        unsigned int            f_flags;
        mode_t                  f_mode;
        int                     f_error;
        loff_t                  f_pos;
        struct fown_struct      f_owner;
        unsigned int            f_uid, f_gid;
        struct file_ra_state    f_ra;

        unsigned long           f_version;
        void                    *f_security;

        /* needed for tty driver, and maybe others */
        void                    *private_data;

#ifdef CONFIG_EPOLL
        /* Used by fs/eventpoll.c to link all the hooks to this file */
        struct list_head        f_ep_links;
        spinlock_t              f_ep_lock;
#endif /* #ifdef CONFIG_EPOLL */
        struct address_space    *f_mapping;
};
每个打开的文件对应一个struct file.它在被打开时由内核创建,并传给它所有可以操作该文件的函数,到文件被关闭时才被删除.

The inode Structure.
Inode结构是用来在内核内部表示文件的.同一个文件可以被打开好多次,所以可以对应很多struct file,但是只对应一个struct inode.该结构里面包含了很多信息,但是,驱动开发者只关心里面两个重要的域:
dev_t i_rdev;//含有真正的设备号
struct cdev *i_cdev;//struct cdev是内核内部表示字符设备的结构.

注册字符设备

<linux/cdev.h>
可以有两种方法注册
struct cdev *my_cdev=cdev_alloc();
my_cdev->ops=&my_fops;
或
void cdev_init(struct cdev *cdev,struct file_operations *fops);

注册完后还要通知内核一声,通过调用
int cdev_add(struct cdev *dev,dev_t num,unsigned int count);
count 一般是 1.

删除字符设备,调用
void cdev_del(struct cdev *dev);


说了那么多,现在可以来个例子了.
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/module.h>
#include <asm/uaccess.h>
#include <linux/cdev.h>
#include <asm/uaccess.h>


#define DP_MAJOR 50
#define DP_MINOR 0
static int char_read(struct file *filp,char __user *buffer,size_t,loff_t *);
static int char_open(struct inode *,struct file *);
static int char_write(struct file *filp,const char __user *buffer,size_t ,loff_t*);
static int char_release(struct inode *,struct file *); 
static char *arr,*p;
static int chropen;
struct cdev *my_cdev;
static int len;
struct file_operations Fops = {
.read = char_read,
.write = char_write,
.open = char_open,
.release = char_release,/* a.k.a. close */
};
static int __init char_init(void)
{
printk(KERN_ALERT"Initing......\n");
dev_t dev;
dev=MKDEV(DP_MAJOR,DP_MINOR);
my_cdev = cdev_alloc( );
arr=kmalloc(1024,GFP_KERNEL);
if(arr==NULL){
printk(KERN_ALERT"kmalloc error\n");
}
sprintf(arr,"Hello,Pid=%d\n",current->pid);
if(my_cdev==NULL){
return -1;
}
if(register_chrdev_region(dev,10,"dpchr")<0){
printk(KERN_ALERT"Register char dev error\n");
return -1;
}
chropen=0;
len=0;
my_cdev->ops = &Fops;
cdev_init(my_cdev,&Fops);
cdev_add(my_cdev,dev,1);

return 0;
}

static int char_open(struct inode *inode,struct file *file)
{
if(chropen==0)
chropen++;
else{
printk(KERN_ALERT"Another process open the char device\n");
return -1;
}
p=arr;
try_module_get(THIS_MODULE);
return 0;
}

static int char_release(struct inode *inode,struct file *file)
{
chropen--;
module_put(THIS_MODULE);
return 0;
}

static int char_read(struct file *filp,char __user *buffer,size_t length,loff_t *offset)
{
int i=0;
if(*p=='\0')
return 0;
while(length&&*p){
put_user(*(p++),buffer++);
length--;
i++;
}
return i;
}

static int char_write(struct file *filp,const char __user  *buffer,size_t length,loff_t *offset)
{

int i;
for(i=0;i<length&&i<1024;i++)
get_user(p[i],buffer+i);

p[i]=0;
len=i;
return i;
}


static void module_close()
{
len=0;
printk(KERN_ALERT"Unloading..........\n");
kfree(arr);
unregister_chrdev_region(MKDEV(DP_MAJOR,DP_MINOR),10);
cdev_del(my_cdev);
}

module_init(char_init);
module_exit(module_close);

需要注意的是,用户调用read/write时返回的值便是我们实现的函数(char_read,char_write)返回的值,所以我们不能随便的返回一个值(比如,0,用户的read/write返回0,所以会认为出错了,然后并没有出错,只是我们返回了一个错误的值而已.


参考资料
内核模块的编程http://www.tldp.org/LDP/lkmpg/2.6/html/index.html
Linux Device Driver 3rd Edition
Linux Kernel Development 2nd Edition

*** 关于insmod和mknod
[2012-01-08 Sun]
如果字符设备的驱动采取的是自动分配驱动设备号，则insmod后系统会为驱动随即生成设备号。
这个设备号可以通过cat /proc/devices 里面对应驱动模块的名字来查
如驱动程序中申请驱动设备号时的代码是这样写的     iRes = alloc_chrdev_region(&g_wy_ch_dev,0,DEV_ID_COUNT,"wychdev");
则在/proc/devices中查找 wychdev对应的设备号，距离如果设备号是200
然后去/dev目录下用chmod wychdev c 200 0 命令创建对应的字符文件，这是对该字符文件进行操作的时候就会出发我们的驱动程序
*** 常用API
随着Linux2.6的发布，由于2.6内核做了教的改动，各个设备的驱动程序在不同程度上要进行改写。为了方便各位Linux爱好者我把自己整理的这分文档share出来。该文当列举了2.6内核同以前版本的绝大多数变化，可惜的是由于时间和精力有限没有详细列出各个函数的用法。 
　　特别声明：该文档中的内容来自http://lwn.net，该网也上也有各个函数的较为详细的说明可供各位参考。 
　　1、使用新的入口 
　　必须包含 ＜linux/init.h＞ 
　　module_init(your_init_func); 
　　module_exit(your_exit_func); 
　　老版本：int init_module(void); 
　　void cleanup_module(voi); 
　　2.4中两种都可以用，对如后面的入口函数不必要显示包含任何头文件。 
　　2、GPL 
　　MODULE_LICENSE("Dual BSD/GPL"); 
　　老版本：MODULE_LICENSE("GPL"); 
　　3、模块参数 
　　必须显式包含＜linux/moduleparam.h＞ 
　　module_param(name, type, perm); 
　　module_param_named(name, value, type, perm); 
　　参数定义 
　　module_param_string(name, string, len, perm); 
　　module_param_array(name, type, num, perm); 
　　老版本：MODULE_PARM(variable,type); 
　　MODULE_PARM_DESC(variable,type); 
　　4、模块别名 
　　MODULE_ALIAS("alias-name"); 
　　这是新增的，在老版本中需在/etc/modules.conf配置，现在在代码中就可以实现。 
　　5、模块计数 
　　int try_module_get(&module); 
　　module_put(); 
　　老版本：MOD_INC_USE_COUNT 和 MOD_DEC_USE_COUNT 
　　6、符号导出 
　　只有显示的导出符号才能被其他模块使用，默认不导出所有的符号，不必使用EXPORT_NO_SYMBOLS 
　　老板本：默认导出所有的符号，除非使用EXPORT_NO_SYMBOLS 
　　7、内核版本检查 
　　需要在多个文件中包含＜linux/module.h＞时，不必定义__NO_VERSION__ 
　　老版本：在多个文件中包含＜linux/module.h＞时，除在主文件外的其他文件中必须定义__NO_VERSION__，防止版本重复定义。 
　　8、设备号 
　　kdev_t被废除不可用，新的dev_t拓展到了32位，12位主设备号，20位次设备号。 
　　unsigned int iminor(struct inode *inode); 
　　unsigned int imajor(struct inode *inode); 
　　老版本：8位主设备号，8位次设备号 
　　int MAJOR(kdev_t dev); 
　　int MINOR(kdev_t dev); 
　　9、内存分配头文件变更 
　　所有的内存分配函数包含在头文件＜linux/slab.h＞，而原来的＜linux/malloc.h＞不存在 
　　老版本：内存分配函数包含在头文件＜linux/malloc.h＞ 
　　10、结构体的初试化 
　　gcc开始采用ANSI C的struct结构体的初始化形式： 
　　static struct some_structure = { 
　　.field1 = value, 
　　.field2 = value, 
　　.. 
　　}; 
　　老版本：非标准的初试化形式 
　　static struct some_structure = { 
　　field1: value, 
　　field2: value, 
　　.. 
　　}; 
　　11、用户模式帮助器 
　　int call_usermodehelper(char *path, char **argv, char **envp,int wait); 
　　新增wait参数 
　　12、request_module() 
　　request_module("foo-device-%d", number); 
　　老版本： 
　　char module_name[32]; 
　　printf(module_name, "foo-device-%d", number); 
　　request_module(module_name); 
　　13、dev_t引发的字符设备的变化 
　　1、取主次设备号为 
　　unsigned iminor(struct inode *inode); 
　　unsigned imajor(struct inode *inode); 
　　2、老的register_chrdev()用法没变，保持向后兼容，但不能访问设备号大于256的设备。 
　　3、新的接口为 
　　a)注册字符设备范围 
　　int register_chrdev_region(dev_t from, unsigned count, char *name); 
　　b)动态申请主设备号 
　　int alloc_chrdev_region(dev_t *dev, unsigned baseminor, unsigned count, char 
　　*name); 
　　看了这两个函数郁闷吧^_^！怎么和file_operations结构联系起来啊？别急！ 
　　c)包含 ＜linux/cdev.h＞，利用struct cdev和file_operations连接 
　　struct cdev *cdev_alloc(void); 
　　void cdev_init(struct cdev *cdev, struct file_operations *fops); 
　　int cdev_add(struct cdev *cdev, dev_t dev, unsigned count); 
　　（分别为，申请cdev结构，和fops连接，将设备加入到系统中！好复杂啊！） 
　　d)void cdev_del(struct cdev *cdev); 
　　只有在cdev_add执行成功才可运行。 
　　e)辅助函数 
　　kobject_put(&cdev-＞kobj); 
　　struct kobject *cdev_get(struct cdev *cdev); 
　　void cdev_put(struct cdev *cdev); 
　　这一部分变化和新增的/sys/dev有一定的关联。 
　　14、新增对/proc的访问操作 
　　＜linux/seq_file.h＞ 
　　以前的/proc中只能得到string, seq_file操作能得到如long等多种数据。 
　　相关函数： 
　　static struct seq_operations 必须实现这个类似file_operations得数据中得各个成 
　　员函数。 
　　seq_printf()； 
　　int seq_putc(struct seq_file *m, char c); 
　　int seq_puts(struct seq_file *m, const char *s); 
　　int seq_escape(struct seq_file *m, const char *s, const char *esc); 
　　int seq_path(struct seq_file *m, struct vfsmount *mnt, 
　　struct dentry *dentry, char *esc); 
　　seq_open(file, &ct_seq_ops); 
　　等等
　　15、底层内存分配 
　　1、＜linux/malloc.h＞头文件改为＜linux/slab.h＞ 
　　2、分配标志GFP_BUFFER被取消，取而代之的是GFP_NOIO 和 GFP_NOFS 
　　3、新增__GFP_REPEAT，__GFP_NOFAIL，__GFP_NORETRY分配标志 
　　4、页面分配函数alloc_pages()，get_free_page()被包含在＜linux/gfp.h＞中 
　　5、对NUMA系统新增了几个函数： 
　　a) struct page *alloc_pages_node(int node_id, 
　　unsigned int gfp_mask, 
　　unsigned int order); 
　　b) void free_hot_page(struct page *page); 
　　c) void free_cold_page(struct page *page); 
　　6、 新增Memory pools 
　　＜linux/mempool.h＞ 
　　mempool_t *mempool_create(int min_nr, 
　　mempool_alloc_t *alloc_fn, 
　　mempool_free_t *free_fn, 
　　void *pool_data); 
　　void *mempool_alloc(mempool_t *pool, int gfp_mask); 
　　void mempool_free(void *element, mempool_t *pool); 
　　int mempool_resize(mempool_t *pool, int new_min_nr, int gfp_mask); 
　　16、 per-CPU变量 
　　get_cpu_var(); 
　　put_cpu_var(); 
　　void *alloc_percpu(type); 
　　void free_percpu(const void *); 
　　per_cpu_ptr(void *ptr, int cpu) 
　　get_cpu_ptr(ptr) 
　　put_cpu_ptr(ptr) 
　　老版本使用 
　　DEFINE_PER_CPU(type, name); 
　　EXPORT_PER_CPU_SYMBOL(name); 
　　EXPORT_PER_CPU_SYMBOL_GPL(name); 
　　DECLARE_PER_CPU(type, name); 
　　DEFINE_PER_CPU(int, mypcint); 
　　2.6内核采用了可剥夺得调度方式这些宏都不安全。
　　17、内核时间变化 
　　1、现在的各个平台的HZ为 
　　Alpha: 1024/1200; ARM: 100/128/200/1000; CRIS: 100; i386: 1000; IA-64: 
　　1024; M68K: 100; M68K-nommu: 50-1000; MIPS: 100/128/1000; MIPS64: 100; 
　　PA-RISC: 100/1000; PowerPC32: 100; PowerPC64: 1000; S/390: 100; SPARC32: 
　　100; SPARC64: 100; SuperH: 100/1000; UML: 100; v850: 24-100; x86-64: 1000. 
　　2、由于HZ的变化，原来的jiffies计数器很快就溢出了，引入了新的计数器jiffies_64 
　　3、#include ＜linux/jiffies.h＞ 
　　u64 my_time = get_jiffies_64(); 
　　4、新的时间结构增加了纳秒成员变量 
　　struct timespec current_kernel_time(void); 
　　5、他的timer函数没变，新增 
　　void add_timer_on(struct timer_list *timer, int cpu); 
　　6、新增纳秒级延时函数 
　　ndelay()； 
　　7、POSIX clocks 参考kernel/posix-timers.c 
　　18、工作队列（workqueue） 
　　1、任务队列（task queue ）接口函数都被取消，新增了workqueue接口函数 
　　struct workqueue_struct *create_workqueue(const char *name); 
　　DECLARE_WORK(name, void (*function)(void *), void *data); 
　　INIT_WORK(struct work_struct *work, 
　　void (*function)(void *), void *data); 
　　PREPARE_WORK(struct work_struct *work, 
　　void (*function)(void *), void *data); 
　　2、申明struct work_struct结构 
　　int queue_work(struct workqueue_struct *queue, 
　　struct work_struct *work); 
　　int queue_delayed_work(struct workqueue_struct *queue, 
　　struct work_struct *work, 
　　unsigned long delay); 
　　int cancel_delayed_work(struct work_struct *work); 
　　void flush_workqueue(struct workqueue_struct *queue); 
　　void destroy_workqueue(struct workqueue_struct *queue); 
　　int schedule_work(struct work_struct *work); 
　　int schedule_delayed_work(struct work_struct *work, unsigned long 
　　delay);(王朝网络 wangchao.net.cn)

*** Linux内核中内存相关的操作函数
关键字：Linux
　　1、kmalloc()/kfree()

　　static __always_inline void *kmalloc(size_t size, gfp_t flags)

　　内核空间申请指定大小的内存区域，返回内核空间虚拟地址。在函数实现中，如果申请的内存空间较大的话，会从buddy系统申请若干内存页面，如果申请的内存空间大小较小的话，会从slab系统中申请内存空间。

　　gfp_t flags 的选项较多。参考内核文件gfp.h.

　　在函数kmalloc()实现中，如果申请的空间较小，会根据申请空间的大小从slab中获取;如果申请的空间较大，如超过一个页面，会直接从buddy系统中获取。

　　2、vmalloc()/vfree()

　　void *vmalloc(unsigned long size)

　　函数作用：从高端(如果存在，优先从高端)申请内存页面，并把申请的内存页面映射到内核的动态映射空间。vmalloc()函数的功能和alloc_pages(_GFP_HIGHMEM)+kmap() 的功能相似，只所以说是相似而不是相同，原因在于用vmalloc()申请的物理内存页面映射到内核的动态映射区(见下图)，并且，用vmalloc()申请的页面的物理地址可能是不连续的。而alloc_pages(_GFP_HIGHMEM)+kmap()申请的页面的物理地址是连续的，被映射到内核的KMAP区。

　　vmalloc分配的地址则限于vmalloc_start与vmalloc_end之间。每一块vmalloc分配的内核虚拟内存都对应一个vm_struct结构体(可别和vm_area_struct搞混，那可是进程虚拟内存区域的结构)，不同的内核虚拟地址被4k大小的空闲区间隔，以防止越界--见下图)。与进程虚拟地址的特性一样，这些虚拟地址与物理内存没有简单的位移关系，必须通过内核页表才可转换为物理地址或物理页。它们有可能尚未被映射，在发生缺页时才真正分配物理页面。

　　如果内存紧张，连续区域无法满足，调用vmalloc分配是必须的，因为它可以将物理不连续的空间组合后分配，所以更能满足分配要求。vmalloc可以映射高端页框，也可以映射底端页框。vmalloc的作用只是为了提供逻辑上连续的地址…

　　注意：在申请页面时，如果注明_GFP_HIGHMEM,即从高端申请。则实际是优先从高端内存申请，顺序为(分配顺序是HIGH, NORMAL, DMA )。

　　3、alloc_pages()/free_pages()

　　内核空间申请指定个数的内存页，内存页数必须是2^order个页。

　　alloc_pages(gfp_mask, order) 中，gfp_mask 是flag标志，其中可以为_ _GFP_DMA、_GFP_HIGHMEM 分别对应DMA和高端内存。

　　注：该函数基于buddy系统申请内存，申请的内存空间大小为2^order个内存页面。

　　参见《linux内核之内存管理。doc》

　　通过函数alloc_pages()申请的内存，需要使用kmap()函数分配内核的虚拟地址。

　　4、__get_free_pages()/__free_pages()

　　unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)

　　作用相当于alloc_pages(NORMAL)+kmap()，但不能申请高端内存页面。

　　__get_free_page()只申请一个页面。

　　5、kmap()/kunmap()

　　返回指定页面对应内核空间的虚拟地址。

　　#include

　　void *kmap(struct page *page);

　　void kunmap(struct page *page);

　　kmap 为系统中的任何页返回一个内核虚拟地址。

　　对于低端内存页，它只返回页的逻辑地址;

　　对于高端内存页， kmap在"内核永久映射空间"中创建一个特殊的映射。 这样的映射数目是有限， 因此最好不要持有过长的时间。

　　使用 kmap 创建的映射应当使用 kunmap 来释放;

　　kmap 调用维护一个计数器， 因此若2个或多个函数都在同一个页上调用kmap也是允许的。

　　通常情况下，"内核永久映射空间"是 4M 大小，因此仅仅需要一个页表即可，内核通过来 pkmap_page_table 寻找这个页表。

　　注意：不用时及时释放。

　　kmalloc()和vmalloc()相比，kmalloc()总是从ZONE_NORMAL(下图中的直接映射区)申请内存。kmalloc()分配的内存空间通常用于linux内核的系统数据结构和链表。因内核需要经常访问其数据结构和链表，使用固定映射的ZONE_NORMAL空间的内存有利于提高效率。

　　使用vmalloc()可以申请非连续的物理内存页，并组成虚拟连续内存空间。vmalloc()优先从高端内存(下图中的动态映射区)申请。内核在分配那些不经常使用的内存时，都用高端内存空间(如果有)，所谓不经常使用是相对来说的，比如内核的一些数据结构就属于经常使用的，而用户的一些数据就属于不经常使用的。

　　alloc_pages(_GFP_HIGHMEM)+kmap() 方式申请的内存使用内核永久映射空间(下图中的KMAP区)，空间较小(通常4M线性空间)，不用时需要及时释放。另外，可以指定alloc_pages()从直接映射区申请内存，需要使用_GFP_NORMAL属性指定。

　　__get_free_pages()/__free_pages() 不能申请高端内存页面，操作区域和kmalloc()相同(下图中的动态映射区)。



　　6、virt_to_page()

　　其作用是由内核空间的虚拟地址得到页结构。见下面的宏定义。

　　#define virt_to_pfn(kaddr) (__pa(kaddr) 》 PAGE_SHIFT)

　　#define pfn_to_virt(pfn) __va((pfn) 《 PAGE_SHIFT)

　　#define virt_to_page(addr) pfn_to_page(virt_to_pfn(addr))

　　#define page_to_virt(page) pfn_to_virt(page_to_pfn(page))

　　#define __pfn_to_page(pfn) (mem_map + ((pfn) - ARCH_PFN_OFFSET))

　　#define __page_to_pfn(page) ((unsigned long)((page) - mem_map) + \

　　ARCH_PFN_OFFSET)

　　7、物理地址和虚拟地址之间转换

　　#ifdef CONFIG_BOOKE

　　#define __va(x) ((void *)(unsigned long)((phys_addr_t)(x) + VIRT_PHYS_OFFSET))

　　#define __pa(x) ((unsigned long)(x) - VIRT_PHYS_OFFSET)

　　#else

　　#define __va(x) ((void *)(unsigned long)((phys_addr_t)(x) + PAGE_OFFSET - MEMORY_START))

　　#define __pa(x) ((unsigned long)(x) - PAGE_OFFSET + MEMORY_START)

　　#endif

　　8、ioremap()/iounmap()

　　ioremap()的作用是把device寄存器和内存的物理地址区域映射到内核虚拟区域，返回值为内核的虚拟地址。

　　注明：在内核中操作内存空间时使用的都是内核虚拟地址，必须把device的空间映射到内核虚拟空间。

　　#include

　　void *ioremap(unsigned long phys_addr, unsigned long size);

　　void *ioremap_nocache(unsigned long phys_addr, unsigned long size); 映射非cache的io内存区域

　　void iounmap(void * addr);

　　为了增加可移植性，最好使用下面的接口函数读写io内存区域，

　　unsigned int ioread8(void *addr);

　　unsigned int ioread16(void *addr);

　　unsigned int ioread32(void *addr);

　　void iowrite8(u8 value, void *addr);

　　void iowrite16(u16 value, void *addr);

　　void iowrite32(u32 value, void *addr);

　　如果你必须读和写一系列值到一个给定的 I/O 内存地址， 你可以使用这些函数的重复版本：

　　void ioread8_rep(void *addr, void *buf, unsigned long count);

　　void ioread16_rep(void *addr, void *buf, unsigned long count);

　　void ioread32_rep(void *addr, void *buf, unsigned long count);

　　void iowrite8_rep(void *addr, const void *buf, unsigned long count);

　　void iowrite16_rep(void *addr, const void *buf, unsigned long count);

　　void iowrite32_rep(void *addr, const void *buf, unsigned long count);

　　这些函数读或写 count 值从给定的 buf 到 给定的 addr. 注意 count 表达为在被写入的数据大小; ioread32_rep 读取 count 32-位值从 buf 开始。

　　9、request_mem_region()

　　本函数的作用是：外设的io端口映射到io memory region中。在本函数实现中会检查输入到本函数的参数所描述的空间(下面成为本io空间)是否和io memory region中已存在的空间冲突等，并设置本io空间的parent字段等(把本io空间插入到io 空间树种)。

　　注明：io memory region 空间中是以树形结构组织的，默认的根为iomem_resource描述的io空间，其name为"PCI mem".

　　request_mem_region(start,n,name) 输入的参数依次是设备的物理地址，字节长度，设备名字。函数返回类型如下

　　struct resource {

　　resource_size_t start;

　　resource_size_t end;

　　const char *name;

　　unsigned long flags;

　　struct resource *parent, *sibling, *child;

　　};

　　10、SetPageReserved()

　　随着linux的长时间运行，空闲页面会越来越少，为了防止linux内核进入请求页面的僵局中，Linux内核采用页面回收算法(PFRA)从用户进程和内核高速缓存中回收内存页框，并根据需要把要回收页框的内容交换到磁盘上的交换区。调用该函数可以使页面不被交换。

　　#define SetPageReserved(page) set_bit(PG_reserved, &(page)->flags)

　　PG_reserved 的标志说明如下。

　　* PG_reserved is set for special pages, which can never be swapped out. Some

　　* of them might not even exist (eg empty_bad_page)…

　　11、do_mmap()/do_ummap()

　　内核使用do_mmap()函数为进程创建一个新的线性地址区间。但是说该函数创建了一个新VMA并不非常准确，因为如果创建的地址区间和一个已经存在的地址区间相邻，并且它们具有相同的访问权限的话，那么两个区间将合并为一个。如果不能合并，那么就确实需要创建一个新的VMA了。但无论哪种情况， do_mmap()函数都会将一个地址区间加入到进程的地址空间中--无论是扩展已存在的内存区域还是创建一个新的区域。

　　同样，释放一个内存区域应使用函数do_ummap()，它会销毁对应的内存区域。

　　12、get_user_pages()

　　作用是在内核空间获取用户空间内存的page 描述，之后可以通过函数kmap() 获取page 对应到内核的虚拟地址。

　　int get_user_pages(struct task_struct *tsk, struct mm_struct *mm,

　　unsigned long start, int len, int write, int force,

　　struct page **pages, struct vm_area_struct **vmas)

　　参数说明

　　参数tsk:指示用户空间对应进程的task_struct数据结构。只是为了记录错误信息用，该参数可以为空。

　　参数mm:从该mm struct中获取start 指示的若干页面。

　　参数start:参数mm空间的起始地址，即用户空间的虚拟地址。

　　参数len:需要映射的页数。

　　参数write:可以写标志。

　　参数force:强制可以写标志。

　　参数pages:输出的页数据结构。

　　参数vmas:对应的需要存储区，(没有看明白对应的代码)

　　返回值：数返回实际获取的页数，貌似对每个实际获取的页都是给页计数值增1,如果实际获取的页不等于请求的页，要放弃操作则必须对已获取的页计数值减1.

　　13、copy_from_user()和copy_to_user()

　　主要应用于设备驱动中读写函数中，通过系统调用触发，在当前进程上下文内核态运行(即当前进程通过系统调用触发)。

　　copy_from_user的目的是防止用户程序欺骗内核，将一个非法的地址传进去，如果没有它，这一非法地址就检测不到，内和就会访问这个地址指向的数据。因为在内核中访问任何地址都没有保护，如果不幸访问一个错误的内存地址会搞死内核或发生更严重的问题

　　copy_from_user调用了access_ok,所以才有"自己判断功能"

　　access_ok()，可以检查访问的空间是否合法。

　　注意：中断代码时不能用copy_from_user,因为其调用了might_sleep()函数，会导致睡眠。

　　unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)

　　通常用在设备读函数或ioctl 中获取参数的函数中：其中"to"是用户空间的buffer地址，在本函数中将内核buffer"from"除的n个字节拷贝到用户空间的"to"buffer.

　　unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)

　　通常用在设备写函数或ioctl中设置参数的函数中："to"是内核空间的buffer指针，要写入的buffer;"from"是用户空间的指针，数据源buffer.

　　14、get_user(x, ptr)

　　本函数的作用是获取用户空间指定地址的数值并保存到内核变量x中，ptr为用户空间的地址。用法举例如下。

　　get_user(val, (int __user *)arg)

　　注明：函数用户进程上下文内核态，即通常在系统调用函数中使用该函数。

　　15、put_user(x, ptr)

　　本函数的作用是将内核空间的变量x的数值保存到用户空间指定地址处，prt为用户空间地址。用法举例如下。

　　put_user(val, (int __user *)arg)

　　注明：函数用户进程上下文内核态，即通常在系统调用函数中使用该函数。


*** 内核和用户态之间共享内存
可以参考我的linuxdemo中的memKernelShareToUsr这个demo
**** 内核态使用remap_pfn_range来将内核内存映射给用户态
内核的驱动程序使用remap_pfn_range()结合设备驱动文件的mmap操作来将内存共享至用户态
-----------以下是内核态代码------
/* 在file_operations中指定设备驱动对应mmap操作的钩子函数是mem_mmap() */
struct file_operations Fops = {
    .read = char_read,
    .write = char_write,
    .open = char_open,
    .release = char_release,/* a.k.a. close */
    .mmap = mem_mmap,
};


unsigned long gsize = 4096 * 10;
unsigned char *mem_msg_buf = NULL;
/* 这里是设备驱动的初始化函数, 在设备驱动初始化的时候将要共享到用户态的内存分配好， */ 
/* 调用自己写的函数malloc_reserved_mem()来进行分配 */
int memDev_init(){
.....
    mem_msg_buf = malloc_reserved_mem(gsize);
.....
}
module_init(memDev_init);

/* 分配共享内存空间的时候，一定要使用kmalloc来申请，因为kmalloc会分配一块内存，这块内存在物理和逻辑上都是连续的 */
/* 分配出来的内存空间首地址赋值给p，p里面存放的是虚拟地址*/
/* 通过一个for循环，将kmalloc分配出来的这块内存块中所有的页都做一次SetPageReserved()操作，这样这些内存才能被remap_pfn_range()至用户态 */
/* SetPageReserved()的作用是指定该地址所在的页面不会被swap out 至硬盘中去 */
static unsigned char * malloc_reserved_mem(unsigned int size){
    unsigned char *p = kmalloc(size, GFP_KERNEL);
    unsigned char *tmp = p;
    unsigned int i, n;
    if (NULL == p){
        printk("Error : malloc_reserved_mem kmalloc failed!\n");
        return NULL;
    }
    n = size / 4096 + 1;
    if (0 == size % 4096 ){
        --n;
    }
    for (i = 0; i < n; ++i){
        SetPageReserved(virt_to_page(tmp));
        tmp += 4096;
    }
    return p;
}

/* 当用户态对驱动设备文件进行mmap操作的时候，就会触发这个函数 */
/* 这个函数做的事情很简单，就是调用remap_pfn_range把内核态的内存映射至用户态 , remap_pfn_range()可以指定一块物理内存映射到一块虚拟内存地址上。*/
/* vma是一个结构体，kernel用这个结构体来定义mmap出来的这一块虚拟内存 */
/* 大致操作就是：vma->start开始的这一段虚拟内存映射上mypfn这个物理地址，映射的长度为vmsize指定 */
/* mypfn就是mem_msg_buf的物理地址的页号，所以也就是将mem_msg_buf映射到了用户态的虚拟地址上 */
int mem_mmap(struct file *filp, struct vm_area_struct *vma){
    printk("in mem_mmap\n");
    unsigned long offset = vma->vm_pgoff << PAGE_SHIFT; 
    unsigned long  physics = ((unsigned long )mem_msg_buf)-PAGE_OFFSET;
    unsigned long mypfn = physics >> PAGE_SHIFT;
    unsigned long vmsize = vma->vm_end-vma->vm_start;
    unsigned long psize = gsize - offset;
    if(vmsize > psize)
        return -ENXIO;
    if(remap_pfn_range(vma,vma->vm_start,mypfn,vmsize,vma->vm_page_prot))
        return -EAGAIN;
    return 0;
}

----------------------下面让我们来看一下用户态是怎么实现的吧-----------------------
用户态所要做的事情非常简单，
首先open驱动设备文件，
然后对该文件进行mmap操作就可以了，
进行mmap操作的时候，如果第一个参数是NULL，则有libc自己分配一块虚拟内存区域，这一块虚拟内存区域将对应于上面的vma
这里还需特别注意的三点就是这里的size的设置，这里的size的设置将决定上面所述vma中start 和 end之间的差，所以一定要和内核中物理内存区域大小对应起来。
另外这里PROT的设置，PROT的设置对应上面vma中的vm_page_prot，如果需要读写，则要设置为PROT_READ|PROT_WRITE
第三点就是MAP_SHARED的设置，如果设置成MAP_SHARED，用户态的虚拟空间就确实映射到了内核态中开辟的空间的物理地址上，就是实实在在的一块内存了。
当然这里也可以设置为MAP_PRIVATE，如果这么设置，那么在mmap的时候，是从内核态开辟的空间的物理地址上做一次copy，copy到用户态的虚拟地址上，所以这样事实上还是两块内存。

void *g_pBuffer = NULL;
int g_fd = -1;

void * getMemMsgBuf(){
    unsigned char * ret;
    if (NULL != g_pBuffer){
        return g_pBuffer;
    }

    if (g_fd < 0){
        g_fd = open("/dev/memMsgDev", O_RDWR);
        if (0 > g_fd){
            printf("Error : getMemMsgBuf() open /dev/memMsgDev failed , errno = %d \n", errno);
            return NULL;
        }
    }

    g_pBuffer = mmap(NULL, 4096 * 10,PROT_READ|PROT_WRITE,MAP_SHARED, g_fd,0 );
    if( g_pBuffer == MAP_FAILED ) {
        printf("Error : getMemMsgBuf() fail mmap!\n");
        return NULL;
    }
    
    return g_pBuffer;
}



** proc目录详解
*** /proc/stat
cpu 2032004 102648 238344 167130733 758440 15159 17878 0
 
cpu0 1022597 63462 141826 83528451 366530 9362 15386 0
 
cpu1 1009407 39185 96518 83602282 391909 5796 2492 0
 
intr 303194010 212852371 3 0 0 11 0 0 2 1 1 0 0 3 0 11097365 0 72615114 6628960 0 179 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0


user (2032004)
从系统启动开始累计到当前时刻，用户态的CPU时间，不包含nice值为负进程。

nice (102648)
从系统启动开始累计到当前时刻，nice值为负的进程所占用的CPU时间

system (238344)
从系统启动开始累计到当前时刻，核心时间

idle (167130733)
从系统启动开始累计到当前时刻，除IO等待时间以外其它等待时间

iowait (758440)
从系统启动开始累计到当前时刻，IO等待时间

irq (15159)
从系统启动开始累计到当前时刻，硬中断时间

softirq (17878)
从系统启动开始累计到当前时刻，软中断时间 




*** /proc/pid/stat
[zhengangen@buick ~]# cat /proc/6873/stat
6873 (a.out) R 6723 6873 6723 34819 6873 8388608 77 0 0 0 41958 31 0 0 25 0 3 0 5882654 1409024 56 4294967295 134512640 134513720 3215579040 0 2097798 0 0 0 0 0 0 0 17 0 0 0
pid 位置1 ； utime位置14，后面依次
pid=6873                            进程号
utime=1587                       该任务在用户态运行的时间，单位为jiffies
stime=41958                      该任务在核心态运行的时间，单位为jiffies
cutime=0                            所有已死线程在用户态运行的时间，单位为jiffies
cstime=0                            所有已死在核心态运行的时间，单位为jiffies

** kernel学习
*** 启动 （自己总结）							 
**** start_kernel
1) page_address_init()  
   初始化page_address_pool, 将page_address_maps都挂载page_address_pool
   以及初始化page_address_htable,
   在highmem.c中, 
2) pidhash_init()
   这个函数是在slab还没有建立起来之前，就通过申请内存来建立hash表的，
   获取内存的调用顺序是pidhash_init()->alloc_large_system_hash()->alloc_bootmem_nopanic()->___alloc_bootmem_nopanic()->__alloc_memory_core_early()
   在__alloc_memory_core_early()中通过early_node_map来获取原始的内存，这个函数中通过调用find_early_area()函数来判断页有没有被申请过，bad_addr()这个函数就是用来判断页是否能进行申请的。
   early_node_map这个数据结构在setup_arch()中会进行设置
3) rest_init()
   这个函数会创建0号进程
   就是通过kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND);
   在kernel_init线程中会进一步调用init进程，也就是1号进程
   rest_init()还会继续启动[kthread]内核进程(2号进程)，这个内核线程是用来调度其他内核线程的
   还会调用pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);

*** 启动网上介绍
在命令行下，输入：ps aux|top 3得到： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 6016 3392 ? Ss Nov05 0:24 init [3] root 2 0.0 0.0 0 0 ? S< Nov05 0:00 [kthreadd] 
显然，kthread是init之后系统创建的第二个进程，创建背景如何？ 
1 系统启动后，根据/boot/efi/efi/redhat/elilo.conf配置，解压缩并执行vmlinuz-2.6.28.10-vs2.3.0.36.11.85b16.hit内核，其执行/arch/ia64/kernel/head.S文件，进行软硬件初始化，后执行start_kernel（位于init/main.c）内核主函数，其执行如下操作： 输出Linux版本信息（printk(linux_banner)） 设置与体系结构相关的环境（setup_arch()） 页表结构初始化（paging_init()） 使用"arch/alpha/kernel/entry.S"中的入口点设置系统自陷入口（trap_init()） 使用alpha_mv结构和entry.S入口初始化系统IRQ（init_IRQ()） 核心进程调度器初始化（包括初始化几个缺省的Bottom-half，sched_init()） 时间、定时器初始化（包括读取CMOS时钟、估测主频、初始化定时器中断等，time_init()） 提取并分析核心启动参数（从环境变量中读取参数，设置相应标志位等待处理，（parse_options()） 控制台初始化（为输出信息而先于PCI初始化，console_init()） 剖析器数据结构初始化（prof_buffer和prof_len变量） 核心Cache初始化（描述Cache信息的Cache，kmem_cache_init()） 延迟校准（获得时钟jiffies与CPU主频ticks的延迟，calibrate_delay()） 内存初始化（设置内存上下界和页表项初始值，mem_init()） 创建和设置内部及通用cache（"slab_cache"，kmem_cache_sizes_init()） 创建uid taskcount SLAB cache（"uid_cache"，uidcache_init()） 创建文件cache（"files_cache"，filescache_init()） 创建目录cache（"dentry_cache"，dcache_init()） 创建与虚存相关的cache（"vm_area_struct"，"mm_struct"，vma_init()） 块设备读写缓冲区初始化（同时创建"buffer_head"cache用户加速访问，buffer_init()） 创建页cache（内存页hash表初始化，page_cache_init()） 建信号队列cache（"signal_queue"，signals_init()） 初始化内存inode表（inode_init()） 创建内存文件描述符表（"filp_cache"，file_table_init()） 检查体系结构漏洞（对于alpha，此函数为空，check_bugs()） SMP机器其余CPU（除当前引导CPU）初始化（对于没有配置SMP的内核，此函数为空，smp_init()） 之后，start_kernel调用rest_init(void)[位于init/main.c文件中]开启了有内核初始化向进程调度执行的转移 
2 rest_init（） --->kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND) 创建kenel_init内核线程 pid = 1 --->kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES) 创建kthreadd，[kthreadd_task] --->complete(&kthreadd_done) 激活内核线程 --->schedule() 进程调度，init内核线程开始执行kernel_init函数，其调用/sbin/init，完成/etc/inittab及之后的系统启动操作 
3 kernel_thread执行 内核线程创建过程 对于ia64系统，在\arch\ia64\kernel\process.c文件中start_kernel_thread
4 kthreadd内核线程执行过程 int kthreadd(void *unused) 
  可见kthreadd内核线程的睡眠过程不能被信号随便中断，且每次执行时，依次执行kthread_create_list中的每个 线程创建请求结构体，创建新的内核线程。 
    4.1内核线程如何添加到kthread_create_list列表中？ 内核模块可以调用导出函数kthread_create函数创建新内核线程 
    struct kthread_create_info{ 
        /* Information passed to kthread() from kthreadd. */ 
	int (*threadfn)(void *data); 
	void *data; 
	/* Result passed back to kthread_create() from kthreadd. */ 
	struct task_struct *result; 
	struct completion done; 
	struct list_head list; }; 
    函数执行过程：子线程创建成功后，会执行threadfn函数 
struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...) 
     4.2 kthreadd内核线程创建新线程，并唤醒等待新线程的线程 位于kernel/kthread.c文件中 static void create_kthread(struct kthread_create_info *create) 
          4.2.1 在上面调用kernel_thread创建新线程时，kthread为新线程创建后执行的第一个函数，create为该函数的参数，所以通过kthread函数完成新线程和struct kthread_create_info的连接。 
                  static int kthread(void *_create) { /* Copy data: it's on kthread's stack */ 
		      struct kthread_create_info *create = _create; int (*threadfn)(void *data) = create->threadfn; 
		      void *data = create->data; 
		      struct kthread self; 
		      int ret; self.should_stop = 0; 
		      init_completion(&self.exited); 
		      current->vfork_done = &self.exited; 
		      /* OK, tell user we're spawned, wait for stop or wakeup */ 
		      __set_current_state(TASK_UNINTERRUPTIBLE); 
		      //新线程进入睡眠状态，除非被初始创建该线程的等待线程显式的唤醒[显然这里不可能时kthreadd线程] 
		      create->result = current; 和kthread_create_info连接在一起 complete(&create->done); 
		      成功时，唤醒初始创建该线程的等待线程[显然不是kthreadd线程] 
		      schedule(); 
		      ret = -EINTR; if (!self.should_stop) ret = threadfn(data); 显然新线程在创建初，必须设置好其将要执行的函数，否则，没有意义 
		      /* we can't just return, we must preserve 保存"self" on stack */ 
		      do_exit(ret) ; // 内核线程执行完任务，关荣退役 } 
		可见内核模块可以调用kthread_create接口创建内核线程，但是在创建过程中必须传入其执行的函数和参数，以及新内核线程的名字等，然后内核模块显示的唤醒kthreadd，并等待kthreadd帮自己创建内核线程，当kthreadd创建新进程完毕后，会唤醒内核模块，此时新的内核线程已经在kthread_create_info->result中，但是其处于不可被中断的睡眠状态，所以此时内核模块必须显示调用wake_up_process(struct task_struct*)唤醒新内核线程，其才能被内核调度执行。 注: a:kthreadd pid=2，task_struct结构体为名称为：kthreadd_task ，其kthreadd_task ->comm =kthreadd其task_struct来源于内核创建之初构造的task_struct，所以其代码段是整个内核空间，没有办法针对其内核空间进行故障检测，且kthreadd执行过程中也没有printk信息,所以也没有办法从klogd内核日志获得信息 b: ktheadd是唯一一个从全局线程链表kthread_create_info中取出节点的程序，但是该链表不是导出变量，无法确定其地址 c:ktheadd在创建之初，调用do_fork()时，为： do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, ®s.pt, 0, NULL, NULL); 由于 CLONE_UNTRACED标志，使得调试器无法跟踪，所以内核线程也不能被跟踪去确定函数地址 d:内核线程好像无法被杀死，由于其task_struct都是来自于内核最开始构造的task_struct，所以该task_struct中应该屏蔽了对所有信号的处理操作,研究这个task_struct结构体 e:但是可以通过自己模拟内核模块，创建新线程来探测kthreadd工作情况，以及通过ps来统计kthread情况，由于ps肯定能得到kthreadd的task_struct结构体，所以可以通过task_struct来推断出kthreadd的执行情况[比如每次执行create_kthread函数，以及可以分析kthread_create_list结构体] 进程0作用： 1. 进程0是所有其他进程的祖先, 也称作idle进程或swapper进程. 2. 进程0是在系统初始化时由kernel自身从无到有创建. 3. 进程0的数据成员大部分是静态定义的，即由预先定义好的INIT_TASK, INIT_MM等宏初始化. 进程0的描述符init_task定义在arch/arm/kernel/init_task.c,由INIT_TASK宏初始化。 init_mm等结构体定义在include/linux/init_task.h内，为init_task成员的初始值,分别由对应的初始化宏如INIT_MM等初始化



   





*** 任务调度
**** schedual函数群的学习
linux内核进程调度的核心函数是schedule
对这个函数的介绍有一个非常好的博客
http://blog.csdn.net/sunnybeike/article/details/6914703

schedule的代码就不用贴了，在kernel/sched.c文件中

其先通过 rq = cpu_rq(cpu); 获得当前cpu中的任务队列，
然后令prev = rq->curr;

同时通过 next = pick_next_task(rq);  将下一个需要调度的任务结构体付给next， 关于这个函数的原理可以参考博客 http://blog.csdn.net/sunnybeike/article/details/6918586

接着通过  context_switch(rq, prev, next);  函数来完成上下文的切换，  代码在kernel/sched.c中

context_switch是schedule中至关重要的一个函数，对于这个函数的介绍，可以参考博客  http://blog.csdn.net/sunnybeike/article/details/6945701

context_switch和schedule这两个函数都是和架构无关的函数，所以他们都是放在kernel目录中的，这个也是linux内核设计的巧妙之处，他将和架构无关的逻辑都抽取出来了，然后将架构有关的代码分别放在对应的CPU目录下面。

在context_switch中又有两个至关重要的函数switch_mm  和 switch_to

switch_mm和switch_to这两个函数就是和架构相关的函数，所以要到对应的CPU目录下面去找，以X86为例，这两个函数在 arch\x86\include\asm\mmu_context.h 和system.h目录下面

按照我的理解switch_mm是切换到next任务的MMU，即将页表目录切换到next任务的页表目录。 但是这个时候除了MMU以外其他的上下文，如堆栈啦、寄存器什么的都还是prev的寄存器。
那么就有一个奇怪的问题了，MMU内存页表都切到next任务的MMU了，怎么还能执行prev任务的上下文呢？哦，其实原因也非常的简单，这个就是linux内核设计的巧妙之处了。因为所有任务在内核态的内存映射都是一样的：）

另一个关键的函数是switch_to （其实是一个宏），这个宏掉完，整个上下文就切换到了next任务了。
可以参考 http://zenhumany.blog.163.com/blog/static/171806633201082892851728/
switch_to中还有一个更加核心的函数__switch_to，这个核心函数在arch\x86\kernel\process_32.c文件中
swith_to的一段代码是这么写的：
    "pushfl\n\t" \
    "pushl %�p\n\t" \
//prev任务保护现场
    "movl %%esp,%[prev_sp]\n\t" \
    "movl %[next_sp],%%esp\n\t" \
//切换到next的esp，注意局部变量受ebp控制，所以这里不影响局部变量
    "movl $1f,%[prev_ip]\n\t" \
    "pushl %[next_ip]\n\t" \
//上面两行要结合起来看，其意思是只要任务不是第一次被调度，那么他被__switch_to之后都会从1:这个位置开始运行 ，  $1f，代表label 1：的地址。 具体说来就是将1:的地址放在了prev_ip中，下次切换到prev任务的时候，就通过pushl %[next_ip]，将这次存放的1:的地址压到栈中，供__switch_to返回时使用。这样其实是一种花哨的作法，功能其实非常简单，只是为了提高效率，也就是说单反是任务切换，切换后的任务总是从1:这个地方开始执行，因为在他上次被切换走时已经。当然如果任务是第一次被创建出来的，第一次被调度的，那他作为next时next_ip中存放的不是1：，而是ret_from_fork。
    __switch_canary \
    "jmp __switch_to\n" \
    "1:\t" \
    "popl %�p\n\t" \
    "popfl\n" \


__switch_to这个函数就看不太懂了，但是其中有一句看懂了
load_sp0(tss, next); ， 这句展开就是  init_tss[cpu].esp0 = next_p->thread.esp0;
3. 把next_p->thread.esp0装入对应于本地CPU的TSS的esp0字段（load_esp0(tss, next)）；我们将在“通过sysenter指令发生系统调用”博文看到，以后任何由sysenter汇编指令产生从用户态到内核态的特权级转换将把这个地址拷贝到TSS段中esp寄存器对应的那个字段：
    init_tss[cpu].esp0 = next_p->thread.esp0;
参考  http://blog.csdn.net/t_p_zhou/article/details/7514122


那么当__switch_to返回之后，就会进入前面在堆栈中准备好的1:那个地址上，然后通过pop恢复next任务的bsp等上下文

*** 网络
**** netfilter
http://www.ibm.com/developerworks/cn/linux/l-ntflt/

*** 内存管理mm
**** 初始化
***** page_address_pool()   在highmem.c文件中
***** free_all_bootmem_core()
6.2.4 页面管理机制的初步建立
    为了对页面管理机制作出初步准备，Linux使用了一种叫bootmem分配器(bootmem allocator)的机制，这种机制仅仅用在系统引导时，它为整个物理内存建立起一个页面位图。这个位图建立在从start_pfn开始的地方，也就是说，内核映象终点_end上方的地方。这个位图用来管理低区（例如小于896MB），因为在0到896MB的范围内，有些页面可能保留，有些页面可能有空洞，因此，建立这个位图的目的就是要搞清楚哪一些物理页面是可以动态分配的。用来存放位图的数据结构为bootmem_data（在mm/numa.c中） ：
       typedef struct bootmem_data {
           unsigned long node_boot_start;
           unsigned long node_low_pfn;
           void *node_bootmem_map;
           unsigned long last_offset;
           unsigned long last_pos;
       } bootmem_data_t;
 
·      node_boot_start表示存放bootmem位图的第一个页面（即内核映象结束处的第一个页面）。
·      node_low_pfn表示物理内存的顶点，最高不超过896MB。
·      node_bootmem_map指向bootmem位图
·      last_offset 用来存放在前一次分配中所分配的最后一个字节相对于last_pos的位移量。
·      last_pos 用来存放前一次分配的最后一个页面的页面号。这个域用在__alloc_bootmem_core()函数中，通过合并相邻的内存来减少内部碎片。
下面介绍与bootmem相关的几个函数，这些函数位于mm/bootmeme.c中。
1. init_bootmem()函数
unsigned long __init init_bootmem (unsigned long start, unsigned long pages)
{
         max_low_pfn = pages;
         min_low_pfn = start;
         return(init_bootmem_core(&contig_page_data, start, 0, pages));
}
   这个函数仅在初始化时用来建立bootmem分配器。这个函数实际上是init_bootmem_core()函数的封装函数。init_bootmem（）函数的参数start表示内核映象结束处的页面号，而pages表示物理内存顶点所在的页面号。而函数init_bootmem_core()就是对contig_page_data变量进行初始化。下面我们来看一下对该变量的定义：
 
int numnodes = 1;       /* Initialized for UMA platforms */
 
static bootmem_data_t contig_bootmem_data;
pg_data_t contig_page_data = { bdata: &contig_bootmem_data };
 
     变量contig_page_data的类型就是前面介绍过的pg_data_t数据结构。每个pg_data_t数据结构代表着一片均匀的、连续的内存空间。在连续空间UMA结构中，只有一个节点contig_page_data，而在NUMA结构或不连续空间UMA结构中，有多个这样的数据结构。系统中各个节点的pg_data_t数据结构通过node_next连接在一起成为一个链。有一个全局量pgdat_list则指向这个链。从上面的定义可以看出，contig_page_data是链中的第一个节点。这里假定整个物理空间为均匀的、连续的，以后若发现这个假定不能成立，则将新的pg_data_t结构加入到链中。
pg_data_t结构中有个指针bdata，contig_page_data被初始化为指向bootmem_data_t数据结构。下面我们来看init_bootmem_core（）函数的具体代码：
/*
  * Called once to set up the allocator itself.
    */
static unsigned long __init init_bootmem_core (pg_data_t *pgdat,
         unsigned long mapstart, unsigned long start, unsigned long end)
{
         bootmem_data_t *bdata = pgdat->bdata;
         unsigned long mapsize = ((end - start)+7)/8;
 
         pgdat->node_next = pgdat_list;
         pgdat_list = pgdat;
 
         mapsize = (mapsize + (sizeof(long) - 1UL)) & ~(sizeof(long) - 1UL);
         bdata->node_bootmem_map = phys_to_virt(mapstart << PAGE_SHIFT);
         bdata->node_boot_start = (start << PAGE_SHIFT);
         bdata->node_low_pfn = end;
 
        /*
          * Initially all pages are reserved - setup_arch() has to
          * register free RAM areas explicitly.
         */
         memset(bdata->node_bootmem_map, 0xff, mapsize);
 
         return mapsize;
}
    下面对这一函数给予说明：
·      变量mapsize存放位图的大小。(end - start)给出现有的页面数，再加个7是为了向上取整，除以8就获得了所需的字节数（因为每个字节映射8个页面）。
·      变量pgdat_list用来指向节点所形成的循环链表首部，因为只有一个节点，因此使pgdat_list指向自己。
·      接下来的一句使memsize成为下一个4的倍数（4为CPU的字长）。例如，假设有40个物理页面，因此，我们可以得出memsize为5个字节。所以，上面的操作就变为（5＋（4－1））＆~(4-1)即(00001000&11111100)，最低的两位变为0，其结果为8。这就有效地使memsize变为4的倍数。
·      phys_to_virt(mapstart << PAGE_SHIFT)把给定的物理地址转换为虚地址。
·      用节点的起始物理地址初始化node_boot_start（这里为0x00000000）
·      用物理内存节点的页面号初始化node_low_pfn。
·      初始化所有被保留的页面，即通过把页面中的所有位都置为1来标记保留的页面
·      返回位图的大小。
2. free_bootmem()函数
    这个函数把给定范围的页面标记为空闲（即可用），也就是，把位图中某些位清0，表示相应的物理内存可以投入分配。
    原函数为：
       void __init free_bootmem (unsigned long addr, unsigned long size)
    {
 
        return(free_bootmem_core(contig_page_data.bdata, addr, size));
     }
从上面可以看出，free_bootmem（）是个封装函数，实际的工作是由free_bootmem_core()函数完成的：
static void __init free_bootmem_core(bootmem_data_t *bdata, unsigned long addr, unsigned long size)
{
         unsigned long i;
         unsigned long start;
         /*
          * round down end of usable mem, partially free pages are
         * considered reserved.
          */
        unsigned long sidx;
        unsigned long eidx = (addr + size - bdata->node_boot_start)/PAGE_SIZE;
        unsigned long end = (addr + size)/PAGE_SIZE;
 
        if (!size) BUG();
          if (end > bdata->node_low_pfn)
                BUG();
 
           /*
          * Round up the beginning of the address.
          */
        start = (addr + PAGE_SIZE-1) / PAGE_SIZE;
        sidx = start - (bdata->node_boot_start/PAGE_SIZE);
 
        for (i = sidx; i < eidx; i++) {
                if (!test_and_clear_bit(i, bdata->node_bootmem_map))
                         BUG();
         }
}
对此函数的解释如下：
·      变量edix被初始化为页面总数。
·      变量end被初始化为最后一个页面的页面号。
·      进行两个可能的条件检查.
·      start初始化为第一个页面的页面号（向上取整），而sidx(start index)初始化为相对于node_boot_start.的页面号。
·      清位图中从sidx到eidx的所有位，即把这些页面标记为可用。
3. reserve_bootmem()函数
  这个函数用来保留页面。为了保留一个页面，只需要在bootmem位图中把相应的位置为1即可。
  原函数为：
  void __init reserve_bootmem (unsigned long addr, unsigned long size)
   {
         reserve_bootmem_core(contig_page_data.bdata, addr, size);
   }
  reserve_bootmem（）为封装函数，实际调用的是reserve_bootmem_core（）函数：
  static void __init reserve_bootmem_core(bootmem_data_t *bdata, unsigned long addr, unsigned long size)
{
         unsigned long i;
         /*
          * round up, partially reserved pages are considered
          * fully reserved.
         */
         unsigned long sidx = (addr - bdata->node_boot_start)/PAGE_SIZE;
         unsigned long eidx = (addr + size - bdata->node_boot_start +
                                                         PAGE_SIZE-1)/PAGE_SIZE;
         unsigned long end = (addr + size + PAGE_SIZE-1)/PAGE_SIZE;
 
         if (!size) BUG();
 
         if (sidx < 0)
                 BUG();
         if (eidx < 0)
                 BUG();
        if (sidx >= eidx)
                 BUG();
         if ((addr >> PAGE_SHIFT) >= bdata->node_low_pfn)
                 BUG();
         if (end > bdata->node_low_pfn)
                 BUG();
         for (i = sidx; i < eidx; i++)
                 if (test_and_set_bit(i, bdata->node_bootmem_map))
                         printk("hm, page %08lx reserved twice.\n", i*PAGE_SIZE);
}
对此函数的解释如下：
·      sidx (start index)初始化为相对于node_boot_start的页面号
·      变量eidx初始化为页面总数（向上取整）。
·      变量end初始化为最后一个页面的页面号（向上取整）。
·      进行各种可能的条件检查.
·      把位图中从sidx到eidx的所有位置1
4．__alloc_bootmem()函数
   这个函数以循环轮转的方式从不同节点分配页面。因为在i386上只有一个节点，因此只循环一次。
   函数原型为：
       void * __alloc_bootmem (unsigned long size,
                               unsigned long align,
                               unsigned long goal);
       void * __alloc_bootmem_core (bootmem_data_t *bdata,
                                    unsigned long size,
                                    unsigned long align,
                                    unsigned long goal);
 
    其中__alloc_bootmem()为封装函数，实际调用的函数为__alloc_bootmem_core （），因为__alloc_bootmem_core （）函数比较长，下面分片断来进行仔细分析：
 
              unsigned long i, start = 0;
              void *ret;
              unsigned long offset, remaining_size;
              unsigned long areasize, preferred, incr;
              unsigned long eidx = bdata->node_low_pfn -
                           (bdata->node_boot_start >> PAGE_SHIFT);
 
   把eidx初始化为本节点中现有页面的总数。
 
              if (!size) BUG();
              if (align & (align-1))
                         BUG();
 
进行条件检查
 
              /*
              * We try to allocate bootmem pages above 'goal'
              * first, then we try to allocate lower pages.
              */
              if (goal && (goal >= bdata->node_boot_start) &&
                   ((goal >> PAGE_SHIFT) < bdata->node_low_pfn)) {
                         preferred = goal - bdata->node_boot_start;
              } else
           preferred = 0;
              preferred = ((preferred + align - 1) & ~(align - 1)) >> PAGE_SHIFT;
                                                  
开始分配后首选页的计算分为两步：
    （1）如果goal为非0且有效，则给preferred赋初值，否则，其初值为0。
（2）根据参数align 来对齐preferred的物理地址。
 
              areasize = (size+PAGE_SIZE-1)/PAGE_SIZE;
 
获得所需页面的总数（向上取整）
 
                  incr = align >> PAGE_SHIFT ? : 1;
 
根据对齐的大小来选择增加值。除非大于4K（很少见），否则增加值为1。
 
              restart_scan:
                   for (i = preferred; i < eidx; i += incr) {
                 unsigned long j;
                   if (test_bit(i, bdata->node_bootmem_map))
                             continue;
 
这个循环用来从首选页面号开始，找到空闲的页面号。test_bit()宏用来测试给定的位，如果给定位为1，则返回1
 
           for (j = i + 1; j < i + areasize; ++j) {
               if (j >= eidx)
                   goto fail_block;
               if (test_bit (j, bdata->node_bootmem_map))
                  goto fail_block;
           }
 
这个循环用来查看在首次满足内存需求以后，是否还有足够的空闲页面。如果没有空闲页，就跳到fail_block。
          
   start = i;
       goto found;
 
如果一直到了这里，则说明从i开始找到了足够的页面，跳过fail_block并继续。
 
                  fail_block:;
                 }
             if (preferred) {
                preferred = 0;
                goto restart_scan; 
                   }
            return NULL;
 
如果到了这里，从首选页面中没有找到满足需要的连续页面，就忽略preferred的值，并从0开始扫描。如果preferred为1，但没有找到满足需要的足够页面，则返回NULL。
 
            found:
已经找到足够的内存，继续处理请求。
 
                 if (start >= eidx)
                     BUG();
 
进行条件检查。
 
       /*
       * Is the next page of the previous allocation-end the start
       * of this allocation's buffer? If yes then we can 'merge'
       * the previous partial page with this allocation.
       */
       if (align <= PAGE_SIZE && bdata->last_offset
                              && bdata->last_pos+1 == start) {
           offset = (bdata->last_offset+align-1) & ~(align-1);
           if (offset > PAGE_SIZE)
               BUG();
           remaining_size = PAGE_SIZE-offset;
 
    if语句检查下列条件：
    （1）所请求对齐的值小于页的大小（4k）。
（2）变量last_offset为非0。如果为0，则说明前一次分配达到了一个非常好的页面边界，没有内部碎片。
（3）检查这次请求的内存是否与前一次请求的内存是相临的，如果是，则把两次分配合在一起进行。
如果以上三个条件都满足，则用前一次分配中最后一页剩余的空间初始化remaining_size。
 
           if (size < remaining_size) {
               areasize = 0;
               // last_pos unchanged
               bdata->last_offset = offset+size;
               ret = phys_to_virt(bdata->last_pos*PAGE_SIZE
                             + offset + bdata->node_boot_start);
 
如果请求内存的大小小于前一次分配中最后一页中的可用空间，则没必要分配任何新的页。变量last_offset增加到新的偏移量，而last_pos保持不变，因为没有增加新的页。把这次新分配的起始地址存放在变量ret中。宏phys_to_virt()返回给定物理地址的虚地址。
 
           } else {
               remaining_size = size - remaining_size;
               areasize = (remaining_size+PAGE_SIZE-1)/PAGE_SIZE;
               ret = phys_to_virt(bdata->last_pos*PAGE_SIZE
                              + offset + bdata->node_boot_start);
               bdata->last_pos = start+areasize-1;
               bdata->last_offset = remaining_size;
 
所请求的大小大于剩余的大小。首先求出所需的页面数，然后更新变量last_pos 和 last_offset。
例如，在前一次分配中，如果分配了9k，则占用3个页面，内部碎片为12k-9k=3k。因此，page_offset为1k，且剩余大小为3k。如果新的请求为1k，则第3个页面本身就能满足要求，但是，如果请求的大小为10k，则需要新分配((10 k- 3k) + PAGE_SIZE-1)/PAGE_SIZE，即2个页面，因此，page_offset为3k。
 
           }
           bdata->last_offset &= ~PAGE_MASK;
       } else {
           bdata->last_pos = start + areasize - 1;
           bdata->last_offset = size & ~PAGE_MASK;
           ret = phys_to_virt(start * PAGE_SIZE +
                                         bdata->node_boot_start);
          }
 
如果因为某些条件未满足而导致不能进行合并，则执行这段代码，我们刚刚把last_pos 和last_offset直接设置为新的值，而未考虑它们原先的值。last_pos的值还要加上所请求的页面数，而新page_offset值的计算就是屏蔽掉除了获得页偏移量位的所有位，即“size &  PAGE_MASK”， PAGE_MASK 为 0x00000FFF，用PAGE_MASK的求反正好得到页的偏移量。
 
             /*
              * Reserve the area now:
              */
      
              for (i = start; i < start+areasize; i++)
                         if (test_and_set_bit(i, bdata->node_bootmem_map))
                             BUG();
              memset(ret, 0, size);
              return ret;
 
现在，我们有了内存，就需要保留它。宏test_and_set_bit()用来测试并置位，如果某位原先的值为0，则它返回0，如果为1，则返回1。还有一个条件判断语句，进行条件判断（这种条件出现的可能性非常小，除非RAM坏）。然后，把这块内存初始化为0，并返回给调用它的函数。
 
5. free_all_bootmem()函数
  这个函数用来在引导时释放页面，并清除bootmem分配器。
   函数原型为：
       void free_all_bootmem (void);
       void free_all_bootmem_core(pg_data_t *pgdat);
 
同前面的函数调用形式类似，free_all_bootmem（）为封装函数，实际调用free_all_bootmem_core（）函数。下面，我们对free_all_bootmem_core（）函数分片断来介绍：
 
              struct page *page = pgdat->node_mem_map;
              bootmem_data_t *bdata = pgdat->bdata;
              unsigned long i, count, total = 0;
              unsigned long idx;
      
              if (!bdata->node_bootmem_map) BUG();
              count = 0;
              idx = bdata->node_low_pfn - (bdata->node_boot_start
                                                 >> PAGE_SHIFT);
   把idx初始化为从内核映象结束处到内存顶点处的页面数。
 
       for (i = 0; i < idx; i++, page++) {
           if (!test_bit(i, bdata->node_bootmem_map)) {
               count++;
               ClearPageReserved(page);
               set_page_count(page, 1);
               __free_page(page);
           }
       }
 
搜索bootmem位图，找到空闲页，并把mem_map中对应的项标记为空闲。set_page_count()函数把page结构的count域置1，而__free_page()真正的释放页面，并修改伙伴（buddy）系统的位图。
 
              total += count;
      
              /*
              * Now free the allocator bitmap itself, it's not
              * needed anymore:
              */
              page = virt_to_page(bdata->node_bootmem_map);
              count = 0;
              for (i = 0; i < ((bdata->node_low_pfn-(bdata->node_boot_start
                           >> PAGE_SHIFT))/8 + PAGE_SIZE-1)/PAGE_SIZE;
                                                         i++,page++) {
                         count++;
                         ClearPageReserved(page);
                         set_page_count(page, 1);
                   __free_page(page);
              }
 
   获得bootmem位图的地址， 并释放它所在的页面。   
 
              total += count;
              bdata->node_bootmem_map = NULL;
              return total;
 
       把该存储节点的bootmem_map域置为NULL，并返回空闲页面的总数。
 
***** mm_init()
start_kernel()
   mm_init()
      page_cgroup_init_flatmem();
      mem_init();
      kmem_cache_init();
      pgtable_cache_init();
      vmalloc_init();


**** page_address_pool  page_address_maps  和高端内存有关
ARRAY_SIZE获得数组的元素个数，这里肯定就是LAST_PKMAP了，由于我们没有启动PAE，这个值等于1024，也就是说page_address_maps共有1024个元素。随后415行，1024个循环以后，page_address_pool通过每个page_address_maps的元素的list字段将他们全部链接起来形成个双向循环链表，又page_address_pool作为head。
**** mem_map
mem_map 的定义：
在mm/memory.c中：
#ifndef CONFIG_NEED_MULTIPLE_NODES
/* use the per-pgdat data instead for discontigmem - mbligh */
unsigned long max_mapnr;
struct page *mem_map;
EXPORT_SYMBOL(max_mapnr);
EXPORT_SYMBOL(mem_map);
#endif
mem_map的赋值：
arch\mips\kernel\Setup.c\arch_mem_init
arch\mips\mm\Init.c\paging_init
mm\Page_alloc.c\free_area_init_nodes
mm\Page_alloc.c\free_area_init_node
mm\Page_alloc.c\alloc_node_mem_map
                          !---------> mem_map = NODE_DATA(0)->node_mem_map;

转：初始化mem_map

http://blog.chinaunix.net/space.php?uid=15724196&do=blog&id=128138

mem_map是一个struct page的数组，管理着系统中所有的物理内存页面。在系统启动的过程中，创建和分配mem_map的内存区域。UMA体系结构中，free_area_init()函数在系统唯一的struct node对象contig_page_data中node_mem_map成员赋值给全局的mem_map变量。调用的关系图：
paging_init()
    !
    !----->  free_area_init() ----> free_area_init_core()----->setup_usemap -----> alloc_bootmem_node()
    !                                 ^                   !
    !                                 !                   -------> set_page_zone() -----> set_page_address()
    !---->   free_area_init_node() ----                   !
                                                          -------> build_zonelists()

free_area_init_node  --->   alloc_node_mem_map  --->  alloc_bootmem_node()

主要的核心函数free_area_init_core(),为node的初始化过程分配本地的lmem_map（node->node_mem_map)。数组的内存在boot memory 分配的alloc_bootmem_node()函数分配.在UMA体系结构中，这个新分配的lmem_map成为全局的mem_map. 对于NUMA体系，lmem_map赋值给每一个node的node_mem_map成员，而这个情况下mem_map就被简单的赋值为PAGE_OFFSET(有兴趣理解NUMA体系结构的可以阅读英文原版，了解更多信息）。UMA体系中，node中的各个zone的zone_mem_map就指向mem_map中的某些元素作为zone所管理的第一个page的地址。

系统中的每个物理页面用struct page数据结构对象来表示，并且跟踪page使用的状态：（省略了一些特定平台用到的成员）

struct page {
        unsigned long flags;          
        atomic_t _count;
        union {
                atomic_t _mapcount; 
                unsigned int inuse; 
        };
        union {
            struct {
                unsigned long private;
                struct address_space *mapping;
            };
            struct kmem_cache *slab;    /* SLUB: Pointer to slab */
            struct page *first_page;    /* Compound tail pages */
        };
        union {
                pgoff_t index;          /* Our offset within mapping. */
                void *freelist;         /* SLUB: freelist req. slab lock */
        };
        struct list_head lru;       

#if defined(WANT_PAGE_VIRTUAL) 
        void *virtual;
#endif         
};
union {
                atomic_t _mapcount; 
                unsigned int inuse; 
        }： 和页表转换有关的PTE链，下面章节将描述。

index：这个成员根据page的使用的目的有2种可能的含义。第一种情况：如果page是file mapping的一部分，它指明在文件中的偏移。如果page是交换缓存，则它指明在address_space所声明的对象:swapper_space（交换地址空间）中的偏移。第二种情况：如果这个page是一个特殊的进程将要释放的一个page块，则这是一个将要释放的page块的序列值，这个值在__free_page_ok()函数中设置。

mapping: 当文件或设备需要内存映射，文件或设备的inode对象有一个address_space类型的成员。如果page属于这个文件或设备，mapping将指向inode中这个成员。如果page不属于任何文件或设备，但是 mapping被设置了，则mapping指向了一个address_space类型的swapper_space对象，则page用于管理交换地址空间(swap address space)了。

lru: page交换调度策略使用。page可能被调度到active_list或者inactive_list队列里。就是使用lru这个list_head。

private：这个保存了一些和mapping（文件mapping到内存）有关的一些特定的信息。如果page是一个buffer page,则它就保存了一个指向buffer_head的指针。

virtual： 不再用于将high memory的映射到ZONE_NORMAL区域的作用了，除了一些其他的体系结构会用到外。

count: page的访问计数，当为0是，说明page是空闲的，当大于0的时候，说明page被一个或多个进程真正使用或者kernel用于在等待I/O。

flags:  page状态的标志信息。kernel代码里定义了大量的宏用于设置，清楚，检测flag成员中的各个位所表示的page状态信息。特别提示一下，SetPageUptodate(),它需要调用一个和体系结构有关的函数：arch_set_page_uptodate().

**** 映射页面到ZONE
映射页面到zone（Mapping page to zones）
在2.4.18内核之前，struct page数据结构中有一个zone的成员，后来证明这样做会无谓的浪费大量的内存空间，因为系统中会有大量的page对象，所以以后版本的page中不在有这样的成员了，而是有一个索引表示，这个索引保存在flag成员中的某些位段中，这个索引占用8个位。2.6.19版本的kernel系统中建立了一个全局的zone数组：

struct zone *zone_table[1 << ZONETABLE_SHIFT] __read_mostly;
EXPORT_SYMBOL(zone_table);
EXPORT_SYMBOL宏的作用，是让zone_table能够被其他载入的模块使用。free_area_init_core()函数对node里的所有page做初始化。
zone_table[nid * MAX_NR_ZONES + j] = zone; //对zone_table做初始化。
nid是node ID。 j是zone的索引。
对每个page调用set_page_zone()初始化page中的zone的索引值（在page->flag中）。
set_page_zone(page, nid * MAX_NR_ZONES + j);
 
但是2.6.20后就不用这一套了，mm/sparse.c文件中做了一套管理系统。新的方法将多个page组成section来管理。 

这里略微描述一下，有兴趣的，可以详细阅读sparse.c的源代码。kernel将所有的page分成多个section管理，对于x86平台，有64个section，每个section管理着(1<<26)个或(1<<30)个（对于支持PAE的情况下）内存区域。

以下是几个主要的define：

include/asm-x86/sparsemem_32.h:

#ifdef CONFIG_X86_PAE
#define SECTION_SIZE_BITS       30
#define MAX_PHYSADDR_BITS       36
#define MAX_PHYSMEM_BITS        36
#else
#define SECTION_SIZE_BITS       26
#define MAX_PHYSADDR_BITS       32
#define MAX_PHYSMEM_BITS        32
#endifinclude/linux/mmzone.h:#define SECTIONS_SHIFT          (MAX_PHYSMEM_BITS - SECTION_SIZE_BITS)#define NR_MEM_SECTIONS         (1UL << SECTIONS_SHIFT)#ifdef CONFIG_SPARSEMEM_EXTREME
#define SECTIONS_PER_ROOT       (PAGE_SIZE / sizeof (struct mem_section))
#else
#define SECTIONS_PER_ROOT       1
#endif#define SECTION_NR_TO_ROOT(sec) ((sec) / SECTIONS_PER_ROOT)
#define NR_SECTION_ROOTS        (NR_MEM_SECTIONS / SECTIONS_PER_ROOT)
#define SECTION_ROOT_MASK       (SECTIONS_PER_ROOT - 1)

首先声明了一个全局的mem_section的全局数组。
struct mem_section *mem_section[NR_SECTION_ROOTS]；

调用sparse_add_one_section()函数，分配mem_section，并且初始化。

**** 页框计算
内核用数据结构page描述一个页框的状态信息，所有的页描述符存放在全局mem_map数组中，其数组的下标为页框号（pfn）。因为每个描述符长度为32字节，所以mem_map所需要的空间略小于整个RAM的1%。

 

那么一个页描述符怎样与一个占据4k的页框相联系（映射）呢？有了mem_map数组，这个问题就很简单了。因为如果知道了page数据的地址pd，用pd去减去mem_map就得到了pd的页框号pfn。那么这个物理页的物理地址是physAddr = pfn << PAGE_SHIFT  。


在得知该物理页的物理地址是physAddr后，就可以视physAddr的大小得到它的虚拟地址：
1.physAddr < 896M  对应虚拟地址是 physAddr + PAGE_OFFSET   (PAGE_OFFSET=3G)
2.physAddr >= 896M 对应虚拟地址不是静态映射的，通过内核的高端虚拟地址映射得到一个虚拟地址。

 

在得到该页的虚拟地址之后，内核就可以正常访问这个物理页了。

 

内核提供一个virt_to_page(addr)宏来产生线性地址addr对应的页描述符地址。pfn_to_page(pfn)宏产生与页框号pfn对应的页描述符地址。相反，也提供page_to_pfn(pg)宏来产生页描述符对应的页的页框号pfn。注意，针对80x86结构，上述宏并不是直接通过men_map数组来确定页框号的，而是通过内存管理区的zone_mem_map来确定的，不过原理是一样的：

#define page_to_pfn(pg)       /
({         /
 struct page *__page = pg;     /
 struct zone *__zone = page_zone(__page);   /
 (unsigned long)(__page - __zone->zone_mem_map)   /
  + __zone->zone_start_pfn;    /
})

各个arch的page.h中会定义这个宏，mips的page.h中没有定义这个宏，mips使用的是memory_model.h中定义的.

这里千万要注意！不要混淆一个概念。这里的physAddr虽然表示物理地址，但是并不能说明该地址的数据就一定存在于物理内存中。那么如何判断这个页到底在不在内存中呢？你看，前面的知识就用到了——分页机制。也就是说，如果这个页因为各种各样五花八门的原因被交换出去了，那么它对应的页的Present标志就为0。这里就牵涉到缺页异常了，要深入了解，请关注笔者后面的博文。

**** x86的mmu机制和kernel内存管理的结合，页表的建立
内核页表的建立
westroom
 
用户头衔：注册会员
状态：我不在线
楼主
发表于 2004-12-25 12:30:05 |只看该作者 |倒序浏览
看了内核不久，对vm很感兴趣。比较很多的内核书籍，都没有看懂内核是怎么建立内核页表的，其实还有很多问题，比如：每个进程有自己的页表吗？我指相对内核页表而言，即需要另外开辟内存存放吗？书中反覆说内核页表建立的两个步骤，还是不大明白，希望高手们指点哈！ 
另外，能简单的描述一下内核1g空间是怎么分布的更好，因为我是比较糊涂的，很多东西绞在一起，互相矛盾了，真不好意思。
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
沙发
发表于 2004-12-25 22:12:42 |只看该作者 |倒序浏览
看了一段时间VM了，说一说自己的理解，希望高手不要见笑了。 
1。每个进程都有自己的页表的，需要存放在内存中，也可以交换出去，有个PRESENT位来标志是否在内存中。 
2。你所说的两个步骤应该是指内核在初始化期间的吧???我说一下2。2内核页表初始化的两个步骤吧（映射前4M），2。4（映射前8M），2。6都是类似的。 
内核在编译的过程中会静态初始化页目录和页表。页全局目录放在swapper_pa_dir中，页表放在pg0中。在初始化期间，要经历从实模式到保护模式的过渡，也就是说要开启分页功能。内核空间位于3G以上，用户空间在0－－3G。由于最初cpu的IP寄存器中装的是物理地址，而编译得到的内核都是虚拟地址，目标是要内核映象在虚拟内核空间中运行，所以第一阶段首先将内核空间，用户空间（从0开始）都映射到物理地址前4M，可以对这4M寻址，对32位机器采用两级分页，通常页表，页目录分别利用虚拟地址10位来寻址，这样页表可以包含1024项，页目录也是1024项。内核空间的页目录项就是从第768项开始的（PAGE_OFFSET=0xC000 0000，内核空间1G，（1023－768＋1）×1024×4K=1G），内核把页目录的第0项，第768（分别对应用户空间，内核空间第一项）项初始化为pg0的地址，其余项都初始化为0。这就建立了临时的内核页表，也就是第一阶段，arch/i386/kerne/head.s中的startup_32（）函数利用向cr3寄存器写入swapper_pa_dir地址，并设置cr0寄存器的PG标志开启分页，然后以一个符号地址做绝对转移，由于这个符号地址是虚拟地址，于是跳转后就进入虚拟空间运行了，至此第一步完成，进入保护模式，这一阶段主要是为开启分页，进入保护模式；第二步是建立正式的内核页目录。首先把第一项清为了0，取消前4M线性地址和物理地址的映射，因为内核线程在运行的时候不允许通过用户空间虚拟地址访问内存，接着按照BIOS探测的物理内存的大小，建立映射，把整个物理内存都映射到内核地址空间。即内核空间0xC000 0000对应物理地址0。
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
板凳
发表于 2004-12-26 11:32:47 |只看该作者 |倒序浏览
谢谢你得回复，我还有一个问题不明白。既然每个进程都有自己得页表目录，在进程运行得时候，也是使用的这个目录，只是在中断处理的时候，跳转到目录的高（1024-768）条目，也就是映射的内核页表目录的高1G条目执行，那内核页表目录的前768项是用来做什么的呢？映射物理内存？不懂
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
4 楼
发表于 2004-12-26 12:04:31 |只看该作者 |倒序浏览
前面的都填充为0，不起作用的，我前面帖子也提到了，内核线程不能通过用户空间的虚拟地址来访问内存，所以前面的用户空间的项都为0。 
分配给每个进程一段线性地址，也只是把页目录项中相应部分初始化，其余项都是0。访问这些项，都会引发异常。
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
5 楼
发表于 2004-12-26 12:23:07 |只看该作者 |倒序浏览
你可以这样理解：内核在0环，普通进程在3环，只要普通进程操作合法，那内核就不能干涉它。也就是说不能在进程合法运行期间，强行通过自己页目录项中用户空间映射的虚拟地址来访问普通进程的空间。只有当发生异常或系统调用，也就是进程被迫或主动要求内核替它干某些事情，这才可以。若进程要求内核访问该进程地址空间的量，也会把这个做为参数传递给系统调用。
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
6 楼
发表于 2004-12-26 15:38:07 |只看该作者 |倒序浏览
我想我没有把我的意思表达清楚哈。我是说内核页表和进程自己的页表到底是什么一个关系？内核页表的低765项一直都是0吗？这些低项到底有什么用，怎么用？说实话，我越来越糊涂了，还麻烦您讲清楚一点哈，谢谢了！
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
7 楼
发表于 2004-12-26 20:10:54 |只看该作者 |倒序浏览
二级分页的话，IA-32把高十位做为页目录索引，中间10位是页表索引，最后12位是OFFSET；那么内核页目录的前768项相当于占位作用，一直是0。比如我找页目录中第800项，那么首先从CR3寄存器找到页目录所在地址，然后找索引为800的项；这些低项就是占着个位置，否则因为是0就删除这些低项的话就无法按照高10位索引找到正确的项。 
每个进程都有自己的页目录，页表，即自己的地址空间；也可能进程之间某个页表相同，这意味着共享这块地址区域。 
系统运行在内核态，那么需要对内核空间寻址，那么就利用内核页目录，页表寻址；但是对于需要访问某进程地址空间的情况（比如发生系统调用，给该系统调用传递了一个进程地址空间的参数），那么处于内核态的例程就可以访问该进程地址空间的页目录，页表，从而实现寻址。 
但是进程不可以访问内核地址空间,比如如果发生系统调用，给该系统调用传递了一个进程地址空间的参数，而这个参数是在PAGE_OFFSET以上的，那就会引发异常。只有给内核传递PAGE_OFFSET以下的地址参数才合法。 
应该说清楚了吧：内核寻址内核空间的时候（>=PAGE_OFFSET），那肯定要用内核页目录，页表了；需要寻址进程地址空间（<PAGE_OFFSET），就利用进程页目录，页表。处于用户地址空间的进程是无权直接访问内核空间的，也就无法使用内核页表了。只有通过系统调用，进入内核态执行，这时候才可以访问内核页表。
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
phyma
 
用户头衔：注册会员
状态：我不在线
8 楼
发表于 2004-12-27 10:22:10 |只看该作者 |倒序浏览
谢谢threeseconds精彩详尽的回复，精华
格式塔
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
9 楼
发表于 2004-12-27 10:46:50 |只看该作者 |倒序浏览
感谢大侠的回帖，我明白了，原来内核也表的低768项没有使用，一直是0，只是起了一个占位检验正确与否的作用，可以这样理解吧，再次感谢哈！
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
10 楼
发表于 2004-12-27 13:53:53 |只看该作者 |倒序浏览
to westroom: 
对，是这样。 
CPU在用虚拟地址的高10位当作索引来查找页目录项时，是从页目录第一项开始，这10位索引当作相对于第一项的偏移，所以不能因为前面项是0就删除他们，他们需要占着位置，以便可以查找到正确的项； 
另外，还有一点就是，内核线程是比较特殊的，它只可以在内核空间执行，不会由于调度发生上下文切换到用户空间，由于内核线程也要使用内核页目录，页表，因此把前面项设置为0，当内核线程利用前面项来访问内存的时候，就会引发异常从而发现错误。 

我也是菜鸟，有问题大家可以一起讨论，有错误也要请大家指出：） 
另外还要多谢版大抬举啊！！！！
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
11 楼
发表于 2004-12-27 17:15:17 |只看该作者 |倒序浏览
那么内核页表的作用其实就是让内核线程能找到想要的东西了，那么干嘛映射真个物理内存到内核空间，使得有一个896M的物理内存大小限制？这个有什么用？ 
另外，__pa(addr)不是用来完成线性地址转无理地址吗（只针对内核而言），内核线程干嘛不直接把addr通过pa（）转化为无理地址，用内核页表干嘛？ 
我也觉得我问题真多，自己也在拼命找答案，只是threeseconds太厚道了，止不住要问个明白了，版主见谅哈！
顶顶0
踩踩0
phyma
 
用户头衔：注册会员
状态：我不在线
12 楼
发表于 2004-12-27 19:56:25 |只看该作者 |倒序浏览
引用:

westroom 说:
那么内核页表的作用其实就是让内核线程能找到想要的东西了，那么干嘛映射真个物理内存到内核空间，使得有一个896M的物理内存大小限制？这个有什么用？ 
另外，__pa(addr)不是用来完成线性地址转无理地址吗（只针对内核而言），内核线程干嘛不直接把addr通过pa（）转化为无理地址，用内核页表干嘛？ 
我也觉得我问题真多，自己也在拼命找答案，只是threeseconds太厚道了，止不住要问个明白了，版主见谅哈！



1.页面表、页表是硬件机制，一旦进入保护模式，cr0的PE位 置位之后就开始启动。硬件是软件的老大，这无论对ring0（内核）还是ring3（用户）的代码都是一样的，引用的地址都会经过分段和分页机制（硬件）的转化。__pa的作用只是在内核需要物理地址的时候才会用到，比如填入cr3中内容是页面表的物理地址，而就需要用它来转化。 

2.很佩服threeseconds的厚道和对i386 MM的详细知识。
格式塔
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
13 楼
发表于 2004-12-28 09:19:12 |只看该作者 |倒序浏览
内核肯定要求可以对整个物理内存进行寻址，以便从全局来掌握整个物理内存的管理，因此映射整个物理内存（如果可能的话）给它，让它当仲裁者；至于896M严格来说也不能说是限制，因为32位地址空间留给内核映射物理内存的只有1G，还要留下128M用于其它映射，这就出现了896M这个分界；大于896小于4G的内存就要进行动态映射，映射到后128M,前面896正常映射；大于4G就要开启PAE，启动三级分页了；当然，对于64位机器，就没有这些麻烦事了，2^64地址空间，够它臭屁一阵子的了：） 
对于__pa版大说的对，实际内核应用__pa挺有限的；你想硬件要寻找页目录，必然要有一个物理地址，而保护方式下开启了分页，在程序运行中都是采用虚拟地址，那么要对内存寻址的话，必然要经历从逻辑地址到线性地址再到物理地址的过程，只不过LINUX简化了段的用法，让段都从虚拟地址0开始，这样逻辑地址偏移就等于线性地址了；但是对于页全局目录，页表来说，他们放在内存里面，你首先要找页全局目录，找不到就没法利用分页。如果你不给定物理地址，你怎么能找到它呢？也就是说你总要给硬件一个起点，不能说我给硬件一个虚拟地址，硬件去找页目录吧，可是要找页目录，硬件也得知道它的物理地址在哪啊，这样就用到__pa了，把物理地址装入CR3，以后就都是硬件自己完成的了；还是要结合硬件来理解，版大说得对，硬件是基础。 

呵呵，我其实也不是厚道，因为我看书想问题不多，就闷头看；这里看看大家的问题就发现很多事情都没有想过，所以可以让我也沾光能跟着大伙想想问题：） 
版大可不要夸我了，我也是菜鸟，理解错误的地方还需要老大指出啊！！！
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
14 楼
发表于 2004-12-28 10:31:52 |只看该作者 |倒序浏览
二位都如此谦虚，小生真觉不如！ 
讲解的不错，原来pa多用于硬件需要直接访问物理内存的情况，而段式，页式是所有程序都必须走的过程哈。而内核对全部物理内存的映射是为了对系统的一个整体掌握（掌握什么呢？）。 
剩下的事情就需要我去看看书，再消化一下二位传授的知识了。：）
知者不言<br /> 言者不知
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
15 楼
发表于 2004-12-28 11:20:15 |只看该作者 |倒序浏览
掌握如何合理分配动态内存（分配给内核本身固定占有的内存以外的内存）给那些请求的进程函数啊：）
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0

发表于 2004-12-28 18:17:58 |只看该作者 |倒序浏览
引用:

threeseconds 说:
二级分页的话，IA-32把高十位做为页目录索引，中间10位是页表索引，最后12位是OFFSET；那么内核页目录的前768项相当于占位作用，一直是0。比如我找页目录中第800项，那么首先从CR3寄存器找到页目录所在地址，然后找索引为800的项；这些低项就是占着个位置，否则因为是0就删除这些低项的话就无法按照高10位索引找到正确的项。 
每个进程都有自己的页目录，页表，即自己的地址空间；也可能进程之间某个页表相同，这意味着共享这块地址区域。 
系统运行在内核态，那么需要对内核空间寻址，那么就利用内核页目录，页表寻址；但是对于需要 
~~~~~~~~ 
访问某进程地址空间的情况（比如发生系统调用，给该系统调用传递了一个进程地址空间的参 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
数），那么处于内核态的例程就可以访问该进程地址空间的页目录，页表，从而实现寻址。 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
但是进程不可以访问内核地址空间,比如如果发生系统调用，给该系统调用传递了一个进程地址空间的参数，而这个参数是在PAGE_OFFSET以上的，那就会引发异常。只有给内核传递PAGE_OFFSET以下的地址参数才合法。 
应该说清楚了吧：内核寻址内核空间的时候（>=PAGE_OFFSET），那肯定要用内核页目录，页表了；需要寻址进程地址空间（<PAGE_OFFSET），就利用进程页目录，页表。处于用户地址空间的进程是无权直接访问内核空间的，也就无法使用内核页表了。只有通过系统调用，进入内核态执行，这时候才可以访问内核页表。

对于楼上所说的这个我有点不明白，在进行系统调用的时侯难道不会把内核的页目录地址放到cr3寄存器里吗？如果把内核的页目录地址放到cr3寄存器里的话，那内核不就不能访问了用户空间了？可是如果不这样子做的话，那进行系统调用的时候怎么访问到内核空间？
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
17 楼
发表于 2004-12-29 11:24:11 |只看该作者 |倒序浏览
每个进程都是拥有4G地址空间，只是用户态下面无法访问高1G空间；内核空间是被所有进程共享的，那么该进程的页目录表的高项部分就应该是内核页表的内容，只是USER/SUPERVISOR位是0，用户态无法访问而已；CR3寄存器就是该进程的页目录地址，进程从用户态切换到内核态，CR3没变，但是却拥有可以访问高项的内核空间的权限了，这样发生系统调用的时候，内核也直接访问当前进程的用户空间，使用的虚拟地址也和当前进程处于用户空间时候使用的虚拟地址是一样的。 
下面这段代码是get_pgd_slow(pgd_alloc调用)中的： 
memcpy(pgd + USER_PTRS_PER_PGD, 
swapper_pg_dir + USER_PTRS_PER_PGD, 
(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t)); 
pgd_alloc可以为新进程建立一个页全局目录，swapper_pg_dir是内核页全局目录地址，USER_PTRS_PER_PGD是页全局目录中用户空间所占的表项数目，这里应该可以看到把内核页目录复制到进程的页目录的高项部分了。 
由此看进程应该是不会直接使用内核页表，都是用的复制品。 

前面说得概念有点混淆，而且我的理解也很片面，还请兄弟继续指正。
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
icoming
 
用户头衔：注册会员
状态：我不在线
18 楼
发表于 2004-12-29 13:18:17 |只看该作者 |倒序浏览
太佩服了 
能搞得那么清楚，我现在在看内存管理，看的稀里糊涂的 
问题一大堆，而且很多东西根本窜不起来
顶顶0
踩踩0
threeseconds
 
用户头衔：注册会员
状态：我不在线
19 楼
发表于 2004-12-29 14:51:40 |只看该作者 |倒序浏览
很多地方我说得也不准确，我也是看了一些皮毛就到这里来瞎说一通，希望有不对的地方大家指正，有问题大家也一起讨论讨论！！ 
我觉得一个人单干还是有点难度，有时候几个人一起，有问题大家一起考虑，讨论，比较有气氛，进步的也会比较快：）
For memory <br /> --14194--5.0<br /> Vanity___Definitely my favourite sin!<br /> ---Al Pacino
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
20 楼
发表于 2004-12-30 11:18:28 |只看该作者 |倒序浏览
很想弄明白在用户程序中，突然执行到一句系统调用的时候，为什么就可以访问页表目录的高项了呢？是不是在段式映射那里进行的这种转换，我想了想页映射没有这种控制吧？
知者不言<br /> 言者不知
顶顶0
踩踩0
phyma
 
用户头衔：注册会员
状态：我不在线
21 楼
发表于 2004-12-30 16:07:52 |只看该作者 |倒序浏览
引用:

westroom 说:
很想弄明白在用户程序中，突然执行到一句系统调用的时候，为什么就可以访问页表目录的高项了呢？是不是在段式映射那里进行的这种转换，我想了想页映射没有这种控制吧？


"突然执行到一句系统调用" 

系统调用是在用户态设置好调用参数后，执行指令 int $0x80，进入内核事先设置好的0x80号中断的中断处理程序。这里利用了i386的陷阱硬件机制，实现运行级别从ring3到ring0的提升。
格式塔
顶顶0
踩踩0
westroom
 
用户头衔：注册会员
状态：我不在线
22 楼
发表于 2004-12-31 09:15:37 |只看该作者 |倒序浏览
然后呢？是什么机制允许它使用页表高项的？
知者不言<br /> 言者不知
顶顶0
踩踩0
phyma
 
用户头衔：注册会员
状态：我不在线
23 楼
发表于 2004-12-31 12:28:19 |只看该作者 |倒序浏览
引用:

westroom 说:
然后呢？是什么机制允许它使用页表高项的？

IDTR指向的中断描述表中的第0x80项（对应于中断0x80），中间内核会设置一个中断处理地址的cs：eip，cs即为内核的代码段。当前特权级就变成了cs的【2：1】位00。于是就进入了ring 0。 

这只是个大略的描述。i386保护模式的中断项其实还有很多的格式（中断，陷阱……）以及相应的跳转策略和权限检查。
格式塔
顶顶0
踩踩0
baijingtao
 
用户头衔：注册会员
状态：我不在线
24 楼
发表于 2005-01-12 14:09:40 |只看该作者 |倒序浏览
引用:

threeseconds 说:
每个进程都是拥有4G地址空间，只是用户态下面无法访问高1G空间；内核空间是被所有进程共享的，那么该进程的页目录表的高项部分就应该是内核页表的内容，只是USER/SUPERVISOR位是0，用户态无法访问而已；CR3寄存器就是该进程的页目录地址，进程从用户态切换到内核态，CR3没变，但是却拥有可以访问高项的内核空间的权限了，这样发生系统调用的时候，内核也直接访问当前进程的用户空间，使用的虚拟地址也和当前进程处于用户空间时候使用的虚拟地址是一样的。 
下面这段代码是get_pgd_slow(pgd_alloc调用)中的： 
memcpy(pgd + USER_PTRS_PER_PGD, 
swapper_pg_dir + USER_PTRS_PER_PGD, 
(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t)); 
pgd_alloc可以为新进程建立一个页全局目录，swapper_pg_dir是内核页全局目录地址，USER_PTRS_PER_PGD是页全局目录中用户空间所占的表项数目，这里应该可以看到把内核页目录复制到进程的页目录的高项部分了。 
由此看进程应该是不会直接使用内核页表，都是用的复制品。 



如果在系统运行的过程中有ioremap类似的函数被驱动程序调用.内核的虚存空间会被扩展.新扩展的部分是怎样和其它进程的3G以上的地址空间的映射同步的?

**** 网上一篇不错的关于kernel内存管理的文章
1. 内核初始化：

    * 内核建立好内核页目录页表数据库，假设物理内存大小为len，则建立了[3G--3G+len]::[0--len]这样的虚地址vaddr和物理地址paddr的线性对应关系；
    * 内核建立一个page数组，page数组和物理页面系列完全是线性对应，page用来管理该物理页面状态，每个物理页面的虚地址保存在page->virtual中；
    * 内核建立好一个free_list，将没有使用的物理页面对应的page放入其中，已经使用的就不用放入了；

2. 内核模块申请内存vaddr = get_free_pages(mask,order)：

    * 内存管理模块从free_list找到一个page，将page->virtual作为返回值，该返回值就是对应物理页面的虚地址；
    * 将page从free_list中脱离；
    * 模块使用该虚拟地址操作对应的物理内存；

3. 内核模块使用vaddr，例如执行指令mov(eax, vaddr)：

    * CPU获得vaddr这个虚地址，利用建立好的页目录页表数据库，找到其对应的物理内存地址；
    * 将eax的内容写入vaddr对应的物理内存地址内；

4. 内核模块释放内存free_pages(vaddr,order)：

    * 依据vaddr找到对应的page；
    * 将该page加入到free_list中；

5. 用户进程申请内存vaddr = malloc(size)：

    * 内存管理模块从用户进程内存空间(0--3G)中找到一块还没使用的空间vm_area_struct(start--end)；
    * 随后将其插入到task->mm->mmap链表中；

6. 用户进程写入vaddr(0-3G)，例如执行指令mov(eax, vaddr)：

    * CPU获得vaddr这个虚地址，该虚地址应该已经由glibc库设置好了，一定在3G一下的某个区域，根据CR3寄存器指向的current->pgd查当前进程的页目录页表数据库，发现该vaddr对应的页目录表项为0，故产生异常；
    * 在异常处理中，发现该vaddr对应的vm_area_struct已经存在，为vaddr对应的页目录表项分配一个页表；
    * 随后从free_list找到一个page，将该page对应的物理页面物理首地址赋给vaddr对应的页表表项，很明显，此时的vaddr和paddr不是线性对应关系了；
    * 将page从free_list中脱离；
    * 异常处理返回；
    * CPU重新执行刚刚发生异常的指令mov(eax, vaddr)；
    * CPU获得vaddr这个虚地址，根据CR3寄存器指向的current->pgd，利用建立好的页目录页表数据库，找到其对应的物理内存地址；
    * 将eax的内容写入vaddr对应的物理内存地址内；  

7. 用户进程释放内存vaddr，free(vaddr)：

    * 找到该vaddr所在的vm_area_struct；
    * 找到vm_area_struct:start--end对应的所有页目录页表项，清空对应的所有页表项；
    * 释放这些页表项指向物理页面所对应的page，并将这些page加入到free_list队列中；
    * 有必要还会清空一些页目录表项，并释放这些页目录表项指向的页表；
    * 从task->mm->mmap链中删除该vm_area_struct并释放掉；

综合说明：

    * 可用物理内存就是free_list中各page对应的物理内存；
    * 页目录页表数据库的主要目的是为CPU访问物理内存时转换vaddr-->paddr使用，分配以及释放内存时不会用到，但是需要内核内存管理系统在合适时机为CPU建立好该库；
    * 对于用户进程在6中获得的物理页面，有两个页表项对应，一个就是内核页目录页表数据库的某个pte[i ]，一个就是当前进程内核页目录页表数据库的某个 pte[j]，但是只有一个page和其对应。如果此时调度到其他进程，其他进程申请并访问某个内存，则不会涉及到该物理页面，因为其分配时首先要从 free_list中找一个page，而该物理页面对应的page已经从free_list中脱离出来了，因此不存在该物理页面被其他进程改写操作的情况。内核中通过get_free_pages等方式获取内存时，也不会涉及到该物理页面，原理同前所述。

**** 网上一幅很不错的原理图
[[./pic/20130921_kernel_mm_principle.gif]]

**** 内核非连续内存管理和page table操作
内核中非连续的内存是通过vmalloc和vfree来进行管理的
从前面章节的图中可以看出线性地址PAGE_OFFSET至ZONE_HIGHMEM(PAGE_OFFSET+896M)之间是内核中连续线性映射地址空间，即代码段、数据段和kmalloc区域
高于ZONE_HIGHMEM起始处（896M）则是非连续映射区域，当然还包括“"永久内核映射"区(应该就是页表区域)
          high_memory                                                          FIXADDR_START
PAGE_OFFSET   !  VMALLOC_START                          VMALLOC_END   PKMAP_BASE   !   
    !         !    !                                             !    !            !
   \/        \/   \/                                            \/   \/           \/
   ! Physical !    ! vmalloc !    ! vmalloc !    !     ! vmalloc !    ! Persistent ! Fix-mapped |
   ! memory   ! 8M ! area    ! 4k ! area    ! 4k ! ... ! area    ! 8k ! kernel     ! linear     |
   ! mapping  !    !         !	  !         !    !     !         !    ! mappings   ! address    |

内核中vm_struct结构体就是对应上图中的一个vmalloc area
get_vm_area 就是获取一个vmalloc area
调用一次vmalloc其实就是递归函数，通过vmalloc反复递归，vmalloc通过get_vm_area()获取vmalloc area，通过kmalloc和alloc_page来申请线性映射的物理页，然后再调用map_vm_area()函数来对这个vmalloc area进行页表更新。
也就是说vmalloc中将获取到的vmalloc area和物理地址联系起来的函数是map_vm_area()

**** page_table
arch/arm/include/asm/pgtable.h:   the macro/function calc pte/pmt
*** 中断
中断可以从plat_irq_dispatch()这个函数入口，
然后是do_IRQ（）
如果关注软中断，则在irq_exit()中invoke_softirq()
哪里更新系统的时间呢？

request_irq()可以在irq线上增加action，set_irq_handler()可以为irq线设置irq_handler，比如为irq线设置handle_level_irq()或者edge等。
irq处理分成两层，第一层，系统会先调用irq线的irq_handler，这个函数用来处理一些芯片相关的东西，然后再依次调用该irq线上面的action函数。
irq_handler是基于irq线的，action是基于设备的。

**** mips
mips中，中断的总入口在genex.S文件的handle_int
也就是NESTED(handle_int, PT_SIZE, sp)
这段汇编先将返回的地址设置为ret_from_irq，然后再调用plat_irq_dispatch
PTR_LA   ra, ret_from_irq
j        plat_irq_dispatch

而异常的处理流程应该是类似
.macro__BUILD_HANDLER exception handler clear verbose ext
只是返回地址是ret_from_exception
PTR_LA     ra, ret_from_exception
j          do_\handler





*** 系统调用
**** mips
traps.c ----> set_except_vector(8, handle_sys);  // 设置系统调用的入口
scall64-o32.S --- > NESTED(handle_sys, PT_SIZE, sp)  
scall64-n32.S   ---->  NESTED(handle_sysn32, PT_SIZE, sp)
                -----> n32_syscall_trace_entry  --->do_syscall_trace
entry.S       ----->  syscall_exit  ----> resume_userspace

关于系统调用的表在哪里呢？
在这里scall64-o32.S 中的 sys_call_table

     


** 驱动学习
*** MII总线
**** GMII RMII MII SGMII XGMII对比
MII即媒体独立接口，也叫介质无关接口。它是IEEE-802.3定义的以太网行业标准。它包括一个数据接口，以及一个MAC和PHY之间的管理接口(图1)。数据接口包括分别用于发送器和接收器的两条独立信道。每条信道都有自己的数据、时钟和控制信号。MII数据接口总共需16个信号。管理接口是个双信号接口：一个是时钟信号，另一个是数据信号。通过管理接口，上层能监视和控制PHY。
MII标准接口 用于连快Fast Ethernet MAC-block与PHY。“介质无关”表明在不对MAC硬件重新设计或替换的情况下，任何类型的PHY设备都可以正常工作。在其他速率下工作的与 MII等效的接口有：AUI（10M　以太网）、GMII（Gigabit　以太网）和XAUI（10-Gigabit　以太网）。

GMII是8bit并行同步收发接口，采用8位接口数据，工作时钟125MHz，因此传输速率可达1000Mbps。同时兼容MII所规定的10/100 Mbps工作方式。
GMII接口数据结构符合IEEE以太网标准。该接口定义见IEEE 802.3-2000。

RMII:       Reduced Media Independant Interface
简化媒体独立接口 
是标准的以太网接口之一，比MII有更少的I/O传输。
关于RMII口和MII口的问题
RMII口是用两根线来传输数据的，
MII口是用4根线来传输数据的，
GMII是用8根线来传输数据的。
GMII和RMII都是并行传输并需要随路时钟。

MII/RMII只是一种接口，对于10M线速,MII的速率是2.5M，RMII则是5M；对于100M线速，MII的速率是25M，RMII则是50M。

802.1q(VLAN)。
以太网帧的格式为：前导符+开始位+目的mac地址+源mac地址+类型/长度+数据+padding(optional)+32bitCRC
如果有vlan，则要在类型/长度后面加上2个字节的vlan tag，其中12bit来表示vlan id，另外4bit表示数据的优先级!
SGMII--Serial Gigabit Media Independent Interface
SGMII是PHY与MAC之间的接口，类似与GMII和RGMII，只不过GMII和RGMII都是并行的，而且需要随路时钟，PCB布线相对麻烦，而且不适应背板应用。而SGMII是串行的，不需要提供另外的时钟，MAC和PHY都需要CDR去恢复时钟。另外SGMII是有8B/10b编码的，速率是1.25G
XGMII
XGMII--10 Gigabit Media Independent Interface 是“10Gb独立于媒体的接口”，X对应罗马数字10

*** 网口驱动
**** 添加网口驱动
Linux 2.6.35内核配置和网卡驱动添加
【环境】
1：Ubuntu 10.10
2：u-boot-2010.03
3：linux-2.6.35
4：优龙FS2410
5：交叉编译器:arm-none-linux-gnueabi-gcc version 4.3.2
 
 
1）解压内核
 
tar jxf linux-2.6.35.tar.bz2
 
2）修改顶层Makefile
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$ vim Makefile
 修改191和192行（可以先找到编译器的绝对路径）
ARCH        ?= arm
CROSS_COMPILE   ?= /home/tony/toolchain/bin/arm-none-linux-gnueabi-
 
3）拷贝配置文件 
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$ cp arch/arm/configs/s3c2410_defconfig .config
 
4）配置内核
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$ make menuconfig
查看类型是否为S3C2410
System Type --->
        ARM system type (Samsung S3C2410, S3C2412, S3C2413, ……)  --->
 
用新交叉编译器需选择EABI 
Kernel Features  --->
        [*] Use the ARM EABI to compile the kernel
        [*]   Allow old ABI binariesto run with this kernel (EXPERIMENTAL) (NEW)
 
5）将cs8900.c和cs8900.h两个文件拷贝到linux-2.6.35/drivers/net/arm/下
 
6）修改linux-2.6.35/drivers/net/arm/vim Kconfig，添加cs8900内核配置项
添加
config S3C2410_CS8900
    tristate "CS8900 support"
    depends on NET_ETHERNET && ARM && ARCH_SMDK2410
    ---help---
      support for cs8900 chipset base Ethernet cards, if you have a networkcard of this type.
 
7）修改linux-2.6.35/drivers/net/arm/vim Makefile
添加：obj-$(CONFIG_S3C2410_CS8900) += cs8900.o
 
8）添加地址映射定义
修改文件：linux-2.6.35/arch/arm/mach-s3c2410/include/mach$vim map.h
添加：
/* CS8900a */
#define pSMDK2410_ETH_IO    __phys_to_pfn(0x19000000)
#define vSMDK2410_ETH_IO    0xE0000000
#define SMDK2410_ETH_IRQ    IRQ_EINT9
 
9）添加平台代码
修改文件：linux-2.6.35/arch/arm/mach-s3c2410$vim mach-smdk2410.c
在59行添加一句：
57 static struct map_desc smdk2410_iodesc[]__initdata = {
58   /*nothing here yet */
59     {vSMDK2410_ETH_IO, pSMDK2410_ETH_IO, SZ_1M, MT_DEVICE}
60};
 
10）配置内核，使之支持cs8900网卡 
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$ make menuconfig
Device Drivers  --->
        [*] Network device support  --->
                [*]  Ethernet (10 or 100Mbit)  --->
                        <*>  CS8900 support
 
11）重新编译内核
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$ make zImage
//********************************************************************
//**        备注：如果想生成uImage                                **
//**        cp u-boot-2010.03/tools/mkimge /usr/bin/         **
//********************************************************************
 
12）拷贝zImage到tftpboot目录进行测试
ww.linuxidc.com@linuxidc:~/win/linux-2.6.35$cp arch/arm/boot/zImage /tftpboot
 
13）在开发板设置参数
setenv serverip 192.168.7.103
setenv ipaddr  192.168.7.163
setenv gatewayip 192.168.7.1
setenv ethaddr 08:00:3e:26:0a:5b
setenv bootcmd tftp 30800000 uImage \; bootm
/*** setenv bootcmd tftp 33000000 zImage \; go 33000000 如果用zImage用这个***/
setenv bootargs console=ttySAC0,115200 init=/linuxrc root=/dev/nfs nfsroot=192.168.7.103:/opt/filesystem ip=192.168.7.163
测试前提：已配置好TFTP、NFS服务
注①：/opt/filesystem为自己的已移植好的文件系统目录
注②：serverip为Ubuntu的IP，ipaddr为开发板的IP
 
14）如果想烧写到nand flash，让内核从nand启动，依次设置如下u-boot参数
tftp 33000000 uImage
nand erase 40000 300000
nand write 33000000 40000 300000
setenv bootcmd nand read 33000000 40000 300000 \; bootm 33000000

**** cavium网口驱动
***** 初始化

C:\wangyao\temp\linux-2.6.34.7\linux-2.6.34.7\drivers\staging\octeon 文件中 cvm_oct_init_module()函数,这个函数也是这个模块的初始化函数
for循环所有的interface ；并且嵌套for循环每个interface上面的port
获取interface的个数的方式是cvmx_helper_get_number_of_interfaces()
获取某个interface上面的port的个数的方式是cvmx_helper_ports_on_interface(interface);
在对port的循环中，每个port都会创建一个dev = alloc_etherdev(sizeof(struct octeon_ethernet))
每个port根据imode = cvmx_helper_interface_get_mode(interface); 知道自己所在平面是什么总线类型，如PCIE、XAUI、SGMII、RGMII等，并给dev赋上对应的驱动函数，如：dev->netdev_ops = &cvm_oct_rgmii_netdev_ops、dev->netdev_ops = &cvm_oct_sgmii_netdev_ops、dev->netdev_ops = &cvm_oct_xaui_netdev_ops，相信后面这些驱动函数在收发包的时候肯定会用到的。
并且会注册这个dev, register_netdev(dev)

*** tty
ptyXX  ---> master pty
ttyXX  ---> slave pty
这两种tty设备属于虚拟tty设备，是供telnetd、sshd等服务使用的。

ttyS1 ttyS2  ---> 串口tty设备

console  ---> 和ttyS1很相似，有些地方说是指显示器 （这个还不是很清楚）
vc 的概念还不是很清楚
**** pty
pty驱动写在了pty.c中
关键一点是，每一个pty的session都有两个设备文件，master、slave，分别是ptyXX 和 ttyXX，对应的dev.name是pty , ttyp，（比较奇怪的名字）
master、slave对应的tty_struct对象实例都会有一个link，指向自己的另一半， tty_struct中也有指向driver的指针，driver中有一个other指针，指向自己的另一半
tty_struct的write操作其实是将数据写到了自己的另一半的实例上面。
pty最终都会注册在tty设备中，tty设备的注册可以参考tty_io.c的tty_register_driver()

** 自制linux
*** 用busybox自制linux
1、将一个装过linux的硬盘挂在自己ubuntu系统上，挂在sdb sdb3下面，将sdb3（原来linux的rootfs）对应mount在 /home/busybox ，并将/home/busybox中的内容删光。
2、首先在ubuntu上用网络下载busybox源代码
3、编译busybox，编译busybox的时候需要注意在menuconfig中选择静态链接（build option） ，和安装路径(install option)
然后make ; make install
4、将busybox的所有编译出来的东西copy到/home/busybox目录下，同时创建目录proc dev sbin usr lib var etc sys
5、创建console，tty0 - 4  , 这些设备
mknod -m 600 dev/console c 5 1  
mknod -m 600 dev/null    c 1 3 

6、创建fstab
proc /proc proc defaults 0 0
tmpfs /tmp tmpfs defaults 0 0
none /tmp ramfs defaults 0 0
sysfs /sys sysfs defaults 0 0
mdev /dev ramfs defaults 0 0
7、创建启动脚本inittab
::sysinit:/etc/init.d/rcS
::askfirst:-/bin/sh
tty2::askfirst:-/bin/sh
tty3::askfirst:-/bin/sh
tty4::askfirst:-/bin/sh
tty4::respawn:/sbin/getty 38400 tty5
tty5::respawn:/sbin/getty 38400 tty6
::restart:/sbin/init
::ctrlaltdel:/sbin/reboot
::shutdown:/bin/umount -a -r
::shutdown:/sbin/swapoff -a

8、rcS
#!/bin/sh
mount proc /proc -t proc
mount sysfs /sys -t sysfs
mount dev /dev -t ramfs
PATH=/sbin:/bin:/usr/sbin:/usr/bin
runlevel=S
prevlevel=N
umask 022
export PATH runlevel prevlevel
echo"--------- munt all--------"
echo /sbin/mdev>/proc/sys/kernel/hotplug
mdev -s
mount -o rw,remount /
mkdir /dev/pts
mount devpts /dev/pts -t devpts
echo "*************************"
echo "**********************frank ARM**************"
echo "Kernel version:linux-2.32.2"
echo "Author:frank"
echo "Data:2010,4,19"
echo "***********************"
/bin/hostname -F /etc/sysconfig/HOSTNAME
/sbin/ifconfig lo 127.0.0.1
ifconfig eth0 down
ifconfig eth0 hw ether 12:34:56:78:aa
ifconfig eth0 192.168.1.33 netmask 255.255.255.0 up
route add default gw 192.168.1.1

9、copy ubuntu的passwd shadow group

10、到这一步一个busybox的rootfs硬盘分区就做好了，他在ubuntu系统的sdb3中，
    将这个硬盘挂在一个虚拟机上，让这块硬盘的sdb1中放置一个kernel，
    然后重启虚拟机就可以享受自己的busybox的linux系统了


在进入系统后可以启动telnetd，使用telnetd -l login， 这样这个系统就具备了telnet服务器的基本能力。



FAQ：

1、为什么起来之后没有eth0, ： 因为网络驱动是通过module来加载的，而busybox不会去帮Kernel加载module，所以没有eth0，需要把网络驱动编译到内核中去

2、为什么不能root：因为没有passwd shadow group这些文件

3、为什么根目录没有写权限： 需要在rcS中增加如下命令 mount  -o  rw,remount  

4、为什么不能telnet ： 因为没有/dev/pts  , 需要在rcS中增加
mkdir /dev/pts
mount -t devpts devpts /dev/pts

* Android
** 代码阅读
*** 好的网站
http://blog.csdn.net/myarrow/article
http://www.cnblogs.com/samchen2009/p/3368158.html     (超赞）

*** input
**** 基本概念
1. EventHub
特别是EventHub::getEvents()这个函数，这个函数里面有一个循环，循环poll各个input设备文件，如果读到input设备文件中有事件发送上来，getEvents
就会去read设备文件，把事件(rawEvent)内容读出来。
除了事件这个线索之外，设备的管理也很重要，在EventHub收到Notify这样的Event时就会调用EventHub::openDeviceLocked()来打开设备文件，并且通过ioctl从设备文件里面获取这个设备文件的各种属性，key、abs、rel、sw、led、ff、prop等，并且根据这些属性给这个设备进行分类，是INPUT_DEVICE_CLASS_TOUCH、INPUT_DEVICE_CLASS_CURSOR或INPUT_DEVICE_CLASS_KEYBOARD等。
2. InputReader
EventHub::getEvents函数是由InputReader::loopOnce()调用，调用时将缓冲区InputReader::mEventBuffer传入，这样getEvents()收到的rawEvent都会存放在mEventBuffer中。
loopOnce()调用完EventHub::getEvents()获取了rawEvent后，再调用InputReader::processEventsLocked()
processEventsLocked()是关键的入口，他会调用processEventsForDeviceLocked()对收到的rawEvent进一步处理，
processEventsForDeviceLocked()会根据rawEvent中的deviceID选择device::process进行处理，这些device都是保存在InputReader中的，这些device都是InputDevice对象，不过在创建这些InputDevice的时候赋予了不同的Mapper(这些device是在InputReader::createDeviceLocked、 addDeviceLocked两个函数中创建的，这个函数从EventHub中获取deviceID和设备类别的对应关系，并根据类别为device注入不同的Mapper，如KeyboardInputMapper、CursorInputMapper、SingleTouchInputMapper等)
3. InputDevice
当rawEvent交给InputDevice::process()函数处理的时候，这个函数依次直接将rawEvent交给他下面的mapper->process()处理。
4. SingleTouchInputMapper
一个mapper实际上就是rawEvent的一个加工处理的工具类。主要是将多个rawEvent汇整为一个触摸事件(还不是最终的MotionEvent)
我们就以SingleTouchInputMapper为例，他的process根据rawEvent.code的类型分别记录触碰的x、y坐标、压力等诸多参数，也就是依次触碰需要很多个rawEvent才能描述，然后最后一个rawEvent的code值是sync，这时SingleTouchInputMapper就会将前面收集到的这些参数汇整，并通过基类TouchInputMapper::process进入基类的sync()处理，在sync()中数据被进一步整理，形成NotifyMotionArgs(NotifyArgs)，并通过dispatchTouches()函数进一步传递给dispatchMotion()函数，在这个函数中，通过getListener()->notifyMotion(&args);将这个事件放入InputReader::sp<QueuedInputListener> mQueuedListener中，由InputReader定期对队列进行Flush，这时会调用每个Args的notify()函数，这个函数会把Arg自身传递给InputerReader的Listener也就是InputDispatcher::notifyMotion()，
根据设备的类型DEVICE_MODE_DIRECT、DEVICE_MODE_UNSCALED、DEVICE_MODE_NAVIGATION可能是不同的函数，比如鼠标设备(DEVICE_MODE_POINTER)可能是dispatchPointerUsage来负责传递给InputDispatcher
5. InputDispatcher
notifyMotion::notifyMotion()函数，这个函数还在InputReader线程中完成的，他负责构造Java可以认识的MotionEvent，并调用policy(也就是NativeInputManager)对象的filterInputEvent，来对事件先进行过滤。之后notifyMotion()函数再使用NotifyMotionArgs对象中的数据构建MotionEntry事件放入InputDispatcher::mInboundQueue，并按照条件调用mLooper->wake()，出发looper线程，looper线程的调用关系如下，当looper线程阻塞在pollOnce时，调用mLooper->wake()就可以把线程唤醒。
   InputDispatcherThread::threadLoop->
      mDispatcher->dispatchOnce(InputDispatcher::dispatchOnce)->
          dispatchOnceInnerLocked 和  mLooper->pollOnce
    dispatchOnceInnerLocked调用findTouchedWindowTargetsLocked找到合适的Windows然后调用dispatchEventLocked，该函数调用prepareDispatchCycleLocked将事件发出     
      4）InputDispatcher::prepareDispatchCycleLocked
           4.1）调用enqueueDispatchEntryLocked创建DispatchEntry对象，并把它增加到Connection::outboundQueue队列中。
           4.2）调用activateConnectionLocked把当前Connection增加到InputDispatcher::mActiveConnections链表中
           4.3）调用InputDispatcher::startDispatchCycleLocked，接着它调用Connection::inputPublisher.publishMotionEvent来发布事件到ashmem buffer中，调用Connection::inputPublisher.sendDispatchSignal发送一个dispatch信号到InputConsumer通知它有一个新的消息到了，快来消费吧！

6. InputConsumer
java侧调用NativeInputEventReceiver::handleEvent()从而调用NativeInputEventReceiver::consumeEvents()从而调用InputConsumer::consumer()从InputDispatcher获取事件，并存储为InputEvent。
然后consumeEvents()回调java的函数keyEvent.obtain()或者MotionEvent.obtain()将InputEvent转化为java测的InputEvent。
然后回调Java侧的InputEventReceiver.InputEventReceiver()函数把消息发送到java侧。

7. InputEventReceiver
InputEventReceiver.InputEventReceiver()直接就呼叫 finishInputEvent 函数, 然后就送finishmessage 通知 InputDispatcherThread 之后, 就完成了这一个输入事件流程了. 然而, 依照过去写app的经验, 一般在app若要接收一些Touchevent 会有个 call back function onTouch 函数要实作, 方便app可以接收到Touch event 然后作相关的应用. 然而刚刚分析的输入事件的流程似乎没有去呼叫onTouch函数, 这到底是怎么一回事? 原因在于 InputEventReceiver 这个类别, 这个类别是属于 abstract 类别, 在java的语法中,abstract类别即使类别中的成员函数都有实作, 也是无法实体化的, 因此只能有abstract类别的衍生类别才能实体化. 搜寻了一下程序代码发现了几个abstract InputEventReceiver类别的衍生类别, 跟InputEvent处理有关的衍生类别就是WindowInputEventReceiver , 原因如下, 再一开始ViewRootImpl在作 setView 时, 除了new 一个新的 InputChannel 对象之后, 又 new 了一个 WindowInputEventReceiver 对象. 此 WindowInputEventReceiver 类别正好又overwrite onInputEvent函数, 因此可以大胆推测dispatchInputEvent呼叫的onInputEvent 函数, 会是此类别的 onInputEvent 函数, 就在从 WindowInputEventReceiver 中的 onInputEvent 函数开始分析.

8. WindowInputEventReceiver
这个类是ViewRootImpl的一个内部类，实现了InputEventReceiver
到了WindowInputEventReceiver.onInputEvent()就会把event传递给ViewRootImpl，ViewRootImpl会把事件传递给InputStage，InputStage代表了事件处理的几个层次，Activity、inputMethord、view等
[[./doc/20140216_android_input_system/Android_input_system.htm]]

    enum DeviceMode {
        DEVICE_MODE_DISABLED, // input is disabled
        DEVICE_MODE_DIRECT, // direct mapping (touchscreen)
        DEVICE_MODE_UNSCALED, // unscaled mapping (touchpad)
        DEVICE_MODE_NAVIGATION, // unscaled mapping with assist gesture (touch navigation)
        DEVICE_MODE_POINTER, // pointer mapping (pointer)
    };

enum {
    AINPUT_SOURCE_UNKNOWN = 0x00000000,

    AINPUT_SOURCE_KEYBOARD = 0x00000100 | AINPUT_SOURCE_CLASS_BUTTON,
    AINPUT_SOURCE_DPAD = 0x00000200 | AINPUT_SOURCE_CLASS_BUTTON,
    AINPUT_SOURCE_GAMEPAD = 0x00000400 | AINPUT_SOURCE_CLASS_BUTTON,
    AINPUT_SOURCE_TOUCHSCREEN = 0x00001000 | AINPUT_SOURCE_CLASS_POINTER,
    AINPUT_SOURCE_MOUSE = 0x00002000 | AINPUT_SOURCE_CLASS_POINTER,
    AINPUT_SOURCE_STYLUS = 0x00004000 | AINPUT_SOURCE_CLASS_POINTER,
    AINPUT_SOURCE_TRACKBALL = 0x00010000 | AINPUT_SOURCE_CLASS_NAVIGATION,
    AINPUT_SOURCE_TOUCHPAD = 0x00100000 | AINPUT_SOURCE_CLASS_POSITION,
    AINPUT_SOURCE_TOUCH_NAVIGATION = 0x00200000 | AINPUT_SOURCE_CLASS_NONE,
    AINPUT_SOURCE_JOYSTICK = 0x01000000 | AINPUT_SOURCE_CLASS_JOYSTICK,

    AINPUT_SOURCE_ANY = 0xffffff00,
};

*** root
**** koushikdutta
koushikdutta是一个开源软件，源代码在github上面可以下载到，下载地址为：
http://github.com/koush/Superuser
http://github.com/koush/Widgets

CM在koush的基础上，对koush的Java侧对象进行了继承和封装，并集成到了CM的ROM中，使用户可以在settings中对root权限进行设置，并且其他应用要获取root权限的时候，会弹出通知或者对话框让用户输入密码进行授权验证等。

代码解读如下：
koush的提权代码主要在jni目录下面，这个目录都是Native下运行的代码
1. su.c
这是koush的入口，也是系统的su程序
su --daemon的话就会启动daemon，这个一定是系统一起来就会拉起的daemon
其他的su参数，可以是su一个有root权限的shell，也可以是su一个命令。

2. daemon.c
su --daemon的话，su_main()就会执行daemon.c中的run_daemon()，启动一个监听socket的服务，
所有的获取root权限的申请都要发socket消息给daemon
daemon收到请求之后，会fork出一个su进程，这个进程从daemon这里得到root权限申请的相关信息，
然后这个孩子su进程会再监听一个新的socket，并且在Android侧弹出一个用户授权相关的对话框或者Activity，并将自己监听的socket的信息发送给这个Activity
Activity完成鉴权之后，将Deny或者Allow通过socket发送给su

3. su.c
其他应用可以直接通过和daemon进行socket交互完成获取root权限。
但是更多情况相信第三方应用是通过su命令来完成的，
如果第三方应用用su命令来进入su.c中的su_main()，则su.c来负责用socket链接daemon，并将需要以root权限做的事情用socket发送给daemon
下面的流程就可以参考daemon.c中描述了。

4. activity.c
用来在Java侧弹出Activity。

*** mem
**** mem_debug
***** libc.debug.malloc
代码基于Android2.3.x版本
Android为Java程序提供了方便的内存泄露信息和工具（如MAT），便于查找。但是，对于纯粹C/C++编写的natvie进程，却不那么容易查找内存泄露。传统的C/C＋＋程序可以使用valgrind工具，也可以使用某些代码检查工具。幸运的是，Google的bionic库为我们查找内存泄露提供了一个非常棒的API－－get_malloc_leak_info。利用它，我们很容易通过得到backtrace的方式找到涉嫌内存泄露的地方。
代码原理分析
我们可以使用adb shell setprop libc.debug.malloc 1来设置内存的调试等级（debug_level），更详细的等级解释见文件bionic/libc/bionic/malloc_debug_common.c中的注释：
/* Handle to shared library where actual memory allocation is implemented.
 This library is loaded and memory allocation calls are redirected there
 when libc.debug.malloc environment variable contains value other than
 zero:
 1 – For memory leak detections.
 5 – For filling allocated / freed memory with patterns defined by
 CHK_SENTINEL_VALUE, and CHK_FILL_FREE macros.
 10 – For adding pre-, and post- allocation stubs in order to detect
 buffer overruns.
 Note that emulator’s memory allocation instrumentation is not controlled by
 libc.debug.malloc value, but rather by emulator, started with -memcheck
 option. Note also, that if emulator has started with -memcheck option,
 emulator’s instrumented memory allocation will take over value saved in
 libc.debug.malloc. In other words, if emulator has started with -memcheck
 option, libc.debug.malloc value is ignored.
 Actual functionality for debug levels 1-10 is implemented in

 libc_malloc_debug_leak.so, while functionality for emultor’s instrumented
 allocations is implemented in libc_malloc_debug_qemu.so and can be run inside
 the emulator only.
*/
对于不同的调试等级，内存分配管理函数操作句柄将指向不同的内存分配管理函数。这样，内存的分配和释放，在不同的的调试等级下，将使用不同的函数版本。
详细过程如下： bbs.yuucn.com 全球顶尖IT精英加盟我们，专业为您解决问题
如下面代码注释所说，在__libc_init例程中会调用malloc_debug_init进行初始化，进而调用malloc_init_impl（在一个进程中，使用pthread_once保证其只被执行一次）
在malloc_init_impl中，会打开对应的C库，解析出函数符号：malloc_debug_initialize（见行366），并执行之（行373）

*** view,canvas,windows
**** 总体来看
拥有UI的应用通常都会拥有至少一个Activity，这个Activity在WindowsManagerService上面会被以一个Windows管理
这个Windows又会对应一个ViewRootImpl，Activity的所有的Layout、ViewGroup、控件的view都会以树状的形式从属于ViewRootImpl。
ViewRootImpl对应一个Surface，ViewRootImpl会递归的调用它下面的所有的ViewGroup和View的draw，来在自己的surface上进行绘制。
后续当ViewRootImpl发生inValiate的时候，也会重新递归调用各个ViewGroup和View的draw进行重新绘制。
**** ViewRootImpl
应用中每一个Activity都拥有一个ViewRootImpl，在进程启动的时候由ActivityThread触发，将ViewRootImpl添加到WindowManagerGlobal的。
ViewRootImpl下面的ViewGroup和View是递归的被addView至他们的父亲View，这个addView的过程通常是在inflate过程中完成的。
当然在运行期间，也有可能会发生动态的addView，比如动态的添加一个控件等等。
**** inflate,measure,layout
http://825288003.iteye.com/blog/1770602
Activity.setContentView()
    PhoneWindow.setContentView()
        LayoutInflager.inflate()
            LayoutInflager.rInflate()
                LayoutInflager.parseInclude()    // 创建View,add View
            view.setLayoutParams()
                    ViewGroup.addView()
            createViewFromTag()
                        createView(attrs)
                            View.View(attrs)    // View的属性
PhoneWindow.measure()
PhoneWindow.onMeasure() // calc the heigh and wigth of the view
ViewRootImpl.doTraversal()
    ViewRootImpl.performTranversals()
        ViewRootImpl.performMeasure()
	    View.performMeasure()
        ViewRootImpl.performLayout()
            ViewRootImpl.measureHierarchy()
            View.layout(left, top, right, bottom)
                View(specify view,as LinearLayout).onLayout()
                    LinearLayout.layoutVertical()
                        LinearLayout.setChildFrame()
                            View(childs).layout(left, top, right, bottom)
                    LinearLayout.layoutHorizontal()
	    View.requestLayout()

*** vm
**** dalvik dexopt
1. Main Flow
main() // the Entry of the tool , dalvik/dexopt/OptMain.cpp
    fromDex()  // process dex, it is easy to understand, will don't want to check the process of zip , this function is still in OptMain.cpp
        dvmContinueOptimization() // dalvik/vm/analysis/DexPrepare.cpp
            rewriteDex()  // optimize the dex, still in DexPrepare.cpp
                dexSwapAndVerify()   // swap byte order, still in DexPrepare.cpp
                dvmDexFileOpenPartial(),dexCreateClassLookup(),loadAllClasses()   // create the DvmDex, load the class , still in DexPrepare.cpp
                verifyAndOptimizeClass()   // still in DexPrepare.cpp
                    dvmOptimizeClass(ClassObject* clazz, bool essentialOnly) // Optimize a class, dalvik/vm/analysis/Optimize.cpp
                        optimizeMethod()   // Optimize a method, analyse the source of the method, rewrite the invoke and put operation, still in Optimize.cpp
                            rewriteVirtualInvoke(),rewriteExecuteInlineRange(),rewriteExecuteInline()   // Optimize a invoke, still in optimize.cpp
                                dvmOptResolveMethod() // resolve the methord invoked, still in optimize.cpp
                                    dvmOptResolveClass()
2. head
There is a head in the beginning of dex file. Check the dexFileParse(), pDexFile->pOptHeader, dexFileSetupBasicPointers()
    pDexFile->pStringIds = (const DexStringId*) (data + pHeader->stringIdsOff);
    pDexFile->pTypeIds = (const DexTypeId*) (data + pHeader->typeIdsOff);
    pDexFile->pFieldIds = (const DexFieldId*) (data + pHeader->fieldIdsOff);
    pDexFile->pMethodIds = (const DexMethodId*) (data + pHeader->methodIdsOff);
    pDexFile->pProtoIds = (const DexProtoId*) (data + pHeader->protoIdsOff);
    pDexFile->pClassDefs = (const DexClassDef*) (data + pHeader->classDefsOff);
    pDexFile->pLinkData = (const DexLink*) (data + pHeader->linkOff);

The dexFileParse() function will parse the header in the Dex file, and put the value in the pDexFile structure.

3. Resolve Class and methord
The process of resolve class and methord associates with the optimize process.
Check the function named dvmFindClassNoInit() used in the dvmOptResolveClass.
    The dexopt using libcore/libdvm/src/main/java/java/lang/ClassLoader.java (calling dalvik/vm/native/java_lang_VMClassLoader.cpp) to resolve Class.

4. LoadClass
Parse the dex file:
The rewriteDex() invokes dexCreateClassLookup() to create the pDvmDex->pDexFile->pClassLookup, which indexes the ClassDef pointers which stored in DexFile->pClassDefs
Resolve the system classes:
The Dalvik_java_lang_VMClassLoader_loadClass() invokes:
    dvmFindClassByName()
        dvmFindClassNoInit()
            dvmFindSystemClassNoInit()
                findClassNoInit()
                    searchBootPathForClass()  // no DexDvm, means the class to find is the system class, search in Boot Path. Iterate the boot path .jar and .dex files
                        dexFindClass() // here to find the ClassDef by using dexFile->pClassLookup,
                    dexFindClass()  // There is DexDvm, means the class is in the dex file we are optimizing, so dexFindClass directly.
                    loadClassFromDex()  // resolve the details of the class from ClassDef, 
                        dexGetClassData() // There is offset in the ClassDef info, we can locate the encodedata of the class
                        loadClassFromDex0()// resolve the fields methods interface and so on from encodeddata
                    dvmAddClassToHash()  // put the class to the Hash table, next time we can use dvmLookupClass() to find it
                    dvmLinkClass() // This converts symbolic references into pointers.

**** art: start up
dalvikvm()    (in dalvikvm.cc)
    JNI_CreateJavaVM
        runtime::start()
            InitNativeMethods()
            InitThreadGroups()
            if(__is__zygote) InitZygote()
            if(!__is__zygote) DidForkFromZygote()
            StartDaemonThreads()
            system_class_loader_ = CreateSystemClassLoader()
            finished_starting_ = true
            StartProfiler()
	    return env and vm
    InvokeMain(env, arg)
        klazz = env->FindClass()
        method = env->GetStaticMethodID(klass.get(), "main", "([Ljava/lang/String;)V");       ( ** method is mid ** )
        env->CallStaticVoidMethod(klazz, method)
            InvokeWithVarArgs(soa, obj=null, mid, args)    (in reflaction.cc, because static method invoking, obj=null)
                InvokeWithArgArray(soa, soa.DecodeMethod(method), arg_array, &result, shorty)      (in reflaction.cc)
                    method->Invoke(soa.Self(), args, arg_array->GetNumBytes(), result, shorty)     (in mirror/art_method.cc)
                        art_quick_invoke_stub(method, args, size, thread=self, result, shorty)     (in arch/xx/quick_entrypoints_xx.S)
                        (or art_static_invoke_stub, art_portable_invoke_stub)
            
**** art: methord
***** invoke a methord
InvokeVirtualOrInterfaceWithVarArgs(soa, obj, mid, args)      (in reflaction.cc)
    receiver = soa.Decode<mirror::Object*>(obj)
    FindVirtualMethod(receiver, soa.DecodeMethod(mid))     (in reflaction.cc)
        receiver->GetClass()->FindVirtualMethodForVirtualOrInterface(method)   (in mirror/class-inl.h, in the class Class::)
            FindVirtualMethodForInterface(method)
            or FindVirtualMethodForVirtual(method)
    InvokeWithArgArray(soa, method, &arg_array, &result, shorty)    (the things in this function is described above)

**** art: thread
***** dump thread stack
The source of dump thread stack is in the art/runtime/thread.cc
The class BuildInternalStackTraceVisitor is used to create the raw data information of the stack trace
The methord Thread::CreateInternalStackTrace() will create a jobject contains the InternalStackTrace.
We can dunp the stack trace in the native code like this(art/runtime/exception_test.cc):
  jobject internal = thread->CreateInternalStackTrace<false>(soa);
  ASSERT_TRUE(internal != nullptr);
  jobjectArray ste_array = Thread::InternalStackTraceToStackTraceElementArray(soa, internal);
  ASSERT_TRUE(ste_array != nullptr);
  mirror::ObjectArray<mirror::StackTraceElement>* trace_array =
      soa.Decode<mirror::ObjectArray<mirror::StackTraceElement>*>(ste_array);

  ASSERT_TRUE(trace_array != nullptr);
  ASSERT_TRUE(trace_array->Get(0) != nullptr);
  EXPECT_STREQ("ExceptionHandle",
               trace_array->Get(0)->GetDeclaringClass()->ToModifiedUtf8().c_str());
  EXPECT_STREQ("ExceptionHandle.java",
               trace_array->Get(0)->GetFileName()->ToModifiedUtf8().c_str());
  EXPECT_STREQ("g", trace_array->Get(0)->GetMethodName()->ToModifiedUtf8().c_str());
  EXPECT_EQ(37, trace_array->Get(0)->GetLineNumber());

  ASSERT_TRUE(trace_array->Get(1) != nullptr);
  EXPECT_STREQ("ExceptionHandle",
               trace_array->Get(1)->GetDeclaringClass()->ToModifiedUtf8().c_str());
  EXPECT_STREQ("ExceptionHandle.java",
               trace_array->Get(1)->GetFileName()->ToModifiedUtf8().c_str());
  EXPECT_STREQ("f", trace_array->Get(1)->GetMethodName()->ToModifiedUtf8().c_str());
  EXPECT_EQ(22, trace_array->Get(1)->GetLineNumber());

The first stack can be got by trace_array->Get(0), second one can be got by trace_array->Get(1), and so on.

**** art: iftable
***** how to get if table
Actually the IfTable is not in the object Class, it is on the heap.
The object Class use a field named iftable_ as the reference of the IfTable.
(in mirro/class.h and mirro/class-inl.h)
inline IfTable* Class::GetIfTable() {
  return GetFieldObject<IfTable>(OFFSET_OF_OBJECT_MEMBER(Class, iftable_));
}
***** how to set if table
inline void Class::SetIfTable(IfTable* new_iftable) {
  SetFieldObject<false>(OFFSET_OF_OBJECT_MEMBER(Class, iftable_), new_iftable);
}
***** TODO when to set if table
ClassLinker::CreateArrayClass()         (in class_linker.cc)      
ClassLinker::LinkInterfaceMethods()     (in class_linker.cc)

why there is CreateArrayClass need to Class::SetIfTable, Creating a normal Class do not need.

**** art: GC
***** what is GC Roots
The so-called GC (Garbage Collector) roots are objects special for garbage collector. Garbage collector collects those objects that are not GC roots and are not accessible by references from GC roots.

There are several kinds of GC roots. One object can belong to more than one kind of root. The root kinds are:

Class - class loaded by system class loader. Such classes can never be unloaded. They can hold objects via static fields. Please note that classes loaded by custom class loaders are not roots, unless corresponding instances of java.lang.Class happen to be roots of other kind(s).

Thread - live thread

Stack Local - local variable or parameter of Java method

JNI Local - local variable or parameter of JNI method

JNI Global - global JNI reference

Monitor Used - objects used as a monitor for synchronization

Held by JVM - objects held from garbage collection by JVM for its purposes. Actually the list of such objects depends on JVM implementation. Possible known cases are: the system class loader, a few important exception classes which the JVM knows about, a few pre-allocated objects for exception handling, and custom class loaders when they are in the process of loading classes. Unfortunately, JVM provides absolutely no additional detail for such objects. Thus it is up to the analyst to decide to which case a certain "Held by JVM" belongs.

**** boot.art
Boot.art is an memory image contains all root objs.
Dump:
You can have a start up by reading the code of class named ImageDumper in art/oatdump/oatdump.cc.
Generate:
Check the code of the class ImageWriter in art/compiler/image_writer.h
Load:
Runtime::Create(RuntimeOptions&)
The option item named -Ximage

*** start up
**** SystemServer
The code of SystemServer is frameworks/base/services/java/com/android/server/SystemServer.java
SystemServer.java do start up at main(), for it is a indepent java process.
The main() function will start each native services by the function nativeInit().
The main() function will start a thread to start each java services.
        ServerThread thr = new ServerThread();
        thr.initAndLoop();

**** zygote startup & bootstrap dexopt
When the Zygote is boot up by the app_process via init.rc.
main()  // in app_main.c
    AndroidRuntime::start()   // AppRuntime inherit from AndroidRuntime
        AndroidRuntime::startVm()   // There are lots of VMopitions indicate here
            JNI_CreateJavaVM()  // In the file java_vm_ext.cc
                Runtime::Create()  // In the file runtime.cc
                    Runtime::Init()
                        gc::Heap::Heap()  // called by Runtime::Init via new gc::Heap
                            space::ImageSpace::Create()
                                GenerateImage() or RelocateImage()                   
                                    PruneDexCache()  // The dalvik-cache folder will be pruned, if the image is regenerated.



*** ActivityManage
**** How to start a Activity
The Application info is resolved in this methord ActivityStackSupervisor.startActivityMayWait() in ActivityStackSupervisor.java
ActivityStackSupervisor.startActivityMayWait() use resolveActivity() to get the application.info from PackageManagerService.

In ActivityManagerService.java, startProcessLocked() will start a new App process by sending message to Zygote, and recode the AppInfo in the mPidsSelfLocked.
The child forked by Zygote will launch ActivityThread.main() first, and call the ActivitymanagerService.attachApplication() by binder. In the applicationAttachLocked(), AMS can get the AppInfo from the mPidsSelfLocked by the caller-pid.
In applicationAttachLocked(), AMS will also use ensurePackageDexOpt() to pre-dex-opt the APK.
And then AMS will call the ActivityThread.bindApplication() through binder, and send the appinfo to the ActivityThread of the App.
*** PM and Installd
**** Package Manager
Package Manager connect to installd by socket.

./services/java/com/android/server/pm/PackageManagerService.java
./services/java/com/android/server/PackageManagerBackupAgent.java
./core/java/android/content/pm/PackageManager.java

We called dexopt for both dexopt of dalvik and dex2art of art runtime.

PackageManagerService.performBootDexOpt()  // Apps used in the 7 days for users go to dexopt. In PackageManagerService.java
    PackageManagerService.performDexOptLI()
        DexFile.isDexOptNeededInternal()    // This is a jni function, it is record to the DexFile_isDexOptNeededInternal()
            DexFile_isDexOptNeededInternal()    // In art/runtime/native/dalvik_system_DexFile.cc
                IsDexOptNeededForFile()     // In art/runtime/native/dalvik_system_DexFile.cc
                    // In side the function, oat_dex_file = oat_file->GetOatDexFile() means get the dex_file partition in the oat file.


                

**** installd

The installd is here
frameworks/native/cmds/installd

** Emulator & qemu
*** how to start emulator for Android
./prebuilts/android-emulator/linux-x86_64/emulator64-x86 -sysdir ./out/target/product/generic_x86_64/ -data userdata.img -kernel ./prebuilts/qemu-kernel/x86_64/kernel-qemu -memory 2048 -partition-size 1000 -gpu off  &

** 刷机经验
*** 将i9100刷成CyanogenMod
2014年4月12日，我经过一个下午和一个晚上的奋战，我把一台闲置的SAMUNGE i9100刷成了CyanogenMod10.1.3稳定版本(对应Android4.0版本）。
4月13日清晨我又通过OTA升级，将该手机升级到了CyanogenMod11-20140412 NightDaily版本，对应Android4.4.2。
目前系统运行正常，下面是我的刷机经过。
i9100原声版本是Android2.3版本
1. PC下载CMinstaller刷机，i9100下载对应的CM安装应用。
本来应该是将手机连接在电脑上，运行CMInstaller就可以完成升级的，
但是我的手机在进入挖煤模式后和PC机的USB连接就会断掉，猜测是由于CMInstall和手机挖煤模式的USB驱动不兼容导致。
无奈只能采用手工刷机。
2. 刷recovery至CWM recovery
由于需要卡刷CM的安装包，所以需要将recovery升级至CWM。
我用odin连接手机的挖煤模式（只有我本子的右上角那个USB口可以连上），并且将recovery升级至CWM（选PDA）
3. 通过CWM recovery将手机刷成CM10.1.3
将i9100的CM10.1.3的升级包（我的手机不是i9100g）存入一张sdcard，并将sdcard插入i9100中。
在CWM recovery菜单中双清，并选择sdcard install，完成刷机。
升级过程中主要异常是CM10.1.3升级包中的update-script运行时，getprop取系统的or.product.device和i9100不匹配，分析这可能是因为手机是水货，系统中的prop文件中对应的产品名称不正确导致，不影响升级，所以讲CM10.1.3升级包手工解开，修改升级脚本，将getpropp("r.product.device")的校验项人为干掉，再压成包，就能在CWM中正常安装了。
另外CWM还有很多不正常的地方，比如log分区mount不上，sdcard文件节点mount不上，外置sdcard被mount到了内置sdcard的节点上了等不正常的现象。
4. 无法启动
刷机后，手机启动不了，停在samsung logo上，logo下面有黄色惊叹号。
5. 可能是fastboot版本较新或者CWM版本不正确的原因
有可能是fastboot版本太新，有lock功能，可以检验recovery的版本，如果非官方版本就不让启动。
也可能是前面使用的CWM的版本有问题，前面也说了，CWM在mount的时候有诸多奇怪问题。
6. 在网上找到一套img，全面刷fastboot、recovery、moderm
使用这个全套img，将手机上面三个区全面升级一下，这样各个区的版本都匹配上，特别是将fastboot降级叫老版本，不会对recovery进行校验。
7. 然后重新用CWM卡刷CM10.1.3的升级包
刷完后重启，成功，进入CyanogenMod10.1.3
8. 第二天清晨，通过CM的OTA在线升级，将CM升级至4-12日的CM11 nightdaily版本
出现trebuchet应用不断崩溃问题，无法进入Launcher
解决方法，在APP设置中，将trebuchet应用进行数据清理，重启，ok就好了。
Nice，我的i9100用上了目前世界上最新版本的手机操作系统了，老树逢春，梅开二度啊。

** source on the web
*** mirror of the android.googlesource.com
**** codeaurora.org
http://www.codeaurora.org
for example:
git clone git://codeaurora.org/platform/frameworks/base -b aosp-new/master

repo init -u git://codeaurora.org/platform/manifest.git -b aosp-new/master

diff --git a/default.xml b/default.xml
index f5dffb1..1d7cc92 100644
--- a/default.xml
+++ b/default.xml
@@ -2,9 +2,9 @@
 <manifest>
 
   <remote  name="aosp"
-           fetch=".."
+           fetch="git://codeaurora.org/"
            review="https://android-review.googlesource.com/" />
-  <default revision="master"
+  <default revision="aosp-new/master"
            remote="aosp"
            sync-j="4" />
 
@@ -116,7 +116,6 @@
   <project path="external/esd" name="platform/external/esd" />
   <project path="external/expat" name="platform/external/expat" groups="pdk" />
   <project path="external/eyes-free" name="platform/external/eyes-free" />
-  <project path="external/f2fs-tools" name="platform/external/f2fs-tools" />
+  <project path="external/f2fs-tools" name="platform/external/f2fs-tools" revision="kernel-f2fs-tools/master" />
   <project path="external/fdlibm" name="platform/external/fdlibm" />
   <project path="external/fio" name="platform/external/fio" />
   <project path="external/flac" name="platform/external/flac" groups="pdk" />
@@ -214,7 +213,6 @@
   <project path="external/qemu" name="platform/external/qemu" />
   <project path="external/qemu-pc-bios" name="platform/external/qemu-pc-bios" /
   <project path="external/regex-re2" name="platform/external/regex-re2" />
-  <project path="external/replicaisland" name="platform/external/replicaisland"
   <project path="external/robolectric" name="platform/external/robolectric" />
   <project path="external/safe-iop" name="platform/external/safe-iop" groups="p
   <project path="external/scrypt" name="platform/external/scrypt" groups="pdk"


* network
** emule和bt协议
@bt @emule

BT和eMule下载协议的比较和分析   eDonkey由Jed McCaleb在2000年创立。

采用“多源文件传输协议”(MFTP，the Multisource File Transfer Protocol)。

eDonkey索引服务器并不集中在一起的，而是各人私有的，遍布全世界，每一个人都可以运行电驴服务器，同时共享的文件索引为被称为“ed2k-quicklink”的连接，文件前缀“ED2K://”。

每个文件都用md5-hash的超级链接标示，这使得该文件独一无二，并且在整个网络上都可以追踪得到。

EDonkey可以通过检索分段从多个用户那里下载文件，最终将下载的文件片断拼成整个文件。

2002年05月3日Merkur不满意eDonkey 2000客户端并且坚信自己能做出更出色的P2P软件，于是便着手开发。

凝聚一批原本在其他领域有出色发挥的程序员，eMule工程就此诞生,目标是将eDonkey的优点及精华保留下来，并加入新的功能以及使图形界面变得更好。

现在eMule的最新版本是0.48a(2007年5月20号发布)。

 emule是eDonkey的升级版，它的独到之处在于开源。

其基本原理和运作方式，也是基于eDonkey,能够直接登录eDonkey的各类服务器。

eMule同时也提供了很多eDonkey所没有的功能，比如可以自动搜索网络中的服务器、保留搜索结果、与连接用户交换服务器地址和文件、优先下载便于预览的文件头尾部分等等，这些都使得eMule使用起来更加便利，也让它得到了电骡的美誉。

  支持BT协议的P2P应用程序很多，如BitBuddy、FlashBT、BitComet和BitSpirit等，通常BT由如下几部分组成：.torrent文件、种子提供站点、目录服务器和内容发布者/下载者。

.torrent文件是一个文本文件，包含了tracker信息和文件信息两部分。

tracker信息主要是BT下载中需要用到的tracker服务器的地址和针对tracker服务器的设置；文件信息是指将目标文件计算处理后再根据BT协议的B编码规则网编码后得到的信息。

BT的主要原理是把提供下载的文件虚拟分成小相等的块，块小必须为2  Kbyte的整数次方（由于是虚拟分块，硬盘上并不产生各个块文件），并把每个块的索引信息和Hash验证码写入.torrent文件中，所以.torrent文件就是被下载文件的“索引”。

早期的BT协议只支持tracker服务器，这种目录服务器是集中式目录与分布式查询的混合型；在BT协议的升级版本中，增加了对DHT（分布式Hash表）网络的支持。

  BT和eMule协议的宏观比较和分析  emule从技术层面上说是比BT好很多的，可是由于各种各样的原因，似乎在互联网上emule并不是很流行。

 1.传统连接方式:  BT使用统一的torrent文件先作一个原下载文件的信息记录,然后客户下载后通过torrent的信息与服务器连接并下载,emule仅有一个文件ID,客户自行与服务器连接再下载;eMule的资源发布更便捷，同时资源更丰富，BT中不同种子之间的用户是分隔的，即使种子中包含的文件是相同的，BT用户之间也无法互通连接。

 2.底层传输协议比较:  BT只使用TCP协议进行下载,协议简单有效,但是功能比较单一,有的功能不完整,emule使用TCP和UDP两种协议进行通信,更加有效的利用了网络资源,功能完整强,但这也同时使主机的负荷增加； 3.文件组织方式和数据验证方式:   BT会在开始前对文件进行一次完全的HASH,就是将文件首尾相联然后按固定块取SHA值,这些值最终被放入torrent文件编码中,客户从网上一次下载完全,高效简单,一般情况下BT软件会在每小块下载完成后就对其进行HASH测试,检查其正确性。

emule在链接字符串中只存放了整体文件的HASH值,通过将这个HASH到服务器上取出文件的相关信息,实际的操作中,会将文件分解成9.28M小的块并进行HASH用于对块的完整性测试。

新版的emule会用一种叫AICH的技术,就是说将文件分成80K小的块然后HASH再将HASH值进行二进迭代式（具体的看emule协议)的HASH最终组成一个HASH二叉树。

好处：可以在链接中只加入根结节的HASH值而不用加入叶子节点,减小了链接字符串小,如果在最终文件下载完毕后,测试出的根节点HASH与得到的根节点的HASH值不同,则可以通过协议与网络上的其它主机的树进行比较快速得出错误的块。

 4.流量控制方式: BT采用针锋相对的方式处理上传下载平衡的控制,这种方式会记录短期内与客户连接的所有节点的上传下载流量,通过在固定时间内对下载流量的比较,得出允许上传的客户;为防止新客户长时间得不到其它客户的认同,BT会在一段时间停止他的上传作为对他的警告；对于已经下载完毕的客户,BT会简单的使上传流量最多的客户得到更多的时间完成上传;为了防止在文件的最后阶段下载速度下降,BT会在最后时向所有连接的客户发送请求迅速完成下载;下载过程中,BT会对文件块在整个网络中的存在复本的多少进行跟踪,比较少的复本总是会得到优先的下载权,以使整个网络的文件冗余度提高。

简单的说，BT使用的是针对文件的流量控制方式。

  Emule采用的是客户积分的方式,就是对所有用户的上传和下载量进行一个运算,从而得出一个客户的积分值,那些积分比较高的用户总是可以得到优先的下载权,甚至可以不进行排队直接下载,结果就是:在一个比较长的时间内对一个用户对其它用户的整体贡献有了一个估量。

简单的说，emule采用的是针对用户的流量控制方式。

  5.功能与性能： emule具有查找功能,而这在BT只能通过网站来实现。

 BT的方式更注重于简单高效的快速传输，而emule更注重于整个网络状态的变化及用户体验。

单从下载效率上说BT占优,而从网络状态及完整的协议支持上说,emule则作了更多的事情。

从性能上考虑,在相同网络状态下,BT下载单文件的能力比较强,emule比较适合于长时间的多文件下载,对机器的使用和影响比较小，这源于两者对网络均衡及p2p模式的不同理解。

  BT片选择策略  1.片断选择 选择一个好的顺序来下载片断，对提高性能非常重要。

一个不好的片断选择算法可能导致所有的片断都处于下载中，或者在某一时间段没有上载任何片段给其它peers。

 2.严格的优先级 片断选择最优先策略是：一旦用户请求了某个片断的子片断，那么将优先请求该片断剩下的子片断。

这样用户可以尽可能快地获得一个完整的片断。

 3.最少优先 对一个下载者来说，在选择下一个下载片断时，通常选择的是在peers之间流传最少的那个片断，也就是所谓的“最少优先”。

这种技术，确保了每个下载者都拥有它的peers们最希望得到的那些片断（即最“稀有”的片段）。

这也确保了那些越普通的片断越放在最后下载，从而减少了这样一种可能性，即某个peer当前正提供上载，而随后却没有任何别人所需要的片断了。

每个peer都优先选择整个系统中最少的那些片断去下载，而那些在系统中相对较多的片断，放在后面下载，这样，整个系统就趋向于一种更优的状态。

如果不用这种算法，大家都去下载最多的那些片断，那么这些片断就会在系统中分布的越来越多，而那些在系统中相对较少的片断仍然很少，最后，某些peer就不再拥有其它peer所需要的片断了，那么系统的参与者越来越少，整个系统的性能就下降。

在BT系统中，充分考虑了经济学的概念，处处从整个系统的性能出发，参与者越多，系统越优化。

 4.随机的第一个片断 “最少优先”的一个例外是在下载刚开始的时候。

此时，下载者没有任何片断可供上传，所以，需要尽快的获取一个完整的片断。

而最少的片断，通常只有某一个peer拥有，所以，它可能比多个peers都拥有的那些片断下载的要慢。

因此，第一个片断是随机选择的，直到第一个片断下载完成，才切换到“最少优先”的策略。

 5.最后阶段模式 有时候，从一个速率很慢的peer那里请求一个片断。

在下载的中间阶段，这不是什么问题，但是却可能潜在的延迟下载的完成。

为了防止这种情况，在最后阶段，peer向它的所有的peers们都发送某片断的子片断的请求，一旦某些子片断到了，那么就会向其它peer发送cancel消息，取消对这些子片断的请求，以避免带宽的浪费。

实际上，用这种方法并没有浪费多少带宽，而文件的结束部分也一直下载的非常快。

 6.阻塞（choking）算法 BT并不集中分配资源。

每个peer自己有责任来尽可能的提高它的下载速率。

Peers从它可以连接的peers处下载文件，并根据对方提供的下载速率给予同等的上传回报（你敬我一尺，我敬你一丈）。

对于合作者，提供上传服务，对于不合作的，就阻塞对方。

所以说，阻塞是一种临时的拒绝上传策略，虽然上传停止了，但是下载仍然继续。

在阻塞停止的时候，连接并不需要重新建立。

阻塞算法并不属于BT对等协议（指peers之间交互的协议）的技术部分，但是对提高性能是必要的。

一个好的阻塞算法应该利用所有可用的资源，为所有下载者提供一致可靠的下载速率，并适当惩罚那些只下载而不上传的peers。

 BT帕累托有效是指任何重新改变资源配置的方式，都不可能使一部分人在没有其他人受损的情况下受益。

这一资源配置的状态，被称为“帕累托最优”（Pareto optimum）状态，或称为“帕累托有效”(Pareto efficient)。

 在计算机领域，寻求帕累托有效是一种本地优化算法BitTorrent的阻塞算法，用一种针锋相对的方式来试图达到帕累托最优。

 但是算法存在以下问题: 最后一个片断的问题被夸大，且随机的第一个片断问题则被低估了。

BitTorrent的最少优先策略在使得一个拥有了部分文件片断的节点快速找到缺少的片断的效率并不好。

  eMule协议和片选择及搜索算法  为了优化整个网络的吞吐量和共享，eMule仔细挑选选择块的下载顺序。

基本的选择策略和分片信息是这样的：每个文件被分成9.28M的块，每部分分成80KB的片。

块下载的顺序是由发送请求文件块消息（.4节）的下载客户端决定。

下载客户端可以在任何给定时刻从各个源中下载一个单独的文件块，所有从相同源中请求的片都在同一个块中。

下面的原理（以这个顺序）应用于下载块等级： 1.（可获得的）片的频率，尽可能快的下载非常稀少的片来形成一个新的源。

 2.用来预览的块（最初+最后的片），预览或检查文件（比如，电影、mp3） 3.请求状态（过程中下载），尝试向每个源询问其它的片。

在所有源之间扩散请求。

 4.完成（未到某种程度的完成），在开始下载另一个时应该完成获得部分的片   频率标准定义了三个区域：非常稀少、稀少和一般。

在每个区域里，标准有特定的权重，用来计算块等级。

较低等级的块先下载。

下面的列表根据上面的原理指定文件等级范围： l0-9999 - 不请求和请求非常稀少的块 l0000-9999 - 不请求稀少和预览块 l20000-29999 - 不请求部分完成的一般的块 l30000-39999 - 请求的稀少和预览的块 l40000-49999 - 请求的没有完成的一般的块 这个算法通常选择第一个最稀少的块。

然而，部分完成的块，接近完成的，也可能被选中。

对于一般的块，在不同的源之间扩散下载。

  eMule和BT中DHT算法 DHT的全称是Distributed Hash Table，即分布式哈希表技术，是一种分布式存储方法。

这种网络不需要中心节点服务器，而是每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。

和中心节点服务器不同，DHT网络中的各节点并不需要维护整个网络的信息，而是只在节点中存储其临近的后继节点信息，幅减少了带宽的占用和资源的消耗。

DHT网络还在与关键字最接近的节点上复制备份冗余信息，避免了单一节点失效问题。

我们可以把整个DHT网络想象成一个城市，那么每个客户端，就好比城市里各个角落的地图，上面绘制了附近区域的地形情况，把这些地图一汇总，城市的全貌就出来了。

  而DHT所采用的算法中最出名的是Kademlia，eMule最早开始使用，Bitcomet、Azureus和BitTorrent只是步其后尘，同样使用Kademlia算法的DHT。

不过它们各自的实现协议不尽相同，因此不能相互兼容（BitComet与BitTorrent兼容，Azureus更像eMule，但与其它都不兼容）。

   在2005年5月著名的BiTtorrent在4.0版实现基于Kademlia协议的DHT技术后，很快国内的BitComet和BitSpirit也实现了和BitTorrent兼容的DHT技术，实现trackerless下载方式。

emule实现的基于Kademlia类似的技术（BT中叫DHT，emule中叫Kad），和BT软件使用的Kd技术的区别在于key、value和node ID的计算方法不同。

  对于BT协议，目前国内用户使用最多的BT客户端就是Bitcomet，默认情况下，无须做任何设置BitComet即可自动连接并使用DHT网络。

启动软件，它会使用和TCP端口号相同的UDP端口进行DHT网络连接。

任何P2P技术的改进都与版权的博奕脱不了干系，DHT网络能够引起如此注目亦是如此。

  确实，BT采用DHT网络后，反盗版将变得更加困难。

因为在此之前，用户进行BT下载时，必需首先连接上Tracker服务器，根据所获得的正在进行下载和上传的用户列表，才能够进行正常的文件交换。

这样的话，只需封禁掉提供Tracker服务的网站，便可以截断盗版传播的途径。

DHT网络则不同，由于此时互联网中任何一个运行BT客户端的用户都可以作为DHT网络中的节点，因此即使封禁掉那些提供Tracker服务的网站，用户还是能够通过全球范围的逻辑DHT网络分享文件，反盗版就无从谈起。

除非让上的人都不上网，或宣布使用BT软件为重罪。

但技术从来都是一把双刃剑。

在批判BT助长盗版气焰的同时，我们也应该看到，BT也正在日渐成为合法作品传播的途径。

由于无法承受超量流量的访问，一些免费和共享软件（如Foobar2000等）开始采用BT方式分发型的合法软件——Linux系统，更是将BT作为主要的分发渠道。

   在eMule中也有使用，常把它叫做KAD，只不过具体实现的协议有所不同。

Kad网络的主要的目标是做到不需要服务器和改善可量测性。

相对于传统的ed2k服务器只能处理一定数量的使用者(我们在服务器列表也都看到了,每个服务器都有最多人数限制)，而且如果服务器连接人数过多,还会严重的的拖垮网络。

传统的ed2k网络需要服务器支持作为中转和存储hash列表信息，kad可以不通过服务器同样完成ed2k网络的一切功能。

Kad需要UDP端口的支持，之后Emule会自动按照客户端的要求，来判断它能否自由连线，然后同样也会分配一个id，这个过程和ed2k的高id和低id检查很像，不过这个id所代表的意义不同于ed2k网络，它代表一个是否“ly”的状态。

 Kad能够自我组织,并且自我调节最佳的使用者数量以及他们的连接效果。

因此,它更能使网络的损失达到最小。

由于具备了以上所叙述的功能，Kad也被称之为Serverless network（无服务器网络）。

虽然目前一直处于开发阶段(alpha stage) 。

通过进行Kad关键字搜寻，任何人可以在文件分享网络中寻找资料。

没有任何中央服务器储存文件索引，这项工作是平均由所有客户端担当：拥有要分享的文件的枝节点，会先处理文件的内容，并从内容计算出一组杂凑Hash值，这组值将会在分享网络中辨识这个文件。

kad网络首先给每个客户分配一个唯一的ID值,然后对不同的ID值进行异或来得到两个客户之间的“距离”,kad会维护一个桶,“距离”越近的用户桶里的数量会越多,kad定期对桶里的用户进行清理,以保持其有效性。

 对于文件和用户emule会有两个这样的结构,可以通过kad来查找文件和文件相关的用户信息;同样为了考虑冗余的问题,kad会将其自身的信息复制一份给“距离”它最近的一定数量的用户,这样就算在它下线后,这些信息也不会丢失。

Kad本身有一个nodes.dat文件，也叫做节点文件，这里面存放了我们在Kad网络中的邻居节点，我们都是通过这些节点来进入Kad网络的，相当于Bt下载中通过router来加入DHT网络。

  注：在eMule具体的实现过程中，采用的ID是28bit。

例如：找到用户小则是通过将用户id异或的方式，两个id的二进位异或值决定他们之间的逻辑距离，如00距离0要比距离00近。

那么当一个用户加入kad后，首先通过一个已知的用户找到一批用户的id和ip地址和端口。

当该用户要寻找一个特定用户A的时候，该用户先询问几个已知的逻辑距离较A较近的用户，如B用户,C用户,D用户，B，C，D会告诉该用户他们知道的更加近的用户的id和ip地址和端口，同理类推，这个用户最终就能找到A。

所以寻找的次数会在logN数量级，这里N代表询问的人数。

 最令人遗憾的是BT和eMule中的DHT算法无法互通和兼容！ 注：在Kad网络中，系统存储的数据以对形式存放。

在BT的DHT实现中，其key值为torrent文件的info_hash串，其value值则和torrent文件有密切关系。

  DHT技术的缺点和发展存在的问题 1.节点频繁加入和离开引起网络波动；网络波动的程度严重影响发现算法的效率。

网络波动（Churn、fluctuation of network）包括结点的加入、退出、失败、迁移、并发加入过程、网络分割等。

DHT的发现算法如Chord、CAN、Koorde等都是考虑网络波动的最差情况下的设计与实现。

由于每个结点的度数尽量保持最小，这样需要响应的成员关系变化的维护可以比较小，从而可以快速恢复网络波动造成的影响。

但是每个结点仅有少量路由状态的代价是发现算法的高延时，因为每一次查找需要联系多个结点。

  2.DHT算法由于采用分布式散列函数，只适合于准确的查找，如果要支持目前Web搜索引擎具有的多关键字查找的功能，还要引入新的方法。

原因在于DHT工作方式:  基于DHT的P2P系统采用相容散列函数根据精确关键词进行对象的定位与发现。

散列函数总是试图保证生成的散列值均匀随机分布，结果两个内容相似度很高但不完全相同的对象被生成了完全不同的散列值，存放到了完全随机的两个节点上。

因此，DHT可以提供精确匹配查询，但是支持语义是非常困难的。

目前在DHT基础上开展带有语义的资源管理技术的研究还非常少。

由于DHT的精确关键词映射的特性决定了无法和信息检索等领域的研究成果，阻碍了基于DHT的P2P系统的规模应用。

作为一种资源组织与发现技术必然要支持复杂的查询，如关键词、内容查询等。

尽管信息检索和数据挖掘领域提供了量成熟的语义查询技术，由于DHT精确关键词映射的特性阻碍了DHT在复杂查询方面的应用。

 3.DHT的安全性：比如节点之间通迅和查找分工没有适当安全认证机制，存在很多安全隐患    当前下载软件的发展趋势就是集成各种协议，打通各种协议的下载（BT、ED2K（eMule）、HTTP、FTP、MMS、RTSP协议），脱兔、迅雷已经做了一部分这样的工作，但是实际效果并不好。

资源下载工具的用户并不关心资源是以什么协议方式在网络上发布的，用户的期望在于拥有相应的权限都可以下载，所有协议之间的隔阂被打通。

下载工具成为向互联网获取资源、同时也是向互联网提供资源的平台。


** wireshark
*** filt
@wireshark  @ethereal

搜索：
The Wireshark Wiki
登录
CaptureFilters

    * FrontPage
    * RecentChanges
    * FindPage
    * HelpContents
    * CaptureFilters

    * 只读网页
    * 备注
    * 信息
    * 附件
    *

CaptureFilters

An overview of the capture filter syntax can be found in the User's Guide. A complete reference can be found in the expression section of the tcpdump manual page.

Wireshark uses the same syntax for capture filters as tcpdump, WinDump, Analyzer, and any other program that uses the libpcap/WinPcap library.

If you need a capture filter for a specific protocol, have a look for it at the ProtocolReference.

目录

   1. CaptureFilters
         1. Examples
         2. Useful Filters
         3. Default Capture Filters
         4. Further Information
         5. See Also
         6. Discussion

Examples

Capture only traffic to or from IP address 172.18.5.4:

    *

      host 172.18.5.4

Capture traffic to or from a range of IP addresses:

    *

      net 192.168.0.0/24

or

    *

      net 192.168.0.0 mask 255.255.255.0

Capture traffic from a range of IP addresses:

    *

      src net 192.168.0.0/24

or

    *

      src net 192.168.0.0 mask 255.255.255.0

Capture traffic to a range of IP addresses:

    *

      dst net 192.168.0.0/24

or

    *

      dst net 192.168.0.0 mask 255.255.255.0

Capture only DNS (port 53) traffic:

    *

      port 53

Capture non-HTTP and non-SMTP traffic on your server (both are equivalent):

    *

      host www.example.com and not (port 80 or port 25)

      host www.example.com and not port 80 and not port 25

Capture except all ARP and DNS traffic:

    *

      port not 53 and not arp

Capture traffic within a range of ports

    *

      (tcp[0:2] > 1500 and tcp[0:2] < 1550) or (tcp[2:2] > 1500 and tcp[2:2] < 1550)

or, with newer versions of libpcap (0.9.1 and later):

    *

      tcp portrange 1501-1549

Capture only Ethernet type EAPOL:

    *

      ether proto 0x888e

Reject ethernet frames towards the Link Layer Discovery Protocol Multicast group:

    *

      not ether dst 01:80:c2:00:00:0e

Capture only IP traffic - the shortest filter, but sometimes very useful to get rid of lower layer protocols like ARP and STP:

    *

      ip

Capture only unicast traffic - useful to get rid of noise on the network if you only want to see traffic to and from your machine, not, for example, broadcast and multicast announcements:

    *

      not broadcast and not multicast

Capture HTTP GET requests. This looks for the bytes 'G', 'E', 'T', and ' ' (hex values 47, 45, 54, and 20) just after the TCP header. "tcp[12:1] & 0xf0) >> 2" figures out the TCP header length. From Jefferson Ogata via the [http://seclists.org/tcpdump/2004/q4/95|tcpdump-workers mailing list].

    *

      port 80 and tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420

Useful Filters

Blaster and Welchia are RPC worms. (Does anyone have better links, i.e. ones that describe or show the actual payload?)

Blaster worm:

    *

      dst port 135 and tcp port 135 and ip[2:2]==48

Welchia worm:

    *

      icmp[icmptype]==icmp-echo and ip[2:2]==92 and icmp[8:4]==0xAAAAAAAA

      The filter looks for an icmp echo request that is 92 bytes long and has an icmp payload that begins with 4 bytes of A's (hex). It is the signature of the welchia worm just before it tries to compromise a system. 

Many worms try to spread by contacting other hosts on ports 135, 445, or 1433. This filter is independent of the specific worm instead it looks for SYN packets originating from a local network on those specific ports. Please change the network filter to reflect your own network.

dst port 135 or dst port 445 or dst port 1433  and tcp[tcpflags] & (tcp-syn) != 0 and tcp[tcpflags] & (tcp-ack) = 0 and src net 192.168.0.0/24

Default Capture Filters

Wireshark tries to determine if it's running remotely (e.g. via SSH or Remote Desktop), and if so sets a default capture filter that should block out the remote session traffic. It does this by checking environment variables in the following order:

*

Environment Variable
	

Resultant Filter

SSH_CONNECTION
	

not (tcp port srcport and addr_family host srchost and tcp port dstport and addr_family host dsthost)

SSH_CLIENT
	

not (tcp port srcport and addr_family host srchost and tcp port dstport)

REMOTEHOST
	

not addr_family host host

DISPLAY
	

not addr_family host host

CLIENTNAME
	

not tcp port 3389

(addr_family will either be "ip" or "ip6")

Further Information

    *

      Filtering while capturing from the Wireshark User's Guide
    *

      The tcpdump man page includes a comprehensive capture filter reference
    *

      The Mike Horn Tutorial gives a good introduction to capture filters
    *

      Capture and display filter Cheat sheets 

See Also

DisplayFilters: more info on filters while displaying, not while capturing

Discussion

BTW, the Symantec page says that Blaster probes 135/tcp, 4444/tcp, and 69/udp. Would

 (tcp dst port 135 or tcp dst port 4444 or udp dst port 69) and ip[2:2]==48

    *

      be a better filter? - Gerald Combs 

Q: What is a good filter for just capturing SIP and RTP packets?

A: On most systems, for SIP traffic to the standard SIP port 5060,

tcp port sip

should capture TCP traffic to and from that port,

udp port sip

should capture UDP traffic to and from that port, and

port sip

should capture both TCP and UDP traffic to and from that port (if one of those filters gets "parse error", try using 5060 instead of sip). For SIP traffic to and from other ports, use that port number rather than sip.

For RTP packets, you would have to determine one of the port numbers that would be used, and specify that port number.

link[0] != 0x80

capture WLAN traffic without Beacons

src net 192.168

Capture all traffic originating (source) in the IP range 192.168.XXX.XXX

    *

      CategoryHowTo

** wrt
*** 构建
**** 如何下载wrt工程
可以上www.openwrt.org这个网站上找到下载wrt工程的方法
•Backfire 10.03 branch:  ChangeLogg 
svn co svn://svn.openwrt.org/openwrt/branches/backfirbe

 •Kamikaze 8.09 branch:  ChangeLogs
svn co svn://svn.openwrt.org/openwrt/branches/8.09

 •Kamikaze 7.09 (deprecated):  ChangeLogs
svn co svn://svn.openwrt.org/openwrt/tags/kamikaze_7.09

 •Development branch:  ChangeLogs
svn co svn://svn.openwrt.org/openwrt/trunk/

 •Kamikaze packages:  ChangeLog 

*Note: Kamikaze only contains the essential set of packages, extra packages can be enabled with the command "make package/symlinks" or can be checked out from the following URL: 
svn co svn://svn.openwrt.org/openwrt/packages/

 •Updating to the latest sources: s
svn up

 •Switching from the prior to 2010 checkout procedure. The move from the past  https:// (webdav) URL to the  svn:// URL is done with a single command:
 svn switch --relocate https://svn.openwrt.org/openwrt svn://svn.openwrt.org/openwrt

 •If you prefer working with git, it is possible to use: 
 ◦ git://nbd.name/openwrt.git (clone of trunk)
 ◦ git://nbd.name/packages.git (clone of packages) 


**** 如何编译wrt工程
在wrt的工程中有packages的概念，packages不在trunk中维护，在编译的时候可以进行单独的拆卸，很棒的设计！
make deconfigure  这个是标准配置
make menuconfig   这个是进行自己配置
make V=99         这个把编译的细节全部打印出来
make              这个只显示主要的编译过程






* database
** orale
*** sql
**** 基本命令
一、SQL PLUS
1 引言

SQL命令
以下17个是作为语句开头的关键字：
alter  drop  revoke
audit  grant  rollback*
commit*  insert  select
comment  lock  update
create  noaudit  validate
delete  rename
这些命令必须以“;”结尾
带*命令句尾不必加分号，并且不存入SQL缓存区。

SQL中没有的SQL*PLUS命令
这些命令不存入SQL缓存区
@  define  pause
#  del  quit
$  describe  remark
/  disconnect  run
accept  document  save
append  edit  set
break  exit  show
btitle  get  spool
change  help  sqlplus
clear  host  start
column  input  timing
compute  list  ttitle
connect  newpage  undefine
copy

-------
2 数据库查询

数据字典
TAB 用户创建的所有基表、视图和同义词清单

DTAB 构成数据字典的所有表

COL 用户创建的基表的所有列定义的清单

CATALOG 用户可存取的所有基表清单

select from tab;

describe命令 描述基表的结构信息
describe dept

select 
from emp;

select empno,ename,job
from emp;

select from dept
order by deptno desc;

逻辑运算符
= !=或<> > >= < <=
in
between value1 and value2
like
%
_
in null
not
no in,is not null

谓词in和not in
有哪些职员和分析员
select ename,job
from emp
where job in ('clerk','analyst');

select ename,job
from emp
where job not in ('clerk','analyst');

谓词between和not between
哪些雇员的工资在2000和3000之间
select ename,job,sal from emp
where sal between 2000 and 3000;

select ename,job,sal from emp
where sal not between 2000 and 3000;

谓词like,not like
select ename,deptno from emp
where ename like 'S%';
(以字母S开头)
select ename,deptno from emp
where ename like '%K';
(以K结尾)
select ename,deptno from emp
where ename like 'W___';
(以W开头，后面仅有三个字母)
select ename,job from emp
where job not like 'sales%';
(哪些雇员的工种名不以sales开头)

谓词is null,is not null
没有奖金的雇员（即commision为null）
select ename,job from emp
where comm is null;

select ename,job from emp
where comm is not null;

多条件查询
select ename,job
from emp
where deptno=20
and job!='clerk';

表达式
/

算术表达式
选择奖金高于其工资的5%的雇员
select ename,sal,comm,comm/sal from emp
where comm>.05*sal
  order by comm/sal desc;

日期型数据的运算
add two days to 6Mar-87
6-Mar-87 2 = 8-Mar-87
add two hours to 6-Mar-87
6-Mar-87 2/24 = 6-Mar-87 and 2hrs
add 15 seconds to 6-Mar-87
6-Mar-87 15/(24*60*60) = 6-Mar-87 and 15 secs

列名的别名
select ename employee from emp
  where deptno=10;
（别名：employee）
select ename,sal,comm,comm/sal "C/S RATIO" from emp
  where comm>.05*sal
  order by comm/sal desc;

SQL命令的编辑
list or l 显示缓冲区的内容
list 4 显示当前SQL命令的第4行，并把第4行作为当前行，在该行号后面有个*。
change or c 用新的内容替换原来在一行中第一次出现内容
SQL>c/(...)/('analyst')/
input or i 增加一行或多行
append or a 在一行后追加内容
del  删除当前行 删除SQL缓冲区中的当前行
run  显示并运行SQL缓冲区中的命令
/  运行SQL缓冲区中的命令
edit  把SQL缓冲区中的命令写到操作系统下的文本文件，
并调用操作系统提供的编辑器执行修改。

-----------
3 数据操纵
数据的插入
insert into dept
  values (10,'accounting','new york');

insert into dept (dname,deptno)
  values ('accounting',10);

从其它表中选择插入数据
insert into emp (empno,ename,deptno)
select id,name,department
from old_emp
where department in(10,20,30,40);

使用参数
insert into dept
  values(&deptno,&dname,&loc);
执行时，SQL/PLUS对每个参数将有提示用户输入

参数对应日期型或字符型数据时，可在参数上加引号，输入时就可不用引号
insert into dept
  values(&deptno,'&dname','&loc');

插入空值（NULL）
insert into dept
  values(50,'education',null);

插入日期型数据
日期型数据缺省格式：DD-MON-YY
insert into emp
(empno,ename,hiredate)
values(7963,'stone','07-APR-87');

系统时间：SYSDATE
insert into emp
(empno,ename,hiredate)
values(7600,'kohn',SYSDATE);

数据更新
update emp
set job='manager'
where ename='martin';

update emp
set job='market rep'
where ename='salesman';

update emp
set deptno=40,job='market rep'
where job='salesman';

数据删除
delete emp
where empno=765;

更新的提交
commit

自动提交方式
set autocommit on
如果状态设为开，则使用inesrt,update,delete会立即提交。

更新取消
rollback

两次连续成功的commit之间的操作，称为一个事务

-------------
4  创建基表、视图
创建基表
create table dept
(deptno number(2),
dname char(14),
loc char(13));

数据字典会自动更新。
一个基表最多254列。

表名列名命名规则：
限制
第一个字符必须是字母，后面可任意（包括 $ # 但不能是逗号）。
名字不得超过30个字符。

唯一
某一用户的基表名必须唯一，不能是ORACLE的保留字，同一基表的列名互不相同。

使用双引号
如果表名用双引号括起来，则可不满足上述规则；
只有使用双引号，才能区别大、小写；
命名时使用了双引号，在以后的操作也必须使用双引号。

数据类型：
char(n)    （不得超过240字符）
number(n,d)
date
long    （最多65536字符）
raw    （二进制原始数据）

空值处理
有时要求列值不能为空
create table dept
(deptno number(2) not null,
dname char(14),
loc char(13));

在基表中增加一列
alter table dept
add (headcnt number(3));

修改已有列属性
alter table dept
modify dname char(20);
注：只有当某列所有值都为空时，才能减小其列值宽度。
只有当某列所有值都为空时，才能改变其列值类型。
只有当某列所有值都为不空时，才能定义该列为not null。
例：
alter table dept modify (loc char(12));
alter table dept modify loc char(12);
alter table dept modify (dname char(13),loc char(12));

创建视图
create view managers as
select ename,job,sal
from emp
where job='manager';

为视图列名取别名
create view mydept
(person,title,salary)
as select ename,job,sal
from emp
where deptno=10;

with check option选项
使用with check option，保证当对视图插入或更新数据时，
该数据必须满足视图定义中select命令所指定的条件。
create view dept20 as
select ename,job,sal,deptno
from emp
where deptno=20
with check option;
在做下述操作时，会发生错误
update dept20
set deptno=30
where ename='ward';

基表、视图的拷贝
create table emp2
as select from emp;

基表、视图的删除
drop table 表名
drop view 视图名

----------
5 SQLPLUS报表功能
SQL*PLUS的一些基本格式命令
column deptno heading department

column ename heading name

column sal heading salary

column sal format $99,999.00

ttitle sample report for|hitech corp

btitle strictly confidential

break on deptno

compute sum of sal on deptno

run

表头和表尾
ttitle sample report for|hitech corp
btitle right strictly confidential

“|”表示换行，结尾不必加分号
选项有三种：left right center

使用TTITLE，系统将自动地在每页的顶部显示日期和页号。
TTITLET和BTITLE命令有效，直至重新设置表头或表尾，或退出SQL*PLUS。

下面命令使标题语句失效
TTITLE OFF
BTITLE OFF

列名
column命令定义用于显示列名
若名字为一个单词，不必加引号
column ename heading employee

column ename heading 'employee|name'
（|为换行）

取消栏定义
column ename clear

列的格式
column ename format A15

column sal format $9,999.99

column comm like sal

like子句，使得某一列的格式参照另一列格式，它拷贝列名及其格式

控制记录显示分组顺序
break on deptno
（不显示重复值）

select deptno,ename
from emp
order by deptno;
（ORDER BY子句用于控制BREAK）

显示为
10 clark
   niller
20 smith
   scott
30 allen
   blake

每次只有一个BREAK命令起作用，但一次可以在多个列上使用BREAK命令
break on 列名1 on 列名2

记录分组
break on deptno skip 2
select deptno,ename
from emp
order by deptno;

每个deptno之间空两行
clear break（取消BREAK命令）
break on page（每次从一新页开始）
break on report（每次从一新报表开始）
break on page on report（联合使用）

分组计算
break on deptno skip 2
compute sum of sal on deptno
计算每个部门的工资总和
skip子句使部门之间的信息分隔开

其他计算命令
compute avg of sal on deptno（平均值）
count 非空值的总数
MAX 最大值
MIN 最小值
STD 标准偏差
VAR 协方差
NUMBER 行数

使compute命令失效
一旦定义了COMPUTE，则一直有效，直到
关闭COMPUTE（clear compute）

SQL/PLUS环境命令
show 选项
（显示当前参数设置情况）

show all（显示全部参数）

设置参数
set 选项 值或开关

set autocommit on

SET命令包括
set autocommit {off|on|immediate}
（自动提交，OFF缺省）

set echo {off|on}
（命令文件执行，是否在终端上显示命令本身，OFF缺省）

set feedback {off|on}
（ON：查询结束时，给出结果，记录数的信息，缺省；
OFF：无查询结果，记录数的信息）

set heading {off|on}
（ON：列的头标在报表上显示，缺省；OFF：不在报表上显示）

set linesize {n}
一行显示的最大字符数，缺省为80

set pagesize {n}
每页的行数，缺省是14

set pause {off|on|text}
（ON：当报表超过一页时，每显示一屏就暂停显示，等待用户打回车键，再接着显示；
OFF：页与页不停顿，缺省；text：页与页停顿，并向用户提示信息）

SET BUFFER buffer
设置当头的命令缓冲区，通常情况下，SQL命令缓冲区已为当前缓冲区。
由于SQL命令缓冲区只能存放一条SQL命令，
所以可用其它缓冲区来存放SQL命令和SQL*PLUS命令。

经常用到的设置可放在login.sql文件中。

SET NULL
set null 'no data'

select ename,comm
from emp
where deptno=30;
把部门30中无佣金雇员的佣金显示为“NO DATA”。

set null是SQL*PLUS命令，用它来标识空值（NULL），可以设置为任意字符串。

存盘命令SAVE
save 文件名

input
1 select empno,ename,job
2 from emp
3 where job='analyst'

save research

目录中会增加一个research.sql文件。

编辑命令EDIT
edit

EDIT编辑当前缓冲区中的内容。

编辑一个文件
edit research

调入命令GET
get research
把磁盘上的文件内容调入缓冲区，并显示在屏幕上，文件名尾不必加.sql。

START命令
运行指定的文件
start research

输出命令SPOOL
spool tryfile
不仅可以使查询结果在屏幕上显示，还可以使结果存入文件

停止向文件输出
spool off

把查询结果在打印机上输出，先把它们存入一个文件中，
然后不必使用SPOOL OFF，而用：
spool out
SPOOL OUT关闭该文件并在系统缺省的打印机上输出

制作报表举例
edit tryfile

set echo off
set autocommit on
set pagesize 25
insert into emp (empno,ename,hiredate)
  values(9999,'geiger',sysdate);
insert into emp (empno,ename,deptno)
  values(3333,'samson',20);
spool newemp
select from emp
  where deptno=20
or deptno is null
/
spool off
set autocommit off

用start命令执行这个文件

------
6 函数
字符型函数
initcap(ename);将ename中每个词的第一个字母改为大写。
如：jack smith--Jack Smith

length(ename);计算字符串的长度。

substr(job,1,4);

其它
lower
upper
least 取出字符串列表中按字母排序排在最前面的一个串
greatest 取出字符串列表中按字母排序排在最后的一个串

日期函数
add_month(hiredate,5) 在雇佣时间上加5个月
month_between(sysdate,hiredate) 计算雇佣时间与系统时间之间相差的月数
next_day(hiredate,'FRIDAY') 计算受雇日期之后的第一个星期五的日期

例
select ename,sal,next_day(sysdate,'FRIDAY') as_of
from emp
where deptno=20;
（as_of是别名）

如果不用to_char函数，日期在ORACLE中的缺省格式是'DD_MON_YY'
to_char(date,date picture)

select ename,to_char(hiredate,'Dy Mon dd,yyyy') hired
from emp
where deptno=10;

to_date(字符串,格式)

insert into emp(empno,ename,hiredate)
values(7999,'asms',to_date('070387083000','MMDDYYHHMISS'));

日期型数据的格式
dd 12
dy fri
day friday
ddspth twelfth

mm 03
mon mar
month march

yy 87
yyyy 1987

例
Mar 12,1987    'Mon dd,yyyy'
MAR 12,1987    'MON dd,yyyy'
Thursday MARCH 12    'Day MONTH dd'
Mar 12 11:00am    'Mon dd hh:miam'
Thu,the twelfth    'Dy,"the"ddspth'

算术函数
least(v1,v2)

select ename,empno,mgr,least(empno,mgr) lownum
from emp
where empno0

trunc(sal,0)
取sal的近似值（截断）

空值函数
nvl(v1,v2)
v1为列名，如果v1不是空值，nvl返回其列值。
v1为空值，返回v2的值。

聚组函数
select sum(comm)
from emp;
（返回一个汇总信息）
不能把sum用在select语句里除非用group by

字符型、日期型、数字型的聚组函数
min max count可用于任何数据类型

select min(ename)
from emp;

select min(hiredate)
from emp;

select min(sal)
from emp;

有多少人有工作？
select count(job)
from emp;

有多少种不同的工种？
select count(distinct job)
from emp;

count distinct 计算某一字段中不同的值的个数

其它聚组函数（只用于数字型数据）
avg 计算平均工资
select avg(sal)
from emp;

stddev 计算工资的平均差
select stddev(sal)
from emp;

sum 计算总工资
select sum(sal)
from emp;

group by子句
select deptno,sum(sal),avg(sal)
from emp
group by deptno;

按多个条件分组
每个部门的雇员数
select deptno,count()
from emp
group by deptno;

每个部门的每个工种的雇员数
select deptno,job,count(*)
from emp
group by deptno,job;

满足条件的分组
（where是针对select的，having是针对group by的）
哪些部门的工资总和超过了9000
select deptno,sum(sal)
from emp
group by deptno
having sum(sal)>9000;

select小结
除去职员，哪些部门的工资总和超过了8000
select deptno,sum(sal)
from emp
where job!='clerk'
group by deptno
having sum(sal)>8000
order by sum(sal);

-------
7 高级查询
等值联接
select empno,ename,job,emp.deptno,dname
from emp,dept
where emp.deptno=dept.deptno;

外联接
select ename,dept.deptno,loc
from emp,dept
where emp.deptno(+)=dept.deptno;
如果在dept.deptno中有的数值，在emp.deptno中没有（如deptno=40），
则作外联接时，结果中会产生一个空值

自联接：同一基表的不同行要做联接，可使用自联接
指出每个雇员的经理名字
select worker.ename,manager.ename manager
from emp worker,emp manager
where worker.mgr=manager.empno;

非等值联接
哪些雇员的工资属于第三级别
select ename,sal
from emp,salgrade
where grade=3
and sal between losal and hisal;
（基表salgrade：grade losal hisal）

集合运算
行的连接
集合运算把2个或多个查询结果合并为一个
union-set union
Rows of first query plus of second query, less duplicate rows

intersect-set intersection
Rows both queries have in common

minus-set difference
rows unique to the first query

介绍几个视图
account view
ename sal job

sales view
ename sal job

research view
ename sal job

union运算
返回一个查询结果中有但又不重要的行，它将基表或视图中的记录合并在一起
所有部门中有哪些雇员工资超过2000
对应列的数据类型必须相同
select ename,sal
from account
where sal>2000
union
select ename,sal
from research
where sal>2000
union
select ename,sal
from sales
where sal>2000;

intersect运算
返回查询结果中相同的部分
各个部门中有哪些相同的工种
select job
from account
intersect
select job
from research
intersect
select job
from sales;

minus运算
返回在第一个查询结果中与第二个查询结果不相同的那部分行记录。
有哪些工种在财会部中有，而在销售部中没有？
select job from account
minus
select job from sales;

子查询
slect ename,deptno
from emp
where deptno=
(select deptno
from emp
where ename='smith');

多级子查询
select ename,job,sal
from emp
where job=
(select job
from emp
where ename='clark')
or sal>
(select sal
from emp
where ename='clark');

多个基表与子查询
select ename,job,sal
from emp,dept
where loc='new york'
and emp.deptno=dept.deptno
and sal>
(select sal
from emp
where ename='scott');

子查询中使用聚组函数
select ename,hiredate
from emp
where hiredate=
(select min(hiredate)
from emp);

8 授权
系统权限
DBA 所有权限
RESOURCE 注册，创建新的基表
CONNECT，注册，查询

只有DBA才有权创建新的用户
grant connect to scott
identified by tiger;

DBA或用户自己可以改变用户口令
grant connect to scott
identified by leopard;

基表权限1
有两种方法获得对基表操作的权限

创建自己的基表
获得基表创建用户的许可
grant select,insert
on emp
to scott;

这些权限有
select insert update delete alter index

把所有权限授于他人
grant all on emp to scott;

同义词
select 
from scott.emp

创建同义词
为用户allen的EMP基表创建同义词employee
create synonym employee
for allen.emp

基表权限2
你可以使其他用户有这样的权力，即其他用户可以把你的基表权限授予他人
grant all
on emp
to scott
with grant option;

收回权限
系统权限 只有被DBA收回

基表权限 随时都可以收回

revoke insert
on emp
from scott;

-------
9 索引
建立索引
create index emp_ename
on emp(ename);

删除索引
drop index emp_ename;

关于索引
只对较大的基表建立索引（至少50条记录）
建立索引之前插入数据
对一个基表可建立任意多个索引
一般是在作为主键的列上建立索引
建立索引之后，不影响SQL命令的执行
建立索引之后，ORACLE自动维护和使用索引

保证数据唯一性
提高执行速度的同时，索引还可以保证每个记录中的每个列值是不重复的。
create unique index emp_empno
on emp(empno);

------
练习和答案

有没有工资比奖金多的雇员？如果有，按工资的降序排列。
如果有两个以上的雇员工资相同，按他们的名字排序。
select ename employee,sal salary,comm commision
from emp
where sal>comm
order by sal desc,ename;

列出有关雇员姓名、奖金占收百分比的信息。
要求显示时列名意义明确，按雇员姓名排序，不包括奖金未知的雇员。
select ename employee,(comm/(comm+sal))100 incentive
from emp
where comm is not null
order by ename;

在chicago（部门30）工作的所有雇员的工资上涨10%。
update emp
set sal=1.1*sal
where deptno=30;

update emp
set sal=1.1*sal
where deptno=(select deptno
from dept
where loc='chicago');

为hitech公司新建一个部门，编号为50，其它信息均不可知。
insert into dept(dname,deptno)
values('faclities',50);

创建视图，三个列名，其中不包括职员信息
create view employee("employee name",
"employee number",
"employee job")
as select ename,empno,job
from emp
where job!='clerk';

制作工资报表，包括雇员姓名、受雇时间（按星期计算），工资和部门编号，
一页显示一个部门的信息，每页尾，显示该页的工资之和以及受雇时间之和，
报表结尾处，显示所有雇员的工资总和以及受雇时间总和，
工资按美元计算，受雇时间按星期计算，每页的上方应有标题。
ttitle 'service'
break on deptno on page on report
compute sum of sal on deptno
compute sum of sal on report
compute sum of service_length on deptno
compute sum of service_length on report
column sal format $99,999.00
column service_length format 9999
select deptno,ename employee,(sysdate-hiredate)/7 service_length,sal
from emp
order by deptno;

制作报表，包括雇员姓名、总收入和受佣日期，
且：姓名的第一个字母必须大写，雇佣日期格式为MM/DD/YYYY，
总收入包括没有奖金的雇员的总收入，姓名按字母顺序排列。
col "hire date"format A12
col "employee" format A10
col "compensation" format $99,999.00
select initcap(ename) "employee",
(sal+nvl(comm,0)) "compensation",
to_char(hiredate,'MM/DD/YYYY') "hire date"
from emp
order by ename;

列出有超过7个周边国家的国家名字和面积。
select nation,area
from nation
where code in
(select nation_code
from border
group by nation_code
having count(*)>7);

列出所有面积大于等于日本的岛国的国名和人口。
select nation,population
from nation,border
where code=nation_code(+)
and nation_code is null
and area>=
(select area
from nation
where upper(nation)='JAPAN');

列出所有边界在其它国家中的国名，并且显示其边界国家名字。
break on nation
select nation1.nation,
nation2.nation borderin_country
from nation nation1,border,nation nation2
where nation1.code=border.nation_code
and border.border_code=nation2.code
order by nation1.nation;

---------
---------
PL/SQL

2 PL/SQL的块结构和数据类型

块结构的特点
嵌套
begin
......
  begin
  ......
  exception
  ......
  end;
exception
......
end;

标识符：
不能超过30个字符
第一个字符必须为字母
其余字符可以是字母，数字，$，_，或#
不区分大小写形式
如果用双引号括起来，则字符顺序可以任意排列，并区分大小写形式
无SQL保留字

数据类型
数字型：
整数，实数，以及指数

字符串：
用单引号括起来
若在字符串表示单引号，则使用两个单引号
字符串长度为零（两个单引号之间没有字符），则表示NULL

字符：
长度为1的字符串

数据定义
语法
标识符[常数] 数据类型[NOT NULL][:=PL/SQL表达式];
':='表示给变量赋值

数据类型包括
数字型 number(7,2)
字符型 char(120)
日期型 date
布尔型 boolean（取值为true,false或null，不存贮在数据库中）

日期型
anniversary date:='05-JUL-95';
project_completion date;

布尔型
over_budget boolean not null:=false;
available boolean;
（初始值为NULL）

%type类型匹配
books_printed number(6);
books_sold book_printed%type;
manager_name emp.ename%type;

变量赋值
变量名:=PL/SQL表达式
numvar:=5;
boolvar:=true;
datevar:='11-JUN-87';

字符型、数字型表达式中的空值
null+<数字>=null（空值加数字仍是空值）
null><数字>=null（空值与数字进行比较，结果仍是空值）
null||'字符串'='字符串'（null即''）
（空值与字符串进行连接运算，结果为原字符串）

变量作用范围
标识符在宣言它的块中有效
标识符如果不在子块中重新定义，则在PL/SQL块的所有子块中同样有效
重新定义后的标识符，作用范围仅在本子块中有效

例
declare
  e_mess char(80);
begin
  /*子块1*/
  declare
    v1 number(4);
  begin
    select empno into v1 from emp
    where job='president';
  exception
    when too_many_rows then
      insert into job_errors
      values('more than one president');
  end;
  /*子块2*/
  declare
    v1 number(4);
  begin
    select empno into v1 from emp
    where job='manager';
  exception
    when too_many_rows then
      insert into job_errors
      values('more than one manager');
  end;
exception
  when others then
    e_mess:=substr(sqlerrm,1,80);
    insert into general errors values(e_mess);
end;

-------
3 SQL和PL/SQL

插入
declare
  my_sal number(7,2):=3040.55;
  my_ename char(25):='wanda';
  my_hiredate date:='08-SEP-88';
begin
  insert into emp
  (empno,enmae,job,hiredate,sal,deptno)
  values(2741,my_ename,'cab driver',my_hiredate,my_sal,20);
end;

删除
declare
  bad_child_type char(20):='naughty';
begin
  delete from santas_gift_list where
  kid_rating=bad_child_type;
end;

事务处理
commit[WORK];
rollback[WORK];
（关键字WORK可选，但对命令执行无任何影响）
savepoint 标记名;（保存当前点）
在事务中标记当前点
rollback [WORK] to [SAVEPOINT] 标记名;（回退到当前保存点）
取消savepoint命令之后的所有对数据库的修改
关键字WORK和SAVEPOINT为可选项，对命令执行无任何影响

函数
PL/SQL块中可以使用SQL命令的所有函数
insert into phonebook(lastname) value(upper(my_lastname));
select avg(sal) into avg_sal from emp;

对于非SQL命令，可使用大多数个体函数
不能使用聚组函数和参数个数不定的函数，如
x:=sqrt(y);
lastname:=upper(lastname);
age_diff:=months_between(birthday1,birthday2)/12;

赋值时的数据类型转换
4种赋值形式:
变量名:=表达式
insert into 基表名 values(表达式1,表达式2,...);
update 基表名 set 列名=表达式;
select 列名 into 变量名 from ...;

数据类型间能进行转换的有:
char转成number
number转成char
char转成date
date转成char

例
char_var:=nm_var;
数字型转换成字符型
date_var:='25-DEC-88';
字符型转换成日期型
insert into 表名(num_col) values('604badnumber');
错误，无法成功地转换数据类型

-------
4 条件控制
例
declare
  num_jobs number(4);
begin
  select count(*) into num_jobs from auditions
  where actorid=&&actor_id and called_back='yes';
  if num_jobs>100 then
    update actor set actor_rating='word class'
    where actorid=&&actor_id;
  elsif num_job=75 then
    update actor set actor_rating='daytime soaps'
    where actorid=&&actor_id;
  else
    update actor set actor_rating='waiter'
    where actorid=&&actor_id;
  end if;
  end if;
  commit;
end;

------
5 循环
语法
loop
......
end loop;
exit;（退出循环）
exit [when];（退出循环，当满足WHEN时）
例1
declare
  ctr number(3):=0;
begin
  loop
    insert into table1 values('tastes great');
    insert into table2 values('less filling');
    ctr:=ctr+1;
  exit when ctr=100;
  end loop;
end;
（注：如果ctr取为NULL，循环无法结束）

例2
FOR语法
for 变量<范围> loop
......
end loop;

declare
  my_index char(20):='fettucini alfredo';
  bowl char(20);
begin
  for my_index in reverse 21..30 loop
  insert into temp(coll) values(my_index);
  /*循环次数从30到21*/
  end loop;
  bowl:=my_index;
end;
跟在in reverse后面的数字必须是从小到大的顺序，必须是整数，不能是变量或表达式

--------
6 游标
显式游标

打开游标
open <游标名>
例
open color_cur;

游标属性
%notfound
%found
%rowcount
%isopen
例
fetch my_cur into my_var;
while my_cur %found loop
  (处理数据)
  fetch my_cur into my_var;
  exit when my_cur %rowcount=10;
end loop;

%notfound属性
取值情况如下：
fetch操作没有返回记录，则取值为true
fetch操作返回一条记录，则取值为false
对游标无fetch操作时，取值为null
<游标名> %notfound
例
if color_cur %notfound then...
注：如果没有fetch操作，则<游标名> %notfound将导致出错，
因为%notfound的初始值为NULL。

关闭游标
close <游标名>
例
close color_cur;

游标的FOR循环
语法
for <记录名> in <游标名> loop
<一组命令>
end loop;
其中：
索引是建立在每条记录的值之上的
记录名不必声明
每个值对应的是记录名，列名
初始化游标指打开游标
活动集合中的记录自动完成FETCH操作
退出循环，关闭游标

隐式游标
隐式游标是指SQL命令中用到的，没有明确定义的游标
insert,update,delete,select语句中不必明确定义游标
调用格式为SQL%
存贮有关最新一条SQL命令的处理信息

隐式游标的属性
隐式游标有四个属性
SQL%NOTFOUND
SQL%FOUND
SQL%ROWCOUNT：隐式游标包括的记录数
例：
delete from baseball_team where batting_avg<100;
if sql%rowcount>5 thn
  insert into temp
  values('your team needs help');
end if;

SQL%ISOPEN：取值总为FALSE。SQL命令执行完毕，PL/SQL立即关闭隐式游标。


7 标号
GOTO语句
用法：
goto you_are_here;
其中you_are_here是要跳转的语句标号
标号必须在同一组命令，或是同一块中使用

正确的使用
<>（标号）
x:=x+1
if a>b then
b:=b+c;
goto dinner;
end if;

错误的使用
goto jail;
if a>b then
b:=b+c;
<>（标号）
x:=x+1;
end if;

标号：解决意义模糊
标号可用于定义列值的变量
<>
declare
deptno number:=20;
begin
  update emp set sal=sal*1.1
  where deptno=sample.deptno;
  commit;
end sample;
如果不用标号和标号限制符，这条命令将修改每条记录。

--------
8 异常处理
预定义的异常情况
任何ORACLE错误都将自动产生一个异常信息
一些异常情况已命名，如：
no_data_found 当SELECT语句无返回记录时产生
too_many_rows 没有定义游标，而SELECT语句返回多条记录时产生
whenever notfound 无对应的记录

用户定义的异常情况
由用户自己获取
在DECLARE部分定义：
declare
  x number;
  something_isnt_right exception;
用户定义的异常情况遵循一般的作用范围规则
条件满足时，获取异常情况：raise something_isnt_right
注意：同样可以获取预定义的异常情况

exception_init语句
允许为ORACLE错误命名

调用格式：
pragma exception_init(<表达式>,);
例
declare
  deadlock_detected exception;
  pragma exception_init(deadlock_detected,-60);

raise语句
单独使用RAISE命令，可再一次获取当前的异常情况（就象异常情况被重复处理了一样）。
在异常处理中，此语句只能单独使用。

异常处理标识符
一组用于处理异常情况的语句：
exception
  when <表达式> or [表达式...] then
  <一组语句>
  ...
  when others then--最后一个处理
  <一组语句>
end;既结束PL/SQL块部分，也结束异常处理部分

------
练习与答案
1:
接收contract_no和item_no值，在inventory表中查找，如果产品：
已发货，在arrival_date中赋值为今天后的7天
已订货，在arrival_date中赋值为今天后的一个月
既无订货又无发货，则在arrival_date中赋值为今天后的两个月，
并在order表中增加一条新的订单记录。

product_status的列值为'shipped'和'ordered'

inventory:
product_id number(6)
product_description char(30)
product_status char(20)
std_shipping_qty number(3)

contract_item:
contract_no number(12)
item_no number(6)
arrival_date date

order:
order_id number(6)
product_id number(6)
qty number(3)

答案：
declare
i_product_id inventory.product_id%type;
i_product_description inventory.product_description%type;
i_product_status inventory.product_status%type;
i_std_shipping_qty inventory.std_shipping_qty%type;

begin
  select product_id,product_description,product_status,std_shipping_qty
  into i_product_id,i_product_description,
       i_product_status,i_std_shipping_qty
  from inventory
  where product_id=(
    select product_id
    from contract_item
    where contract_no=&&contractno and item_no=&&itemno);
  if i_product_status='shipped' then
    update contract_item
    set arrival_date=sysdate+7
    where item_no=&&itemno and contract_no=&&contractno;
  elsif i_product_status='ordered' then
      update contract_item
      set arrival_date=add_months(sysdate,1)
      where item_no=&&itemno and contract_no=&&contractno;
    else
      update contract_item
      set arrival_date=add_months(sysdate,2)
      where item_no=&&itemno and contract_no=&&contractno;
      insert into orders
      values(100,i_product_id,i_std_shipping_qty);
    end if;
  end if;
  commit;
end;


2:
1.找出指定部门中的所有雇员
2.用带'&'的变量提示用户输入部门编号
3.把雇员姓名及工资存入prnttable表中，基结构为：
create table prnttable
(seq number(7),line char(80));
4.异常情况为，部门中奖金不为空值的雇员信息才能存入prnttable表中。

答案：
declare
cursor emp_cur is
  select ename,sal,comm
  from emp where deptno=&dno;
emp_rec emp_cur%rowtype;
null_commission exception;
begin
  open emp_cur;
  fetch emp_cur into emp_rec;
  while (emp_cur%found) loop
    if emp_rec.comm is null then
    begin
    close emp_cur;
    raise null_commission;
    end;
    end if;
  fetch emp_cur into emp_rec;
  end loop;
  close emp_sur;
  exception
    when null_commission then
      open emp_cur;
      fetch emp_cur into emp_rec;
      while (emp_cur%found) loop
        if emp_rec.comm is not null then
          insert into temp values(emp_rec.sal,emp_rec.ename);
        end if;
        fetch emp_cur into emp_rec;
      end loop;
      close emp_cur;
      commit;
end 
*** 管理
**** 常用命令
第一章：日志管理
1.forcing log switches

sql> alter system switch logfile;

2.forcing checkpoints

sql> alter system checkpoint;

3.adding online redo log groups

sql> alter database add logfile [group 4]

sql> (''/disk3/log4a.rdo'',''/disk4/log4b.rdo'') size 1m;

4.adding online redo log members

sql> alter database add logfile member

sql> ''/disk3/log1b.rdo'' to group 1,

sql> ''/disk4/log2b.rdo'' to group 2;

5.changes the name of the online redo logfile

sql> alter database rename file ''c:/oracle/oradata/oradb/redo01.log''

sql> to ''c:/oracle/oradata/redo01.log'';

6.drop online redo log groups

sql> alter database drop logfile group 3;

7.drop online redo log members

sql> alter database drop logfile member ''c:/oracle/oradata/redo01.log'';

8.clearing online redo log files

sql> alter database clear [unarchived] logfile ''c:/oracle/log2a.rdo'';

9.using logminer analyzing redo logfiles

a. in the init.ora specify utl_file_dir = '' ''

b. sql> execute dbms_logmnr_d.build(''oradb.ora'',''c:oracleoradblog'');

c. sql> execute dbms_logmnr_add_logfile(''c:oracleoradataoradbredo01.log'',

sql> dbms_logmnr.new);

d. sql> execute dbms_logmnr.add_logfile(''c:oracleoradataoradbredo02.log'',

sql> dbms_logmnr.addfile);

e. sql> execute dbms_logmnr.start_logmnr(dictfilename=>''c:oracleoradblogoradb.ora'');

f. sql> select * from v$logmnr_contents(v$logmnr_dictionary,v$logmnr_parameters

sql> v$logmnr_logs);

g. sql> execute dbms_logmnr.end_logmnr;


第二章：表空间管理

1.create tablespaces

sql> create tablespace tablespace_name datafile ''c:oracleoradatafile1.dbf'' size 100m,

sql> ''c:oracleoradatafile2.dbf'' size 100m minimum extent 550k [logging/nologging]

sql> default storage (initial 500k next 500k maxextents 500 pctinccease 0)

sql> [online/offline] [permanent/temporary] [extent_management_clause]

2.locally managed tablespace

sql> create tablespace user_data datafile ''c:oracleoradatauser_data01.dbf''

sql> size 500m extent management local uniform size 10m;

3.temporary tablespace

sql> create temporary tablespace temp tempfile ''c:oracleoradatatemp01.dbf''

sql> size 500m extent management local uniform size 10m;

4.change the storage setting

sql> alter tablespace app_data minimum extent 2m;

sql> alter tablespace app_data default storage(initial 2m next 2m maxextents 999);

5.taking tablespace offline or online

sql> alter tablespace app_data offline;

sql> alter tablespace app_data online;

6.read_only tablespace

sql> alter tablespace app_data read only|write;

7.droping tablespace

sql> drop tablespace app_data including contents;

8.enableing automatic extension of data files

sql> alter tablespace app_data add datafile ''c:oracleoradataapp_data01.dbf''size 200m

sql> autoextend on next 10m maxsize 500m;

9.change the size fo data files manually

sql> alter database datafile ''c:oracleoradataapp_data.dbf''resize 200m;

10.Moving data files: alter tablespace

sql> alter tablespace app_data rename datafile ''c:oracleoradataapp_data.dbf''

sql> to ''c:oracleapp_data.dbf'';

11.moving data files:alter database

sql> alter database rename file ''c:oracleoradataapp_data.dbf''

sql> to ''c:oracleapp_data.dbf'';


第三章：表

1.create a table

sql> create table table_name (column datatype,column datatype]....)

sql> tablespace tablespace_name [pctfree integer] [pctused integer]

sql> [initrans integer] [maxtrans integer]

sql> storage(initial 200k next 200k pctincrease 0 maxextents 50)

sql> [logging|nologging] [cache|nocache]

2.copy an existing table

sql> create table table_name [logging|nologging] as subquery

3.create temporary table

sql> create global temporary table xay_temp as select * from xay;

on commit preserve rows/on commit delete rows

4.pctfree = (average row size - initial row size) *100 /average row size

pctused = 100-pctfree- (average row size*100/available data space)

5.change storage and block utilization parameter

sql> alter table table_name pctfree=30 pctused=50 storage(next 500k

sql> minextents 2 maxextents 100);

6.manually allocating extents

sql> alter table table_name allocate extent(size 500k datafile ''c:/oracle/data.dbf'');

7.move tablespace

sql> alter table employee move tablespace users;

8.deallocate of unused space

sql> alter table table_name deallocate unused [keep integer]

9.truncate a table

sql> truncate table table_name;

10.drop a table

sql> drop table table_name [cascade constraints];

11.drop a column

sql> alter table table_name drop column comments cascade constraints checkpoint 1000;

alter table table_name drop columns continue;

12.mark a column as unused

sql> alter table table_name set unused column comments cascade constraints;

alter table table_name drop unused columns checkpoint 1000;

alter table orders drop columns continue checkpoint 1000

data_dictionary : dba_unused_col_tabs


－－分析表
　　analyze table mzbs.db_code ESTIMATE STATISTICS SAMPLE 20 PERCENT;
　　
　　－－表空间管理和用户管理
　　
　　--查看表空间和数据文件
　　
　　select file_name,tablespace_name,autoextensible from dba_data_files;
　　
　　--数据表空间
　　
　　CREATE TABLESPACE USER_DATA
　　LOGGING
　　DATAFILE D:ORACLEORADATAORCL est.DBF SIZE 50m REUSE ,
　　c:USERS01112.DBF SIZE 50m REUSE
　　AUTOEXTEND
　　ON NEXT　1280K MAXSIZE　16383M EXTENT MANAGEMENT LOCAL
　　
　　--修改表空间数据文件的路径
　　
　　ALTER TABLESPACE app_data
　　RENAME
　　DATAFILE /DISK4/app_data_01.dbf
　　TO　 /DISK5/app_data_01.dbf;
　　
　　ALTER DATABASE
　　RENAME FILE /DISK1/system_01.dbf
　　TO /DISK2/system_01.dbf;
　　
　　--临时表空间
　　
　　CREATE TEMPORARY
　　TABLESPACE　USER_DATA_TEMP TEMPFILE D:TEMP0111.DBF
　　SIZE 50M REUSE AUTOEXTEND
　　ON NEXT　1024K MAXSIZE　16383M EXTENT MANAGEMENT LOCAL UNIFORM
　　SIZE 1024K
　　
　　--增加数据文件
　　
　　ALTER TABLESPACE　USER_DATA
　　ADD DATAFILE c:USERS01113.DBF SIZE 50M;
　　
　　ALTER TABLESPACE USER_DATA
　　ADD DATAFILE c:USERS01114.DBF　SIZE 50M
　　AUTOEXTEND ON
　　;
　　
　　--删除表空间
　　
　　DROP TABLESPACE USER_DATA INCLUDING CONTENTS;
　　
　　--修改表空间的存储参数
　　
　　ALTER TABLESPACE tablespacename
　　MINIMUM EXTENT 2M;
　　
　　ALTER TABLESPACE tablespacename
　　DEFAULT STORAGE (
　　INITIAL 2M
　　NEXT 2M
　　MAXEXTENTS 999 );
　　
　　--表空间联机/脱机/只读
　　
　　ALTER TABLESPACE tablespacename OFFLINE/ONLINE/READ ONLY;

--修改数据文件大小
　　ALTER DATABASE
　　DATAFILE c:USERS01113.DBF RESIZE 40M;
　　
　　--创建用户、赋予权限
　　
　　CREATE USER USER_DATA PROFILE DEFAULT IDENTIFIED BY　USER_DATA
　　DEFAULT
　　TABLESPACE USER_DATA　TEMPORARY
　　TABLESPACE USER_DATA　ACCOUNT UNLOCK;
　　
　　GRANT CONNECT TO USER_DATA;
　　GRANT RESOURCE TO USER_DATA;
　　
　　3、表的管理
　　
　　--创建表
　　
　　CREAE TABLE TABLENAME
　　(COLUMN1 COLUTYPE DEFAULT(VALUE) NOT NULL)
　　(COLUMN2 COLUTYPE DEFAULT(VALUE) NOT NULL);
　　
　　--建表的索引存储分配
　　
　　CREATE TABLE summit.employee(id NUMBER(7) CONSTRAINT employee_id_pk PRIMARY KEY DEFERRABLE USING INDEX　STORAGE(INITIAL 100K NEXT 100K)
　　TABLESPACE indx,
　　last_name VARCHAR2(25) CONSTRAINT employee_last_name_nn NOT NULL,
　　dept_id NUMBER(7))
　　TABLESPACE data;
　　
　　--修改表的存储分配
　　
　　ALTER TABLE tablename
　　PCTFREE 30
　　PCTUSED 50
　　STORAGE(NEXT 500K
　　MINEXTENTS 2
　　MAXEXTENTS 100);
　　
　　ALTER TABLE tablename
　　ALLOCATE EXTENT(SIZE 500K
　　DATAFILE /DISK3/DATA01.DBF);
　　
　　--把表移到另一个表空间
　　
　　ALTER TABLE TABLENAME MOVE TABLESPACE TABLESPACENAME;
　　
　　--回收空闲的空间(回收到High-water mark)
　　全部回收需要TRUNCATE TABLE tablename
　　
　　ALTER TABLE tablename
　　DEALLOCATE UNUSED;
　　
　　--删除表(连同所用constraint)
　　
　　DROP TABLE tablename
　　CASCADE CONSTRAINTS;
　　
　　--给表增加列
　　
　　ALTER TABLE TABLENAME
　　ADD COLUMN COLUTYPE DEFAULT(VALUE) NOT NULL;
　　
　　--删除表中的列
　　
　　ALTER TABLE tablename
　　DROP COLUMN columnname;
　　
　　ALTER TABLE tablename
　　DROP COLUMN columnname
　　CASCADE CONSTRAINTS CHECKPOINT 1000;
　　
　　--标记列不可用
　　
　　ALTER TABLE tablename
　　SET UNUSED COLUMN columnname
　　CASCADE CONSTRAINTS;
　　
　　--删除标记为不可用的列
　　
　　ALTER TABLE tablename
　　DROP UNUSED COLUMNS CHECKPOINT 1000;
　　
　　--继续删除列选项
　　
　　ALTER TABLE tablename
　　DROP COLUMNS CONTINUE CHECKPOINT 1000;
　　
　　--把表放到BUFFER_POOL中去
　　
　　ALTER TABLE tablename
　　STORAGE (BUFFER_POOL RECYCLE);
　　
　　--避免动态分配EXTENT
　　
　　ALTER TABLE tablename ALLOCATE EXTENT;
　　
　　--把表放到CACHE中去
　　
　　ALTER TABLE tablename ALLOCATE CACHE/NOCACHE;
　　
　　4、索引管理
　　
　　--创建索引
　　
　　CREATE INDEX indexname ON TABLENAME(COLUMNNAME);
　　
　　CREATE INDEX indexname ON TABLENAME(COLUMNNAME) TABLESPACE TABLESPACENAME;
　　
　　--重新建立索引
　　
　　ALTER INDEX indexname REBUILD TABLESPACE　TABLESPACE;
　　
　　--索引分配参数
　　
　　ALTER INDEX indexname
　　STORAGE(NEXT 400K
　　MAXEXTENTS 100);
　　
　　--释放索引空间
　　
　　ALTER INDEX indexname
　　ALLOCATE EXTENT (SIZE 200K
　　DATAFILE /DISK6/indx01.dbf);
　　
　　ALTER INDEX indexname
　　DEALLOCATE UNUSED;
　　
　　--重新整理索引表空间碎片
　　
　　ALTER INDEX indexname COALESCE;
　　
　　--删除索引
　　
　　DROP INDEX indexname
　　
　　--把索引放到BUFFER_POOL中
　　
　　ALTER INDEX cust_name_idx
　　REBUILD
　　STORAGE (BUFFER_POOL KEEP);
　　
　　5、约束管理
　　
　　--建立主键
　　
　　ALTER TABLE TABLENAME
　　ADD CONSTRAINT CONSTRAINTNAME PRIMARY KEY(COLUMN1,COLUMN2)
　　
　　--使约束无效
　　
　　ALTER TABLE TABLENAME ENABLE NOVALIDATE CONSTRAINT constraintname;
　　
　　ALTER TABLE TABLENAME ENABLE VALIDATE CONSTRAINT constraintname;
　　
　　--删除约束
　　
　　ALTER TABLE tablename　DROP CONSTRAINT constraintname;
　　
　　DROP TABLE tablename CASCADE CONSTRAINTS;(删除表后将所用的外键删除)
　　
　　--给列增加缺省值
　　
　　ALTER TABLE TABLENAME
　　MODIFY columnname　DEFAULT(value) NOT NULL;
　　
　　--给表增加外键
　　ALTER TABLE　tablename
　　ADD CONSTRAINT　constraintname
　　FOREIGN KEY(column) REFERENCES table1name(column1);
　　
　　6、安全策略
　　
　　--加密传输
　　
　　把客户端环境变量ora_encrypt_login设为true
　　把服务器端参数dblink_encypt_login设为true
　　
　　--数据库管理员安全策略
　　
　　a、建库后立即修改SYS/SYSTEM的口令(9.2后必须修改其口令)
　　b、只有数据库管理员才能以SYSDBA登录系统
　　c、建立不同角色的管理员，分配不同的权限
　　
　　比如：对象创建于维护
　　数据库的调整与维护
　　创建用户分配角色
　　启动关闭
　　恢复备份
　　
　　--应用开发者的安全策略
　　
　　a、开发者的特权只能在测试开发的数据库中赋予权限
　　b、自由开发者、受控开发者
　　自由开发者:create tableindexprocedurepackage
　　受控开发者:没有以上权限
　　
　　7、日志文件管理
　　
　　--切换日志文件
　　
　　ALTER SYSTEM SWITCH LOGFILE;
　　
　　--增加日志文件
　　
　　ALTER DATABASE ADD LOGFILE
　　(/DISK3/log3a.rdo,
　　/DISK4/log3b.rdo) size 1M;
　　
　　--增加日志成员
　　
　　ALTER DATABASE ADD LOGFILE MEMBER
　　/DISK4/log1b.rdo TO GROUP 1
　　/DISK4/log2b.rdo TO GROUP 2;
　　
　　--删除日志文件
　　
　　ALTER DATABASE DROP LOGFILE GROUP 3;
　　
　　--删除日志成员
　　
　　ALTER DATABASE DROP LOGFILE MEMBER /DISK4/log2b.dbf;
　　
　　--清除日志文件内容
　　
　　ALTER DATABASE CLEAR LOGFILE /DISK3/log2a.rdo; 




**** 常用系统表
1.系统表
ORACLE数据库的系统参数都存储在数据库中，可以通过SQLPLUS，以用户SYSYTEM进行查询。几个重要的表或者视图如下：

v$controlfile：控制文件的信息；
v$datafile：数据文件的信息；
v$log：日志文件的信息；
v$process：处理器的信息；
v$session：会话信息；
v$transaction：事务信息；
v$resource：资源信息；
v$sga：系统全局区的信息。


上面的视图名中的‘v$’,只是视图名字中的字符。类似于上面的视图或表还有很多，位于：
$ORACLE_HOME/RDBMS/ADMIN/CATALOG.SQL文件中。


这些视图或表可以在SQLPLUS中用SELECT语句进行查询。


2.数据字典视图
表和列
DBA_TABLES、ALL_TABLES和USER_TABLES显示了有关数据库表的一般信息。


DBA_TAB_COLUMNS、ALL_TAB_COLUMNS和USER_TAB_COLUMNS显示了每个数据库表的列的信息。


注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括表。


完整性约束
DBA_CONSTRAINTS、ALL_CONSTRAINTS和USER_CONSTRAINST显示有关约束的一般信息。


DBA_CONS_COLUMNS、ALL_CONS_COLUMNS和USER_CONS_COLUMNS显示有关列的相关约束的一般信息。


视图
DBA_VIEWS、ALL_VIEWS和USER_VIEWS。


注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括视图。


序列
DBA_SEQUENCES、ALL_SEQUENCES和USER_SEQUENCES。


注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括序列。


同义词
DBA_SYNONYMS、ALL_SYNONYMS和USER_SYNONYMS。


注意：DBA_OBJECTS、ALL_OBJECTS和USER_OBJECTS显示了模式对象的信息，包括同义词。


索引
DBA_INDEXS、ALL_INDEXS、USER_INDEXS、DBA_IND_COLUMNS、ALL_IND_COLUMNS和USER_IND_COLUMNS。


用户
DBA_USERS。


角色
DBA_ROLES。


表空间定额
DBA_TS_QUOTAS。


配置表
DBA_PROFILES。


表空间
DBA_TABLESPACES。


数据文件
DBA_DATA_FILES。


段
DBA_SEGMENTS、USER_SEGMENT。


回滚段
DBA_ROLLBACK_SEGS、V$ROLLNAME、V$ROLLSTAT。 


* Algorithm
** 时间复杂度
   首先了解一下几个概念。一个是时间复杂度，一个是渐近时间复杂度。前者是某个算法的时间耗费，它是该算法所求解问题规模n的函数，而后者是指当问题规模趋向无穷大时，该算法时间复杂度的数量级。
当我们评价一个算法的时间性能时，主要标准就是算法的渐近时间复杂度，因此，在算法分析时，往往对两者不予区分，经常是将渐近时间复杂度T(n)=O(f(n))简称为时间复杂度，其中的f(n)一般是算法中频度最大的语句频度。
此外，算法中语句的频度不仅与问题规模有关，还与输入实例中各元素的取值相关。但是我们总是考虑在最坏的情况下的时间复杂度。以保证算法的运行时间不会比它更长。
常见的时间复杂度，按数量级递增排列依次为：常数阶O(1)、对数阶O(log2n)、线性阶O(n)、线性对数阶O(nlog2n)、平方阶O(n^2)、立方阶O(n^3)、k次方阶O(n^k)、指数阶O(2^n)。
下面我们通过例子加以说明，让大家碰到问题时知道如何去解决。
1、设三个函数f,g,h分别为 f(n)=100n^3+n^2+1000 , g(n)=25n^3+5000n^2 , h(n)=n^1.5+5000nlgn
请判断下列关系是否成立：
（1） f(n)=O(g(n))
（2） g(n)=O(f(n))
（3） h(n)=O(n^1.5)
（4） h(n)=O(nlgn)
这 里我们复习一下渐近时间复杂度的表示法T(n)=O(f(n))，这里的"O"是数学符号，它的严格定义是"若T(n)和f(n)是定义在正整数集合上的 两个函数，则T(n)=O(f(n))表示存在正的常数C和n0 ,使得当n≥n0时都满足0≤T(n)≤C?f(n)。"用容易理解的话说就是这两个函数当整型自变量n趋向于无穷大时，两者的比值是一个不等于0的常 数。这么一来，就好计算了吧。

◆ (1)成立。题中由于两个函数的最高次项都是n^3,因此当n→∞时，两个函数的比值是一个常数，所以这个关系式是成立的。
◆ （2）成立。与上同理。
◆ （3）成立。与上同理。
◆ （4）不成立。由于当n→∞时n^1.5比nlgn递增的快，所以h(n)与nlgn的比值不是常数，故不成立。

2、设n为正整数，利用大"O"记号，将下列程序段的执行时间表示为n的函数。
(1) i=1; k=0
while(i<n)
{ k=k+10*i;i++;
}
解答：T(n)=n-1， T(n)=O(n)， 这个函数是按线性阶递增的。
(2) x=n; // n>1
while (x>=(y+1)*(y+1))
y++;
解答：T(n)=n1/2 ，T(n)=O(n1/2)， 最坏的情况是y=0，那么循环的次数是n1/2次，这是一个按平方根阶递增的函数。
(3) x=91; y=100;
while(y>0)
if(x>100)
{x=x-10;y--;}
else x++;
解答： T(n)=O(1)， 这个程序看起来有点吓人，总共循环运行了1000次，但是我们看到n没有? 没。这段程序的运行是和n无关的，就算它再循环一万年，我们也不管他，只是一个常数阶的函数。
一个经验规则

有如下复杂度关系

c < log2N < n < n * Log2N < n^2 < n^3 < 2^n < 3^n < n!

其中c是一个常量，如果一个算法的复杂度为c 、 log2N 、n 、 n*log2N ,那么这个算法时间效率比较高 ，如果是 2^n , 3^n ,n!，那么稍微大一些的n就会令这个算法不能动了，居于中间的几个则差强人意。
 







* English
** Phrase
+ Reaffirms his faith
reaffirm   said and said 

+ lure

** WEB
*** movie
http://zhidao.baidu.com/question/154220764.html














* Embedded
** mips


*** 汇编
**** rdhwr
rdhwr可以用来读取硬件寄存器，
rdhwr %3, $29   代表读取硬件寄存器29 ， 至寄存器3
在用户态使用rdhwr %0,$0, 可以用来读取cpu num
$1读取L1 Cache的有效行大小，$2读取协处理器0的Count寄存器，$3返回协处理器Count寄存器变化的速度，也就是处理器运行的速度。
用户态使用rdhwr %0,$29, 由于没有硬件寄存器29，所以会陷入内核，内核可以模拟实现29号寄存器，然后将值返回给用户态，通常linux中用29号硬件寄存器来存储tls的首地址
可以参考内核中的如下宏，来写嵌入式的汇编语言，来使用rdhwr
#define CVMX_RDHWRNV(result, regstr) \
        asm ("rdhwr %[rt],$" CVMX_TMP_STR(regstr) : [rt] "=d" (result))

// turn the variable name into a string 
#define CVMX_TMP_STR(x) CVMX_TMP_STR2(x)
#define CVMX_TMP_STR2(x) #x

在linux-mips中，内核是通过如下代码来handle rdhwr的
set_except_vector(10, rdhwr_noopt ? handle_ri :
  (cpu_has_vtag_icache ?
     handle_ri_rdhwr_vivt : handle_ri_rdhwr));

** ARM
*** Categorical
ARMv7 - A  , normal
ARMv7 - R  , realtime
ARMv7 - M  , micro
ARMv8 - A  , normal, 64bits


* Other
** 服务器空间
1. IXWebHosting
流量：NA
空间：NA
支持：php，mysql，perl
价格：3.95 * 12
http://ixwebhosting.idcspy.com/ixwebhosting-linux.html

2. godaddy
流量：NA
空间：10G
支持：php，mysql, (perl , python  7$才支持)
价格：4.99 * 12
http://www.godaddy.com/hosting/web-hosting.aspx?isc=cjcdplink&ci=9009

3. hostease 
流量：20G
空间：2G   （NA 6.96$）
支持：php，mysql，python, perl
价格：3.95 * 12
http://cn.hostease.com/shared-hosting.html


4. HostGator
流量：NA
空间：NA
支持：php，mysql, python
价格：3.96 * 12
http://www.hostgator.com/shared.shtml


5.
流量：NA
空间：NA
支持：jsp
价格：4.95 * 12
http://www.lunarpages.com/web-hosting/basic-hosting/

6.
流量：
空间：
支持：php，mysql
价格：


7.
流量：
空间：
支持：php，mysql
价格：


8.
流量：
空间：
支持：php，mysql
价格：


9.
流量：
空间：
支持：php，mysql
价格：

10.
流量：
空间：
支持：php，mysql
价格：




不错的推荐网址 http://www.idcspy.com/%E5%8D%81%E5%A4%A7%E7%BE%8E%E5%9B%BD%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA.html


** 我的主页
*** 3v
我的主页地址   wangyaosuper.free3v.net
管理方法 ftp://wangyaosuper.free3v.net      密码是wyao123
主页  www.3v.cm   用户名wangyaosuper  密码不记得了
